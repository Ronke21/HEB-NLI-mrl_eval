{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.31992641692410745,
  "eval_steps": 10316,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0031992641692410746,
      "grad_norm": 3.647721290588379,
      "learning_rate": 6.078055022392836e-08,
      "loss": 0.0157,
      "step": 20
    },
    {
      "epoch": 0.006398528338482149,
      "grad_norm": 9.216941833496094,
      "learning_rate": 1.2476007677543187e-07,
      "loss": 0.0128,
      "step": 40
    },
    {
      "epoch": 0.009597792507723224,
      "grad_norm": 4.939019680023193,
      "learning_rate": 1.887396033269354e-07,
      "loss": 0.0289,
      "step": 60
    },
    {
      "epoch": 0.012797056676964298,
      "grad_norm": 10.117718696594238,
      "learning_rate": 2.5271912987843894e-07,
      "loss": 0.0167,
      "step": 80
    },
    {
      "epoch": 0.01599632084620537,
      "grad_norm": 5.143263339996338,
      "learning_rate": 3.166986564299424e-07,
      "loss": 0.0082,
      "step": 100
    },
    {
      "epoch": 0.019195585015446447,
      "grad_norm": 4.074337482452393,
      "learning_rate": 3.8067818298144597e-07,
      "loss": 0.0268,
      "step": 120
    },
    {
      "epoch": 0.02239484918468752,
      "grad_norm": 0.1844700276851654,
      "learning_rate": 4.446577095329495e-07,
      "loss": 0.0156,
      "step": 140
    },
    {
      "epoch": 0.025594113353928596,
      "grad_norm": 0.014935605227947235,
      "learning_rate": 5.086372360844531e-07,
      "loss": 0.0092,
      "step": 160
    },
    {
      "epoch": 0.02879337752316967,
      "grad_norm": 0.030009910464286804,
      "learning_rate": 5.726167626359565e-07,
      "loss": 0.013,
      "step": 180
    },
    {
      "epoch": 0.03199264169241074,
      "grad_norm": 3.4048354625701904,
      "learning_rate": 6.365962891874601e-07,
      "loss": 0.0073,
      "step": 200
    },
    {
      "epoch": 0.03519190586165182,
      "grad_norm": 2.451016902923584,
      "learning_rate": 7.005758157389636e-07,
      "loss": 0.0143,
      "step": 220
    },
    {
      "epoch": 0.038391170030892895,
      "grad_norm": 2.6395034790039062,
      "learning_rate": 7.645553422904671e-07,
      "loss": 0.0153,
      "step": 240
    },
    {
      "epoch": 0.04159043420013397,
      "grad_norm": 0.17071953415870667,
      "learning_rate": 8.285348688419706e-07,
      "loss": 0.0079,
      "step": 260
    },
    {
      "epoch": 0.04478969836937504,
      "grad_norm": 1.1250747442245483,
      "learning_rate": 8.925143953934741e-07,
      "loss": 0.008,
      "step": 280
    },
    {
      "epoch": 0.04798896253861612,
      "grad_norm": 1.0496363639831543,
      "learning_rate": 9.564939219449776e-07,
      "loss": 0.0094,
      "step": 300
    },
    {
      "epoch": 0.05118822670785719,
      "grad_norm": 3.4772379398345947,
      "learning_rate": 1.0204734484964812e-06,
      "loss": 0.0136,
      "step": 320
    },
    {
      "epoch": 0.054387490877098266,
      "grad_norm": 4.341487407684326,
      "learning_rate": 1.0844529750479848e-06,
      "loss": 0.0056,
      "step": 340
    },
    {
      "epoch": 0.05758675504633934,
      "grad_norm": 0.07271590828895569,
      "learning_rate": 1.1484325015994881e-06,
      "loss": 0.0087,
      "step": 360
    },
    {
      "epoch": 0.06078601921558042,
      "grad_norm": 3.246042251586914,
      "learning_rate": 1.212412028150992e-06,
      "loss": 0.0049,
      "step": 380
    },
    {
      "epoch": 0.06398528338482148,
      "grad_norm": 6.233398914337158,
      "learning_rate": 1.2763915547024953e-06,
      "loss": 0.0087,
      "step": 400
    },
    {
      "epoch": 0.06718454755406257,
      "grad_norm": 4.4029951095581055,
      "learning_rate": 1.3403710812539989e-06,
      "loss": 0.0082,
      "step": 420
    },
    {
      "epoch": 0.07038381172330364,
      "grad_norm": 5.2398600578308105,
      "learning_rate": 1.4043506078055024e-06,
      "loss": 0.0093,
      "step": 440
    },
    {
      "epoch": 0.07358307589254472,
      "grad_norm": 2.390291452407837,
      "learning_rate": 1.4683301343570058e-06,
      "loss": 0.0108,
      "step": 460
    },
    {
      "epoch": 0.07678234006178579,
      "grad_norm": 0.20899948477745056,
      "learning_rate": 1.5323096609085096e-06,
      "loss": 0.0066,
      "step": 480
    },
    {
      "epoch": 0.07998160423102686,
      "grad_norm": 4.942864894866943,
      "learning_rate": 1.596289187460013e-06,
      "loss": 0.0103,
      "step": 500
    },
    {
      "epoch": 0.08318086840026793,
      "grad_norm": 8.910289764404297,
      "learning_rate": 1.6602687140115165e-06,
      "loss": 0.0135,
      "step": 520
    },
    {
      "epoch": 0.08638013256950901,
      "grad_norm": 0.025533391162753105,
      "learning_rate": 1.72424824056302e-06,
      "loss": 0.0089,
      "step": 540
    },
    {
      "epoch": 0.08957939673875008,
      "grad_norm": 0.7780927419662476,
      "learning_rate": 1.7882277671145234e-06,
      "loss": 0.0075,
      "step": 560
    },
    {
      "epoch": 0.09277866090799117,
      "grad_norm": 1.1585496664047241,
      "learning_rate": 1.852207293666027e-06,
      "loss": 0.0122,
      "step": 580
    },
    {
      "epoch": 0.09597792507723224,
      "grad_norm": 0.016127465292811394,
      "learning_rate": 1.9161868202175304e-06,
      "loss": 0.0068,
      "step": 600
    },
    {
      "epoch": 0.09917718924647331,
      "grad_norm": 0.34317103028297424,
      "learning_rate": 1.980166346769034e-06,
      "loss": 0.0084,
      "step": 620
    },
    {
      "epoch": 0.10237645341571439,
      "grad_norm": 0.11007340252399445,
      "learning_rate": 2.044145873320538e-06,
      "loss": 0.0091,
      "step": 640
    },
    {
      "epoch": 0.10557571758495546,
      "grad_norm": 0.27486467361450195,
      "learning_rate": 2.108125399872041e-06,
      "loss": 0.005,
      "step": 660
    },
    {
      "epoch": 0.10877498175419653,
      "grad_norm": 0.19054588675498962,
      "learning_rate": 2.1721049264235446e-06,
      "loss": 0.0078,
      "step": 680
    },
    {
      "epoch": 0.1119742459234376,
      "grad_norm": 7.3258233070373535,
      "learning_rate": 2.236084452975048e-06,
      "loss": 0.0066,
      "step": 700
    },
    {
      "epoch": 0.11517351009267868,
      "grad_norm": 8.288479804992676,
      "learning_rate": 2.3000639795265518e-06,
      "loss": 0.0076,
      "step": 720
    },
    {
      "epoch": 0.11837277426191976,
      "grad_norm": 0.3918476700782776,
      "learning_rate": 2.364043506078055e-06,
      "loss": 0.0093,
      "step": 740
    },
    {
      "epoch": 0.12157203843116084,
      "grad_norm": 0.14414948225021362,
      "learning_rate": 2.4280230326295585e-06,
      "loss": 0.009,
      "step": 760
    },
    {
      "epoch": 0.12477130260040191,
      "grad_norm": 0.24460460245609283,
      "learning_rate": 2.4920025591810623e-06,
      "loss": 0.007,
      "step": 780
    },
    {
      "epoch": 0.12797056676964297,
      "grad_norm": 7.225488185882568,
      "learning_rate": 2.5559820857325656e-06,
      "loss": 0.0056,
      "step": 800
    },
    {
      "epoch": 0.13116983093888407,
      "grad_norm": 8.28003978729248,
      "learning_rate": 2.6199616122840694e-06,
      "loss": 0.0081,
      "step": 820
    },
    {
      "epoch": 0.13436909510812514,
      "grad_norm": 0.062131792306900024,
      "learning_rate": 2.6839411388355728e-06,
      "loss": 0.005,
      "step": 840
    },
    {
      "epoch": 0.13756835927736621,
      "grad_norm": 8.319822311401367,
      "learning_rate": 2.7479206653870766e-06,
      "loss": 0.0064,
      "step": 860
    },
    {
      "epoch": 0.1407676234466073,
      "grad_norm": 3.182339668273926,
      "learning_rate": 2.8119001919385795e-06,
      "loss": 0.0104,
      "step": 880
    },
    {
      "epoch": 0.14396688761584836,
      "grad_norm": 0.043217454105615616,
      "learning_rate": 2.8758797184900833e-06,
      "loss": 0.0093,
      "step": 900
    },
    {
      "epoch": 0.14716615178508943,
      "grad_norm": 0.06831171363592148,
      "learning_rate": 2.939859245041587e-06,
      "loss": 0.0117,
      "step": 920
    },
    {
      "epoch": 0.1503654159543305,
      "grad_norm": 6.150307655334473,
      "learning_rate": 3.0038387715930904e-06,
      "loss": 0.0049,
      "step": 940
    },
    {
      "epoch": 0.15356468012357158,
      "grad_norm": 4.827648162841797,
      "learning_rate": 3.0678182981445942e-06,
      "loss": 0.0075,
      "step": 960
    },
    {
      "epoch": 0.15676394429281265,
      "grad_norm": 0.6485546231269836,
      "learning_rate": 3.131797824696097e-06,
      "loss": 0.0036,
      "step": 980
    },
    {
      "epoch": 0.15996320846205372,
      "grad_norm": 0.49286001920700073,
      "learning_rate": 3.195777351247601e-06,
      "loss": 0.0058,
      "step": 1000
    },
    {
      "epoch": 0.1631624726312948,
      "grad_norm": 0.30482009053230286,
      "learning_rate": 3.2597568777991047e-06,
      "loss": 0.0055,
      "step": 1020
    },
    {
      "epoch": 0.16636173680053587,
      "grad_norm": 0.020520923659205437,
      "learning_rate": 3.323736404350608e-06,
      "loss": 0.0072,
      "step": 1040
    },
    {
      "epoch": 0.16956100096977694,
      "grad_norm": 8.089029312133789,
      "learning_rate": 3.387715930902112e-06,
      "loss": 0.0054,
      "step": 1060
    },
    {
      "epoch": 0.17276026513901802,
      "grad_norm": 0.03820296749472618,
      "learning_rate": 3.451695457453615e-06,
      "loss": 0.0077,
      "step": 1080
    },
    {
      "epoch": 0.1759595293082591,
      "grad_norm": 0.09461426734924316,
      "learning_rate": 3.5156749840051186e-06,
      "loss": 0.0092,
      "step": 1100
    },
    {
      "epoch": 0.17915879347750016,
      "grad_norm": 0.9214872121810913,
      "learning_rate": 3.5796545105566224e-06,
      "loss": 0.0088,
      "step": 1120
    },
    {
      "epoch": 0.18235805764674126,
      "grad_norm": 1.5814621448516846,
      "learning_rate": 3.6436340371081257e-06,
      "loss": 0.0036,
      "step": 1140
    },
    {
      "epoch": 0.18555732181598233,
      "grad_norm": 4.8131937980651855,
      "learning_rate": 3.7076135636596295e-06,
      "loss": 0.0049,
      "step": 1160
    },
    {
      "epoch": 0.1887565859852234,
      "grad_norm": 8.6712064743042,
      "learning_rate": 3.7715930902111324e-06,
      "loss": 0.0091,
      "step": 1180
    },
    {
      "epoch": 0.19195585015446448,
      "grad_norm": 5.878591060638428,
      "learning_rate": 3.835572616762636e-06,
      "loss": 0.0101,
      "step": 1200
    },
    {
      "epoch": 0.19515511432370555,
      "grad_norm": 6.432859897613525,
      "learning_rate": 3.89955214331414e-06,
      "loss": 0.0079,
      "step": 1220
    },
    {
      "epoch": 0.19835437849294663,
      "grad_norm": 0.3911115229129791,
      "learning_rate": 3.963531669865644e-06,
      "loss": 0.0024,
      "step": 1240
    },
    {
      "epoch": 0.2015536426621877,
      "grad_norm": 6.002155303955078,
      "learning_rate": 4.027511196417147e-06,
      "loss": 0.0113,
      "step": 1260
    },
    {
      "epoch": 0.20475290683142877,
      "grad_norm": 0.034379974007606506,
      "learning_rate": 4.0914907229686505e-06,
      "loss": 0.0064,
      "step": 1280
    },
    {
      "epoch": 0.20795217100066984,
      "grad_norm": 0.245756596326828,
      "learning_rate": 4.155470249520154e-06,
      "loss": 0.0069,
      "step": 1300
    },
    {
      "epoch": 0.21115143516991092,
      "grad_norm": 1.476542353630066,
      "learning_rate": 4.219449776071657e-06,
      "loss": 0.0077,
      "step": 1320
    },
    {
      "epoch": 0.214350699339152,
      "grad_norm": 0.02424820140004158,
      "learning_rate": 4.2834293026231614e-06,
      "loss": 0.0073,
      "step": 1340
    },
    {
      "epoch": 0.21754996350839306,
      "grad_norm": 4.7293195724487305,
      "learning_rate": 4.347408829174665e-06,
      "loss": 0.0013,
      "step": 1360
    },
    {
      "epoch": 0.22074922767763414,
      "grad_norm": 5.636271953582764,
      "learning_rate": 4.411388355726168e-06,
      "loss": 0.0048,
      "step": 1380
    },
    {
      "epoch": 0.2239484918468752,
      "grad_norm": 0.006125065963715315,
      "learning_rate": 4.4753678822776715e-06,
      "loss": 0.0063,
      "step": 1400
    },
    {
      "epoch": 0.22714775601611628,
      "grad_norm": 0.4995366036891937,
      "learning_rate": 4.539347408829175e-06,
      "loss": 0.0102,
      "step": 1420
    },
    {
      "epoch": 0.23034702018535735,
      "grad_norm": 0.2672869861125946,
      "learning_rate": 4.603326935380679e-06,
      "loss": 0.0079,
      "step": 1440
    },
    {
      "epoch": 0.23354628435459845,
      "grad_norm": 0.43741855025291443,
      "learning_rate": 4.6673064619321824e-06,
      "loss": 0.0077,
      "step": 1460
    },
    {
      "epoch": 0.23674554852383953,
      "grad_norm": 0.49594128131866455,
      "learning_rate": 4.731285988483685e-06,
      "loss": 0.0068,
      "step": 1480
    },
    {
      "epoch": 0.2399448126930806,
      "grad_norm": 0.08358272910118103,
      "learning_rate": 4.795265515035189e-06,
      "loss": 0.0065,
      "step": 1500
    },
    {
      "epoch": 0.24314407686232167,
      "grad_norm": 0.06224599480628967,
      "learning_rate": 4.8592450415866925e-06,
      "loss": 0.0021,
      "step": 1520
    },
    {
      "epoch": 0.24634334103156275,
      "grad_norm": 5.708918571472168,
      "learning_rate": 4.923224568138196e-06,
      "loss": 0.0055,
      "step": 1540
    },
    {
      "epoch": 0.24954260520080382,
      "grad_norm": 3.0138895511627197,
      "learning_rate": 4.9872040946897e-06,
      "loss": 0.004,
      "step": 1560
    },
    {
      "epoch": 0.2527418693700449,
      "grad_norm": 9.562094688415527,
      "learning_rate": 5.0511836212412034e-06,
      "loss": 0.0074,
      "step": 1580
    },
    {
      "epoch": 0.25594113353928594,
      "grad_norm": 0.22499431669712067,
      "learning_rate": 5.115163147792707e-06,
      "loss": 0.0038,
      "step": 1600
    },
    {
      "epoch": 0.25914039770852704,
      "grad_norm": 0.015243493020534515,
      "learning_rate": 5.179142674344211e-06,
      "loss": 0.0064,
      "step": 1620
    },
    {
      "epoch": 0.26233966187776814,
      "grad_norm": 0.009542080573737621,
      "learning_rate": 5.2431222008957135e-06,
      "loss": 0.0047,
      "step": 1640
    },
    {
      "epoch": 0.2655389260470092,
      "grad_norm": 0.22578199207782745,
      "learning_rate": 5.307101727447217e-06,
      "loss": 0.0093,
      "step": 1660
    },
    {
      "epoch": 0.2687381902162503,
      "grad_norm": 4.283547401428223,
      "learning_rate": 5.371081253998721e-06,
      "loss": 0.007,
      "step": 1680
    },
    {
      "epoch": 0.27193745438549133,
      "grad_norm": 0.03048321232199669,
      "learning_rate": 5.4350607805502244e-06,
      "loss": 0.0043,
      "step": 1700
    },
    {
      "epoch": 0.27513671855473243,
      "grad_norm": 0.0555131696164608,
      "learning_rate": 5.499040307101729e-06,
      "loss": 0.0052,
      "step": 1720
    },
    {
      "epoch": 0.2783359827239735,
      "grad_norm": 0.30611807107925415,
      "learning_rate": 5.563019833653231e-06,
      "loss": 0.0083,
      "step": 1740
    },
    {
      "epoch": 0.2815352468932146,
      "grad_norm": 3.731032371520996,
      "learning_rate": 5.6269993602047345e-06,
      "loss": 0.0096,
      "step": 1760
    },
    {
      "epoch": 0.2847345110624556,
      "grad_norm": 0.029559297487139702,
      "learning_rate": 5.690978886756239e-06,
      "loss": 0.0059,
      "step": 1780
    },
    {
      "epoch": 0.2879337752316967,
      "grad_norm": 0.11989385634660721,
      "learning_rate": 5.754958413307742e-06,
      "loss": 0.0064,
      "step": 1800
    },
    {
      "epoch": 0.29113303940093777,
      "grad_norm": 1.4497236013412476,
      "learning_rate": 5.818937939859246e-06,
      "loss": 0.0126,
      "step": 1820
    },
    {
      "epoch": 0.29433230357017887,
      "grad_norm": 4.037020206451416,
      "learning_rate": 5.882917466410749e-06,
      "loss": 0.0103,
      "step": 1840
    },
    {
      "epoch": 0.2975315677394199,
      "grad_norm": 5.19830846786499,
      "learning_rate": 5.946896992962252e-06,
      "loss": 0.0085,
      "step": 1860
    },
    {
      "epoch": 0.300730831908661,
      "grad_norm": 0.08461894094944,
      "learning_rate": 6.010876519513756e-06,
      "loss": 0.0053,
      "step": 1880
    },
    {
      "epoch": 0.30393009607790206,
      "grad_norm": 0.017132030799984932,
      "learning_rate": 6.07485604606526e-06,
      "loss": 0.0036,
      "step": 1900
    },
    {
      "epoch": 0.30712936024714316,
      "grad_norm": 0.012963555753231049,
      "learning_rate": 6.138835572616764e-06,
      "loss": 0.0046,
      "step": 1920
    },
    {
      "epoch": 0.31032862441638426,
      "grad_norm": 0.9619695544242859,
      "learning_rate": 6.2028150991682664e-06,
      "loss": 0.0029,
      "step": 1940
    },
    {
      "epoch": 0.3135278885856253,
      "grad_norm": 0.19336195290088654,
      "learning_rate": 6.26679462571977e-06,
      "loss": 0.0076,
      "step": 1960
    },
    {
      "epoch": 0.3167271527548664,
      "grad_norm": 0.13274964690208435,
      "learning_rate": 6.330774152271274e-06,
      "loss": 0.0066,
      "step": 1980
    },
    {
      "epoch": 0.31992641692410745,
      "grad_norm": 7.872570037841797,
      "learning_rate": 6.394753678822777e-06,
      "loss": 0.009,
      "step": 2000
    }
  ],
  "logging_steps": 20,
  "max_steps": 31260,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.1746841745019904e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
