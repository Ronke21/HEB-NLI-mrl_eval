{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 3870,
  "global_step": 11725,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008531285824735398,
      "grad_norm": 71.65048217773438,
      "learning_rate": 1.6197783461210572e-07,
      "loss": 4.6384,
      "step": 20
    },
    {
      "epoch": 0.017062571649470795,
      "grad_norm": 102.68253326416016,
      "learning_rate": 3.3248081841432233e-07,
      "loss": 3.1749,
      "step": 40
    },
    {
      "epoch": 0.02559385747420619,
      "grad_norm": 17.452062606811523,
      "learning_rate": 5.029838022165389e-07,
      "loss": 0.4351,
      "step": 60
    },
    {
      "epoch": 0.03412514329894159,
      "grad_norm": 13.994255065917969,
      "learning_rate": 6.734867860187553e-07,
      "loss": 0.1628,
      "step": 80
    },
    {
      "epoch": 0.04265642912367698,
      "grad_norm": 13.612831115722656,
      "learning_rate": 8.439897698209719e-07,
      "loss": 0.1272,
      "step": 100
    },
    {
      "epoch": 0.05118771494841238,
      "grad_norm": 6.461900234222412,
      "learning_rate": 1.0144927536231885e-06,
      "loss": 0.12,
      "step": 120
    },
    {
      "epoch": 0.059719000773147776,
      "grad_norm": 5.9307451248168945,
      "learning_rate": 1.1849957374254051e-06,
      "loss": 0.1097,
      "step": 140
    },
    {
      "epoch": 0.06825028659788318,
      "grad_norm": 14.960783004760742,
      "learning_rate": 1.3554987212276216e-06,
      "loss": 0.103,
      "step": 160
    },
    {
      "epoch": 0.07678157242261857,
      "grad_norm": 10.409835815429688,
      "learning_rate": 1.526001705029838e-06,
      "loss": 0.1,
      "step": 180
    },
    {
      "epoch": 0.08531285824735396,
      "grad_norm": 8.561992645263672,
      "learning_rate": 1.6965046888320547e-06,
      "loss": 0.0971,
      "step": 200
    },
    {
      "epoch": 0.09384414407208937,
      "grad_norm": 3.3433620929718018,
      "learning_rate": 1.8670076726342711e-06,
      "loss": 0.0967,
      "step": 220
    },
    {
      "epoch": 0.10237542989682476,
      "grad_norm": 3.3893580436706543,
      "learning_rate": 2.0375106564364876e-06,
      "loss": 0.0945,
      "step": 240
    },
    {
      "epoch": 0.11090671572156016,
      "grad_norm": 3.6756434440612793,
      "learning_rate": 2.2080136402387043e-06,
      "loss": 0.0866,
      "step": 260
    },
    {
      "epoch": 0.11943800154629555,
      "grad_norm": 4.296774387359619,
      "learning_rate": 2.378516624040921e-06,
      "loss": 0.0912,
      "step": 280
    },
    {
      "epoch": 0.12796928737103094,
      "grad_norm": 6.822972297668457,
      "learning_rate": 2.549019607843137e-06,
      "loss": 0.0813,
      "step": 300
    },
    {
      "epoch": 0.13650057319576636,
      "grad_norm": 5.30983304977417,
      "learning_rate": 2.719522591645354e-06,
      "loss": 0.0881,
      "step": 320
    },
    {
      "epoch": 0.14503185902050175,
      "grad_norm": 2.7905166149139404,
      "learning_rate": 2.8900255754475705e-06,
      "loss": 0.0835,
      "step": 340
    },
    {
      "epoch": 0.15356314484523714,
      "grad_norm": 2.911580801010132,
      "learning_rate": 3.0605285592497867e-06,
      "loss": 0.0836,
      "step": 360
    },
    {
      "epoch": 0.16209443066997253,
      "grad_norm": 3.4929614067077637,
      "learning_rate": 3.231031543052004e-06,
      "loss": 0.0835,
      "step": 380
    },
    {
      "epoch": 0.17062571649470792,
      "grad_norm": 3.2315032482147217,
      "learning_rate": 3.4015345268542205e-06,
      "loss": 0.0832,
      "step": 400
    },
    {
      "epoch": 0.17915700231944334,
      "grad_norm": 2.3710854053497314,
      "learning_rate": 3.572037510656437e-06,
      "loss": 0.0805,
      "step": 420
    },
    {
      "epoch": 0.18768828814417873,
      "grad_norm": 2.8283257484436035,
      "learning_rate": 3.7425404944586534e-06,
      "loss": 0.0798,
      "step": 440
    },
    {
      "epoch": 0.19621957396891412,
      "grad_norm": 4.398725986480713,
      "learning_rate": 3.91304347826087e-06,
      "loss": 0.0802,
      "step": 460
    },
    {
      "epoch": 0.20475085979364951,
      "grad_norm": 3.019404649734497,
      "learning_rate": 4.083546462063086e-06,
      "loss": 0.0751,
      "step": 480
    },
    {
      "epoch": 0.21328214561838493,
      "grad_norm": 3.4493117332458496,
      "learning_rate": 4.254049445865303e-06,
      "loss": 0.0789,
      "step": 500
    },
    {
      "epoch": 0.22181343144312032,
      "grad_norm": 3.5042102336883545,
      "learning_rate": 4.42455242966752e-06,
      "loss": 0.0786,
      "step": 520
    },
    {
      "epoch": 0.23034471726785571,
      "grad_norm": 4.519463539123535,
      "learning_rate": 4.595055413469736e-06,
      "loss": 0.0828,
      "step": 540
    },
    {
      "epoch": 0.2388760030925911,
      "grad_norm": 4.458188533782959,
      "learning_rate": 4.765558397271953e-06,
      "loss": 0.0838,
      "step": 560
    },
    {
      "epoch": 0.2474072889173265,
      "grad_norm": 2.226768732070923,
      "learning_rate": 4.936061381074169e-06,
      "loss": 0.0745,
      "step": 580
    },
    {
      "epoch": 0.2559385747420619,
      "grad_norm": 3.3293583393096924,
      "learning_rate": 5.106564364876386e-06,
      "loss": 0.0801,
      "step": 600
    },
    {
      "epoch": 0.2644698605667973,
      "grad_norm": 3.2027769088745117,
      "learning_rate": 5.2770673486786025e-06,
      "loss": 0.0781,
      "step": 620
    },
    {
      "epoch": 0.2730011463915327,
      "grad_norm": 2.943660259246826,
      "learning_rate": 5.44757033248082e-06,
      "loss": 0.0763,
      "step": 640
    },
    {
      "epoch": 0.2815324322162681,
      "grad_norm": 3.0417890548706055,
      "learning_rate": 5.618073316283036e-06,
      "loss": 0.0801,
      "step": 660
    },
    {
      "epoch": 0.2900637180410035,
      "grad_norm": 1.8657169342041016,
      "learning_rate": 5.788576300085252e-06,
      "loss": 0.0722,
      "step": 680
    },
    {
      "epoch": 0.2985950038657389,
      "grad_norm": 2.532022714614868,
      "learning_rate": 5.959079283887469e-06,
      "loss": 0.074,
      "step": 700
    },
    {
      "epoch": 0.3071262896904743,
      "grad_norm": 2.7510859966278076,
      "learning_rate": 6.1295822676896854e-06,
      "loss": 0.0773,
      "step": 720
    },
    {
      "epoch": 0.3156575755152097,
      "grad_norm": 2.4297237396240234,
      "learning_rate": 6.300085251491902e-06,
      "loss": 0.074,
      "step": 740
    },
    {
      "epoch": 0.32418886133994507,
      "grad_norm": 2.0020360946655273,
      "learning_rate": 6.470588235294119e-06,
      "loss": 0.0822,
      "step": 760
    },
    {
      "epoch": 0.33272014716468046,
      "grad_norm": 3.716052532196045,
      "learning_rate": 6.641091219096335e-06,
      "loss": 0.0761,
      "step": 780
    },
    {
      "epoch": 0.34125143298941585,
      "grad_norm": 1.7700426578521729,
      "learning_rate": 6.811594202898551e-06,
      "loss": 0.0734,
      "step": 800
    },
    {
      "epoch": 0.3497827188141513,
      "grad_norm": 3.2676103115081787,
      "learning_rate": 6.982097186700768e-06,
      "loss": 0.0806,
      "step": 820
    },
    {
      "epoch": 0.3583140046388867,
      "grad_norm": 2.1422126293182373,
      "learning_rate": 7.152600170502985e-06,
      "loss": 0.0774,
      "step": 840
    },
    {
      "epoch": 0.3668452904636221,
      "grad_norm": 2.2391650676727295,
      "learning_rate": 7.323103154305201e-06,
      "loss": 0.0726,
      "step": 860
    },
    {
      "epoch": 0.37537657628835747,
      "grad_norm": 1.9532012939453125,
      "learning_rate": 7.493606138107418e-06,
      "loss": 0.0756,
      "step": 880
    },
    {
      "epoch": 0.38390786211309286,
      "grad_norm": 1.953543782234192,
      "learning_rate": 7.664109121909635e-06,
      "loss": 0.0796,
      "step": 900
    },
    {
      "epoch": 0.39243914793782825,
      "grad_norm": 1.6011791229248047,
      "learning_rate": 7.83461210571185e-06,
      "loss": 0.0757,
      "step": 920
    },
    {
      "epoch": 0.40097043376256364,
      "grad_norm": 1.8830382823944092,
      "learning_rate": 8.005115089514067e-06,
      "loss": 0.0774,
      "step": 940
    },
    {
      "epoch": 0.40950171958729903,
      "grad_norm": 1.8010324239730835,
      "learning_rate": 8.175618073316285e-06,
      "loss": 0.0775,
      "step": 960
    },
    {
      "epoch": 0.4180330054120344,
      "grad_norm": 2.1304311752319336,
      "learning_rate": 8.3461210571185e-06,
      "loss": 0.0773,
      "step": 980
    },
    {
      "epoch": 0.42656429123676987,
      "grad_norm": 1.470168113708496,
      "learning_rate": 8.516624040920717e-06,
      "loss": 0.0705,
      "step": 1000
    },
    {
      "epoch": 0.43509557706150526,
      "grad_norm": 2.2382636070251465,
      "learning_rate": 8.687127024722934e-06,
      "loss": 0.0669,
      "step": 1020
    },
    {
      "epoch": 0.44362686288624065,
      "grad_norm": 1.8203202486038208,
      "learning_rate": 8.85763000852515e-06,
      "loss": 0.0774,
      "step": 1040
    },
    {
      "epoch": 0.45215814871097604,
      "grad_norm": 1.7503384351730347,
      "learning_rate": 9.028132992327367e-06,
      "loss": 0.075,
      "step": 1060
    },
    {
      "epoch": 0.46068943453571143,
      "grad_norm": 1.7953828573226929,
      "learning_rate": 9.198635976129584e-06,
      "loss": 0.0794,
      "step": 1080
    },
    {
      "epoch": 0.4692207203604468,
      "grad_norm": 1.4670830965042114,
      "learning_rate": 9.369138959931799e-06,
      "loss": 0.0703,
      "step": 1100
    },
    {
      "epoch": 0.4777520061851822,
      "grad_norm": 1.772258996963501,
      "learning_rate": 9.539641943734016e-06,
      "loss": 0.0734,
      "step": 1120
    },
    {
      "epoch": 0.4862832920099176,
      "grad_norm": 2.9581501483917236,
      "learning_rate": 9.710144927536233e-06,
      "loss": 0.0777,
      "step": 1140
    },
    {
      "epoch": 0.494814577834653,
      "grad_norm": 2.232893943786621,
      "learning_rate": 9.880647911338449e-06,
      "loss": 0.0718,
      "step": 1160
    },
    {
      "epoch": 0.5033458636593884,
      "grad_norm": 2.37386155128479,
      "learning_rate": 9.994313874147083e-06,
      "loss": 0.0761,
      "step": 1180
    },
    {
      "epoch": 0.5118771494841238,
      "grad_norm": 1.5459802150726318,
      "learning_rate": 9.975360121304019e-06,
      "loss": 0.0742,
      "step": 1200
    },
    {
      "epoch": 0.5204084353088592,
      "grad_norm": 1.3021963834762573,
      "learning_rate": 9.956406368460956e-06,
      "loss": 0.0734,
      "step": 1220
    },
    {
      "epoch": 0.5289397211335946,
      "grad_norm": 1.597999930381775,
      "learning_rate": 9.937452615617893e-06,
      "loss": 0.0709,
      "step": 1240
    },
    {
      "epoch": 0.53747100695833,
      "grad_norm": 1.7881083488464355,
      "learning_rate": 9.91849886277483e-06,
      "loss": 0.0758,
      "step": 1260
    },
    {
      "epoch": 0.5460022927830654,
      "grad_norm": 1.5873678922653198,
      "learning_rate": 9.899545109931767e-06,
      "loss": 0.0747,
      "step": 1280
    },
    {
      "epoch": 0.5545335786078008,
      "grad_norm": 1.9387354850769043,
      "learning_rate": 9.880591357088704e-06,
      "loss": 0.0721,
      "step": 1300
    },
    {
      "epoch": 0.5630648644325362,
      "grad_norm": 1.4130702018737793,
      "learning_rate": 9.861637604245642e-06,
      "loss": 0.0717,
      "step": 1320
    },
    {
      "epoch": 0.5715961502572716,
      "grad_norm": 1.8428972959518433,
      "learning_rate": 9.842683851402578e-06,
      "loss": 0.0724,
      "step": 1340
    },
    {
      "epoch": 0.580127436082007,
      "grad_norm": 1.4968459606170654,
      "learning_rate": 9.823730098559515e-06,
      "loss": 0.0758,
      "step": 1360
    },
    {
      "epoch": 0.5886587219067424,
      "grad_norm": 1.2676019668579102,
      "learning_rate": 9.804776345716452e-06,
      "loss": 0.0665,
      "step": 1380
    },
    {
      "epoch": 0.5971900077314778,
      "grad_norm": 1.8817964792251587,
      "learning_rate": 9.78582259287339e-06,
      "loss": 0.0687,
      "step": 1400
    },
    {
      "epoch": 0.6057212935562132,
      "grad_norm": 1.285622000694275,
      "learning_rate": 9.766868840030326e-06,
      "loss": 0.0739,
      "step": 1420
    },
    {
      "epoch": 0.6142525793809486,
      "grad_norm": 1.2413806915283203,
      "learning_rate": 9.747915087187264e-06,
      "loss": 0.0665,
      "step": 1440
    },
    {
      "epoch": 0.622783865205684,
      "grad_norm": 2.1756792068481445,
      "learning_rate": 9.728961334344202e-06,
      "loss": 0.0703,
      "step": 1460
    },
    {
      "epoch": 0.6313151510304194,
      "grad_norm": 1.9868725538253784,
      "learning_rate": 9.710007581501138e-06,
      "loss": 0.0717,
      "step": 1480
    },
    {
      "epoch": 0.6398464368551547,
      "grad_norm": 1.7578349113464355,
      "learning_rate": 9.691053828658074e-06,
      "loss": 0.0756,
      "step": 1500
    },
    {
      "epoch": 0.6483777226798901,
      "grad_norm": 1.6402246952056885,
      "learning_rate": 9.672100075815012e-06,
      "loss": 0.0741,
      "step": 1520
    },
    {
      "epoch": 0.6569090085046255,
      "grad_norm": 1.3414349555969238,
      "learning_rate": 9.653146322971948e-06,
      "loss": 0.0665,
      "step": 1540
    },
    {
      "epoch": 0.6654402943293609,
      "grad_norm": 1.3915817737579346,
      "learning_rate": 9.634192570128886e-06,
      "loss": 0.0679,
      "step": 1560
    },
    {
      "epoch": 0.6739715801540963,
      "grad_norm": 1.5640926361083984,
      "learning_rate": 9.615238817285824e-06,
      "loss": 0.0655,
      "step": 1580
    },
    {
      "epoch": 0.6825028659788317,
      "grad_norm": 1.388024926185608,
      "learning_rate": 9.59628506444276e-06,
      "loss": 0.0667,
      "step": 1600
    },
    {
      "epoch": 0.6910341518035672,
      "grad_norm": 1.719452977180481,
      "learning_rate": 9.577331311599698e-06,
      "loss": 0.0737,
      "step": 1620
    },
    {
      "epoch": 0.6995654376283026,
      "grad_norm": 1.8105440139770508,
      "learning_rate": 9.558377558756634e-06,
      "loss": 0.0691,
      "step": 1640
    },
    {
      "epoch": 0.708096723453038,
      "grad_norm": 1.5640692710876465,
      "learning_rate": 9.539423805913572e-06,
      "loss": 0.0694,
      "step": 1660
    },
    {
      "epoch": 0.7166280092777734,
      "grad_norm": 1.4716624021530151,
      "learning_rate": 9.520470053070508e-06,
      "loss": 0.0694,
      "step": 1680
    },
    {
      "epoch": 0.7251592951025088,
      "grad_norm": 1.2508314847946167,
      "learning_rate": 9.501516300227446e-06,
      "loss": 0.0687,
      "step": 1700
    },
    {
      "epoch": 0.7336905809272442,
      "grad_norm": 1.1716455221176147,
      "learning_rate": 9.482562547384384e-06,
      "loss": 0.0682,
      "step": 1720
    },
    {
      "epoch": 0.7422218667519795,
      "grad_norm": 2.117145538330078,
      "learning_rate": 9.46360879454132e-06,
      "loss": 0.0622,
      "step": 1740
    },
    {
      "epoch": 0.7507531525767149,
      "grad_norm": 1.1250722408294678,
      "learning_rate": 9.444655041698258e-06,
      "loss": 0.0657,
      "step": 1760
    },
    {
      "epoch": 0.7592844384014503,
      "grad_norm": 1.3863455057144165,
      "learning_rate": 9.425701288855194e-06,
      "loss": 0.0653,
      "step": 1780
    },
    {
      "epoch": 0.7678157242261857,
      "grad_norm": 1.1507670879364014,
      "learning_rate": 9.40674753601213e-06,
      "loss": 0.0682,
      "step": 1800
    },
    {
      "epoch": 0.7763470100509211,
      "grad_norm": 1.6055928468704224,
      "learning_rate": 9.387793783169068e-06,
      "loss": 0.0692,
      "step": 1820
    },
    {
      "epoch": 0.7848782958756565,
      "grad_norm": 1.9319509267807007,
      "learning_rate": 9.368840030326006e-06,
      "loss": 0.0622,
      "step": 1840
    },
    {
      "epoch": 0.7934095817003919,
      "grad_norm": 1.2491706609725952,
      "learning_rate": 9.349886277482942e-06,
      "loss": 0.0701,
      "step": 1860
    },
    {
      "epoch": 0.8019408675251273,
      "grad_norm": 1.514551043510437,
      "learning_rate": 9.33093252463988e-06,
      "loss": 0.0653,
      "step": 1880
    },
    {
      "epoch": 0.8104721533498627,
      "grad_norm": 1.1855770349502563,
      "learning_rate": 9.311978771796818e-06,
      "loss": 0.0645,
      "step": 1900
    },
    {
      "epoch": 0.8190034391745981,
      "grad_norm": 1.2600820064544678,
      "learning_rate": 9.293025018953754e-06,
      "loss": 0.0678,
      "step": 1920
    },
    {
      "epoch": 0.8275347249993334,
      "grad_norm": 1.1765464544296265,
      "learning_rate": 9.27407126611069e-06,
      "loss": 0.0681,
      "step": 1940
    },
    {
      "epoch": 0.8360660108240688,
      "grad_norm": 1.7712113857269287,
      "learning_rate": 9.255117513267628e-06,
      "loss": 0.0627,
      "step": 1960
    },
    {
      "epoch": 0.8445972966488043,
      "grad_norm": 1.0009464025497437,
      "learning_rate": 9.236163760424564e-06,
      "loss": 0.0675,
      "step": 1980
    },
    {
      "epoch": 0.8531285824735397,
      "grad_norm": 1.3925752639770508,
      "learning_rate": 9.217210007581502e-06,
      "loss": 0.0671,
      "step": 2000
    },
    {
      "epoch": 0.8616598682982751,
      "grad_norm": 1.869296669960022,
      "learning_rate": 9.19825625473844e-06,
      "loss": 0.0662,
      "step": 2020
    },
    {
      "epoch": 0.8701911541230105,
      "grad_norm": 1.693095326423645,
      "learning_rate": 9.179302501895376e-06,
      "loss": 0.0717,
      "step": 2040
    },
    {
      "epoch": 0.8787224399477459,
      "grad_norm": 1.3099929094314575,
      "learning_rate": 9.160348749052314e-06,
      "loss": 0.0667,
      "step": 2060
    },
    {
      "epoch": 0.8872537257724813,
      "grad_norm": 1.1621946096420288,
      "learning_rate": 9.14139499620925e-06,
      "loss": 0.0705,
      "step": 2080
    },
    {
      "epoch": 0.8957850115972167,
      "grad_norm": 1.091015100479126,
      "learning_rate": 9.122441243366187e-06,
      "loss": 0.0669,
      "step": 2100
    },
    {
      "epoch": 0.9043162974219521,
      "grad_norm": 1.4202077388763428,
      "learning_rate": 9.103487490523124e-06,
      "loss": 0.0671,
      "step": 2120
    },
    {
      "epoch": 0.9128475832466875,
      "grad_norm": 1.7878766059875488,
      "learning_rate": 9.084533737680061e-06,
      "loss": 0.0689,
      "step": 2140
    },
    {
      "epoch": 0.9213788690714229,
      "grad_norm": 0.986436665058136,
      "learning_rate": 9.065579984837e-06,
      "loss": 0.0696,
      "step": 2160
    },
    {
      "epoch": 0.9299101548961582,
      "grad_norm": 1.2721070051193237,
      "learning_rate": 9.046626231993935e-06,
      "loss": 0.0711,
      "step": 2180
    },
    {
      "epoch": 0.9384414407208936,
      "grad_norm": 1.0452007055282593,
      "learning_rate": 9.027672479150873e-06,
      "loss": 0.0671,
      "step": 2200
    },
    {
      "epoch": 0.946972726545629,
      "grad_norm": 1.9123196601867676,
      "learning_rate": 9.00871872630781e-06,
      "loss": 0.065,
      "step": 2220
    },
    {
      "epoch": 0.9555040123703644,
      "grad_norm": 1.080116629600525,
      "learning_rate": 8.989764973464746e-06,
      "loss": 0.0647,
      "step": 2240
    },
    {
      "epoch": 0.9640352981950998,
      "grad_norm": 1.406845211982727,
      "learning_rate": 8.970811220621683e-06,
      "loss": 0.0658,
      "step": 2260
    },
    {
      "epoch": 0.9725665840198352,
      "grad_norm": 1.3563703298568726,
      "learning_rate": 8.951857467778621e-06,
      "loss": 0.0654,
      "step": 2280
    },
    {
      "epoch": 0.9810978698445706,
      "grad_norm": 1.3807165622711182,
      "learning_rate": 8.932903714935557e-06,
      "loss": 0.0633,
      "step": 2300
    },
    {
      "epoch": 0.989629155669306,
      "grad_norm": 1.6621743440628052,
      "learning_rate": 8.913949962092495e-06,
      "loss": 0.0702,
      "step": 2320
    },
    {
      "epoch": 0.9981604414940415,
      "grad_norm": 1.3783202171325684,
      "learning_rate": 8.894996209249433e-06,
      "loss": 0.0649,
      "step": 2340
    },
    {
      "epoch": 1.0063984643685515,
      "grad_norm": 1.2986963987350464,
      "learning_rate": 8.87604245640637e-06,
      "loss": 0.0448,
      "step": 2360
    },
    {
      "epoch": 1.014929750193287,
      "grad_norm": 1.4103795289993286,
      "learning_rate": 8.857088703563305e-06,
      "loss": 0.042,
      "step": 2380
    },
    {
      "epoch": 1.0234610360180223,
      "grad_norm": 1.2898468971252441,
      "learning_rate": 8.838134950720243e-06,
      "loss": 0.0443,
      "step": 2400
    },
    {
      "epoch": 1.0319923218427578,
      "grad_norm": 1.2196269035339355,
      "learning_rate": 8.81918119787718e-06,
      "loss": 0.0376,
      "step": 2420
    },
    {
      "epoch": 1.040523607667493,
      "grad_norm": 1.9303441047668457,
      "learning_rate": 8.800227445034117e-06,
      "loss": 0.0405,
      "step": 2440
    },
    {
      "epoch": 1.0490548934922286,
      "grad_norm": 1.77320396900177,
      "learning_rate": 8.781273692191055e-06,
      "loss": 0.0401,
      "step": 2460
    },
    {
      "epoch": 1.0575861793169639,
      "grad_norm": 1.5941417217254639,
      "learning_rate": 8.762319939347991e-06,
      "loss": 0.0366,
      "step": 2480
    },
    {
      "epoch": 1.0661174651416994,
      "grad_norm": 2.0326857566833496,
      "learning_rate": 8.743366186504929e-06,
      "loss": 0.038,
      "step": 2500
    },
    {
      "epoch": 1.0746487509664346,
      "grad_norm": 1.2373627424240112,
      "learning_rate": 8.724412433661867e-06,
      "loss": 0.0404,
      "step": 2520
    },
    {
      "epoch": 1.0831800367911701,
      "grad_norm": 1.2686012983322144,
      "learning_rate": 8.705458680818803e-06,
      "loss": 0.0364,
      "step": 2540
    },
    {
      "epoch": 1.0917113226159054,
      "grad_norm": 1.3480863571166992,
      "learning_rate": 8.686504927975739e-06,
      "loss": 0.0318,
      "step": 2560
    },
    {
      "epoch": 1.100242608440641,
      "grad_norm": 1.2063369750976562,
      "learning_rate": 8.667551175132677e-06,
      "loss": 0.0404,
      "step": 2580
    },
    {
      "epoch": 1.1087738942653762,
      "grad_norm": 1.0140087604522705,
      "learning_rate": 8.648597422289615e-06,
      "loss": 0.036,
      "step": 2600
    },
    {
      "epoch": 1.1173051800901117,
      "grad_norm": 1.4635465145111084,
      "learning_rate": 8.629643669446551e-06,
      "loss": 0.0336,
      "step": 2620
    },
    {
      "epoch": 1.1258364659148472,
      "grad_norm": 0.9423919320106506,
      "learning_rate": 8.610689916603489e-06,
      "loss": 0.0405,
      "step": 2640
    },
    {
      "epoch": 1.1343677517395825,
      "grad_norm": 1.4716863632202148,
      "learning_rate": 8.591736163760425e-06,
      "loss": 0.0419,
      "step": 2660
    },
    {
      "epoch": 1.142899037564318,
      "grad_norm": 0.49612629413604736,
      "learning_rate": 8.572782410917361e-06,
      "loss": 0.0355,
      "step": 2680
    },
    {
      "epoch": 1.1514303233890533,
      "grad_norm": 1.8832061290740967,
      "learning_rate": 8.553828658074299e-06,
      "loss": 0.0355,
      "step": 2700
    },
    {
      "epoch": 1.1599616092137888,
      "grad_norm": 1.3957444429397583,
      "learning_rate": 8.534874905231237e-06,
      "loss": 0.0432,
      "step": 2720
    },
    {
      "epoch": 1.168492895038524,
      "grad_norm": 1.1432989835739136,
      "learning_rate": 8.515921152388173e-06,
      "loss": 0.0366,
      "step": 2740
    },
    {
      "epoch": 1.1770241808632596,
      "grad_norm": 2.22466778755188,
      "learning_rate": 8.49696739954511e-06,
      "loss": 0.0327,
      "step": 2760
    },
    {
      "epoch": 1.1855554666879948,
      "grad_norm": 1.410293698310852,
      "learning_rate": 8.478013646702049e-06,
      "loss": 0.0385,
      "step": 2780
    },
    {
      "epoch": 1.1940867525127303,
      "grad_norm": 1.1639065742492676,
      "learning_rate": 8.459059893858985e-06,
      "loss": 0.036,
      "step": 2800
    },
    {
      "epoch": 1.2026180383374656,
      "grad_norm": 1.1367725133895874,
      "learning_rate": 8.440106141015921e-06,
      "loss": 0.037,
      "step": 2820
    },
    {
      "epoch": 1.2111493241622011,
      "grad_norm": 1.638221025466919,
      "learning_rate": 8.421152388172859e-06,
      "loss": 0.038,
      "step": 2840
    },
    {
      "epoch": 1.2196806099869364,
      "grad_norm": 1.1819881200790405,
      "learning_rate": 8.402198635329797e-06,
      "loss": 0.0394,
      "step": 2860
    },
    {
      "epoch": 1.228211895811672,
      "grad_norm": 1.4750813245773315,
      "learning_rate": 8.383244882486733e-06,
      "loss": 0.0335,
      "step": 2880
    },
    {
      "epoch": 1.2367431816364072,
      "grad_norm": 1.065888524055481,
      "learning_rate": 8.36429112964367e-06,
      "loss": 0.0462,
      "step": 2900
    },
    {
      "epoch": 1.2452744674611427,
      "grad_norm": 1.7542463541030884,
      "learning_rate": 8.345337376800607e-06,
      "loss": 0.0348,
      "step": 2920
    },
    {
      "epoch": 1.253805753285878,
      "grad_norm": 1.5557069778442383,
      "learning_rate": 8.326383623957544e-06,
      "loss": 0.04,
      "step": 2940
    },
    {
      "epoch": 1.2623370391106135,
      "grad_norm": 1.2366845607757568,
      "learning_rate": 8.307429871114482e-06,
      "loss": 0.0366,
      "step": 2960
    },
    {
      "epoch": 1.270868324935349,
      "grad_norm": 1.399287462234497,
      "learning_rate": 8.288476118271418e-06,
      "loss": 0.0387,
      "step": 2980
    },
    {
      "epoch": 1.2793996107600842,
      "grad_norm": 1.584909439086914,
      "learning_rate": 8.269522365428355e-06,
      "loss": 0.0384,
      "step": 3000
    },
    {
      "epoch": 1.2879308965848195,
      "grad_norm": 1.623761773109436,
      "learning_rate": 8.250568612585292e-06,
      "loss": 0.0405,
      "step": 3020
    },
    {
      "epoch": 1.296462182409555,
      "grad_norm": 1.191117763519287,
      "learning_rate": 8.23161485974223e-06,
      "loss": 0.039,
      "step": 3040
    },
    {
      "epoch": 1.3049934682342905,
      "grad_norm": 2.431979179382324,
      "learning_rate": 8.212661106899166e-06,
      "loss": 0.0366,
      "step": 3060
    },
    {
      "epoch": 1.3135247540590258,
      "grad_norm": 1.4322799444198608,
      "learning_rate": 8.193707354056104e-06,
      "loss": 0.0364,
      "step": 3080
    },
    {
      "epoch": 1.3220560398837613,
      "grad_norm": 2.5069756507873535,
      "learning_rate": 8.174753601213042e-06,
      "loss": 0.0377,
      "step": 3100
    },
    {
      "epoch": 1.3305873257084966,
      "grad_norm": 1.5756449699401855,
      "learning_rate": 8.155799848369977e-06,
      "loss": 0.0403,
      "step": 3120
    },
    {
      "epoch": 1.339118611533232,
      "grad_norm": 1.554504632949829,
      "learning_rate": 8.136846095526914e-06,
      "loss": 0.0372,
      "step": 3140
    },
    {
      "epoch": 1.3476498973579674,
      "grad_norm": 1.3024414777755737,
      "learning_rate": 8.117892342683852e-06,
      "loss": 0.0377,
      "step": 3160
    },
    {
      "epoch": 1.3561811831827029,
      "grad_norm": 1.5967285633087158,
      "learning_rate": 8.098938589840788e-06,
      "loss": 0.0374,
      "step": 3180
    },
    {
      "epoch": 1.3647124690074381,
      "grad_norm": 1.228695273399353,
      "learning_rate": 8.079984836997726e-06,
      "loss": 0.037,
      "step": 3200
    },
    {
      "epoch": 1.3732437548321736,
      "grad_norm": 1.990204095840454,
      "learning_rate": 8.061031084154664e-06,
      "loss": 0.0339,
      "step": 3220
    },
    {
      "epoch": 1.381775040656909,
      "grad_norm": 1.3977327346801758,
      "learning_rate": 8.0420773313116e-06,
      "loss": 0.0396,
      "step": 3240
    },
    {
      "epoch": 1.3903063264816444,
      "grad_norm": 1.8141638040542603,
      "learning_rate": 8.023123578468538e-06,
      "loss": 0.0396,
      "step": 3260
    },
    {
      "epoch": 1.3988376123063797,
      "grad_norm": 1.8831732273101807,
      "learning_rate": 8.004169825625474e-06,
      "loss": 0.0389,
      "step": 3280
    },
    {
      "epoch": 1.4073688981311152,
      "grad_norm": 1.2574933767318726,
      "learning_rate": 7.985216072782412e-06,
      "loss": 0.0377,
      "step": 3300
    },
    {
      "epoch": 1.4159001839558507,
      "grad_norm": 1.2488410472869873,
      "learning_rate": 7.966262319939348e-06,
      "loss": 0.038,
      "step": 3320
    },
    {
      "epoch": 1.424431469780586,
      "grad_norm": 1.5340235233306885,
      "learning_rate": 7.947308567096286e-06,
      "loss": 0.0363,
      "step": 3340
    },
    {
      "epoch": 1.4329627556053213,
      "grad_norm": 1.5770941972732544,
      "learning_rate": 7.928354814253222e-06,
      "loss": 0.0333,
      "step": 3360
    },
    {
      "epoch": 1.4414940414300568,
      "grad_norm": 2.0061604976654053,
      "learning_rate": 7.90940106141016e-06,
      "loss": 0.036,
      "step": 3380
    },
    {
      "epoch": 1.4500253272547923,
      "grad_norm": 2.4136147499084473,
      "learning_rate": 7.890447308567098e-06,
      "loss": 0.0338,
      "step": 3400
    },
    {
      "epoch": 1.4585566130795276,
      "grad_norm": 0.965997040271759,
      "learning_rate": 7.871493555724034e-06,
      "loss": 0.0388,
      "step": 3420
    },
    {
      "epoch": 1.467087898904263,
      "grad_norm": 1.1300678253173828,
      "learning_rate": 7.85253980288097e-06,
      "loss": 0.0399,
      "step": 3440
    },
    {
      "epoch": 1.4756191847289983,
      "grad_norm": 1.4704970121383667,
      "learning_rate": 7.833586050037908e-06,
      "loss": 0.0339,
      "step": 3460
    },
    {
      "epoch": 1.4841504705537338,
      "grad_norm": 1.8651429414749146,
      "learning_rate": 7.814632297194846e-06,
      "loss": 0.038,
      "step": 3480
    },
    {
      "epoch": 1.4926817563784691,
      "grad_norm": 1.6426928043365479,
      "learning_rate": 7.795678544351782e-06,
      "loss": 0.0403,
      "step": 3500
    },
    {
      "epoch": 1.5012130422032046,
      "grad_norm": 1.974236249923706,
      "learning_rate": 7.77672479150872e-06,
      "loss": 0.0355,
      "step": 3520
    },
    {
      "epoch": 1.50974432802794,
      "grad_norm": 1.7053399085998535,
      "learning_rate": 7.757771038665658e-06,
      "loss": 0.0362,
      "step": 3540
    },
    {
      "epoch": 1.5182756138526754,
      "grad_norm": 1.5994757413864136,
      "learning_rate": 7.738817285822594e-06,
      "loss": 0.0365,
      "step": 3560
    },
    {
      "epoch": 1.526806899677411,
      "grad_norm": 1.7015713453292847,
      "learning_rate": 7.71986353297953e-06,
      "loss": 0.0386,
      "step": 3580
    },
    {
      "epoch": 1.5353381855021462,
      "grad_norm": 1.1512885093688965,
      "learning_rate": 7.700909780136468e-06,
      "loss": 0.0412,
      "step": 3600
    },
    {
      "epoch": 1.5438694713268815,
      "grad_norm": 2.095616340637207,
      "learning_rate": 7.681956027293404e-06,
      "loss": 0.0352,
      "step": 3620
    },
    {
      "epoch": 1.552400757151617,
      "grad_norm": 1.878972053527832,
      "learning_rate": 7.663002274450342e-06,
      "loss": 0.0317,
      "step": 3640
    },
    {
      "epoch": 1.5609320429763525,
      "grad_norm": 1.7786049842834473,
      "learning_rate": 7.64404852160728e-06,
      "loss": 0.0357,
      "step": 3660
    },
    {
      "epoch": 1.5694633288010877,
      "grad_norm": 0.8731728196144104,
      "learning_rate": 7.6250947687642166e-06,
      "loss": 0.0331,
      "step": 3680
    },
    {
      "epoch": 1.577994614625823,
      "grad_norm": 1.9207634925842285,
      "learning_rate": 7.6061410159211535e-06,
      "loss": 0.0369,
      "step": 3700
    },
    {
      "epoch": 1.5865259004505585,
      "grad_norm": 1.73280930519104,
      "learning_rate": 7.58718726307809e-06,
      "loss": 0.038,
      "step": 3720
    },
    {
      "epoch": 1.595057186275294,
      "grad_norm": 1.3477373123168945,
      "learning_rate": 7.568233510235027e-06,
      "loss": 0.0373,
      "step": 3740
    },
    {
      "epoch": 1.6035884721000293,
      "grad_norm": 1.5375611782073975,
      "learning_rate": 7.549279757391964e-06,
      "loss": 0.0375,
      "step": 3760
    },
    {
      "epoch": 1.6121197579247646,
      "grad_norm": 1.4638755321502686,
      "learning_rate": 7.5303260045489015e-06,
      "loss": 0.037,
      "step": 3780
    },
    {
      "epoch": 1.6206510437495,
      "grad_norm": 0.8938762545585632,
      "learning_rate": 7.5113722517058385e-06,
      "loss": 0.0383,
      "step": 3800
    },
    {
      "epoch": 1.6291823295742356,
      "grad_norm": 2.276852607727051,
      "learning_rate": 7.4924184988627755e-06,
      "loss": 0.0337,
      "step": 3820
    },
    {
      "epoch": 1.6377136153989709,
      "grad_norm": 2.450070858001709,
      "learning_rate": 7.473464746019713e-06,
      "loss": 0.0339,
      "step": 3840
    },
    {
      "epoch": 1.6462449012237061,
      "grad_norm": 1.5818637609481812,
      "learning_rate": 7.4545109931766495e-06,
      "loss": 0.038,
      "step": 3860
    },
    {
      "epoch": 1.6505105441360741,
      "eval_loss": 2.8245937824249268,
      "eval_runtime": 31.1317,
      "eval_samples_per_second": 64.211,
      "eval_steps_per_second": 2.024,
      "step": 3870
    },
    {
      "epoch": 1.6547761870484416,
      "grad_norm": 0.9348584413528442,
      "learning_rate": 7.4355572403335865e-06,
      "loss": 0.0358,
      "step": 3880
    },
    {
      "epoch": 1.6633074728731772,
      "grad_norm": 2.3523857593536377,
      "learning_rate": 7.4166034874905235e-06,
      "loss": 0.0353,
      "step": 3900
    },
    {
      "epoch": 1.6718387586979127,
      "grad_norm": 1.4343699216842651,
      "learning_rate": 7.3976497346474605e-06,
      "loss": 0.0362,
      "step": 3920
    },
    {
      "epoch": 1.680370044522648,
      "grad_norm": 1.590593695640564,
      "learning_rate": 7.378695981804398e-06,
      "loss": 0.038,
      "step": 3940
    },
    {
      "epoch": 1.6889013303473832,
      "grad_norm": 1.04262113571167,
      "learning_rate": 7.359742228961335e-06,
      "loss": 0.0377,
      "step": 3960
    },
    {
      "epoch": 1.6974326161721187,
      "grad_norm": 1.5683563947677612,
      "learning_rate": 7.340788476118272e-06,
      "loss": 0.0357,
      "step": 3980
    },
    {
      "epoch": 1.7059639019968542,
      "grad_norm": 1.7710851430892944,
      "learning_rate": 7.321834723275209e-06,
      "loss": 0.0387,
      "step": 4000
    },
    {
      "epoch": 1.7144951878215895,
      "grad_norm": 2.1948189735412598,
      "learning_rate": 7.302880970432145e-06,
      "loss": 0.0356,
      "step": 4020
    },
    {
      "epoch": 1.7230264736463248,
      "grad_norm": 1.7899514436721802,
      "learning_rate": 7.283927217589083e-06,
      "loss": 0.0352,
      "step": 4040
    },
    {
      "epoch": 1.7315577594710603,
      "grad_norm": 1.6470146179199219,
      "learning_rate": 7.26497346474602e-06,
      "loss": 0.0325,
      "step": 4060
    },
    {
      "epoch": 1.7400890452957958,
      "grad_norm": 1.4558771848678589,
      "learning_rate": 7.246019711902957e-06,
      "loss": 0.0404,
      "step": 4080
    },
    {
      "epoch": 1.748620331120531,
      "grad_norm": 0.8634148240089417,
      "learning_rate": 7.227065959059894e-06,
      "loss": 0.033,
      "step": 4100
    },
    {
      "epoch": 1.7571516169452663,
      "grad_norm": 2.084841012954712,
      "learning_rate": 7.208112206216832e-06,
      "loss": 0.0398,
      "step": 4120
    },
    {
      "epoch": 1.7656829027700018,
      "grad_norm": 1.475646734237671,
      "learning_rate": 7.189158453373769e-06,
      "loss": 0.0367,
      "step": 4140
    },
    {
      "epoch": 1.7742141885947373,
      "grad_norm": 1.3587642908096313,
      "learning_rate": 7.170204700530705e-06,
      "loss": 0.0388,
      "step": 4160
    },
    {
      "epoch": 1.7827454744194726,
      "grad_norm": 1.742559552192688,
      "learning_rate": 7.151250947687642e-06,
      "loss": 0.0366,
      "step": 4180
    },
    {
      "epoch": 1.791276760244208,
      "grad_norm": 1.3492496013641357,
      "learning_rate": 7.13229719484458e-06,
      "loss": 0.0375,
      "step": 4200
    },
    {
      "epoch": 1.7998080460689434,
      "grad_norm": 1.6216411590576172,
      "learning_rate": 7.113343442001517e-06,
      "loss": 0.0386,
      "step": 4220
    },
    {
      "epoch": 1.808339331893679,
      "grad_norm": 1.6208757162094116,
      "learning_rate": 7.094389689158454e-06,
      "loss": 0.0403,
      "step": 4240
    },
    {
      "epoch": 1.8168706177184144,
      "grad_norm": 1.3530749082565308,
      "learning_rate": 7.075435936315391e-06,
      "loss": 0.0377,
      "step": 4260
    },
    {
      "epoch": 1.8254019035431497,
      "grad_norm": 1.3832131624221802,
      "learning_rate": 7.056482183472329e-06,
      "loss": 0.032,
      "step": 4280
    },
    {
      "epoch": 1.833933189367885,
      "grad_norm": 1.9385995864868164,
      "learning_rate": 7.037528430629266e-06,
      "loss": 0.0346,
      "step": 4300
    },
    {
      "epoch": 1.8424644751926205,
      "grad_norm": 1.5931757688522339,
      "learning_rate": 7.018574677786202e-06,
      "loss": 0.0344,
      "step": 4320
    },
    {
      "epoch": 1.850995761017356,
      "grad_norm": 1.759461522102356,
      "learning_rate": 6.999620924943139e-06,
      "loss": 0.0398,
      "step": 4340
    },
    {
      "epoch": 1.8595270468420912,
      "grad_norm": 1.8243038654327393,
      "learning_rate": 6.980667172100076e-06,
      "loss": 0.0383,
      "step": 4360
    },
    {
      "epoch": 1.8680583326668265,
      "grad_norm": 1.3040982484817505,
      "learning_rate": 6.961713419257014e-06,
      "loss": 0.0368,
      "step": 4380
    },
    {
      "epoch": 1.876589618491562,
      "grad_norm": 0.9030531048774719,
      "learning_rate": 6.942759666413951e-06,
      "loss": 0.0365,
      "step": 4400
    },
    {
      "epoch": 1.8851209043162975,
      "grad_norm": 1.9381898641586304,
      "learning_rate": 6.923805913570888e-06,
      "loss": 0.035,
      "step": 4420
    },
    {
      "epoch": 1.8936521901410328,
      "grad_norm": 1.350717306137085,
      "learning_rate": 6.904852160727825e-06,
      "loss": 0.0369,
      "step": 4440
    },
    {
      "epoch": 1.902183475965768,
      "grad_norm": 15.299674034118652,
      "learning_rate": 6.885898407884761e-06,
      "loss": 0.0316,
      "step": 4460
    },
    {
      "epoch": 1.9107147617905036,
      "grad_norm": 1.3760277032852173,
      "learning_rate": 6.866944655041699e-06,
      "loss": 0.0398,
      "step": 4480
    },
    {
      "epoch": 1.919246047615239,
      "grad_norm": 1.7299038171768188,
      "learning_rate": 6.847990902198636e-06,
      "loss": 0.0366,
      "step": 4500
    },
    {
      "epoch": 1.9277773334399744,
      "grad_norm": 1.8286347389221191,
      "learning_rate": 6.829037149355573e-06,
      "loss": 0.0329,
      "step": 4520
    },
    {
      "epoch": 1.9363086192647097,
      "grad_norm": 1.4507192373275757,
      "learning_rate": 6.8100833965125106e-06,
      "loss": 0.0385,
      "step": 4540
    },
    {
      "epoch": 1.9448399050894452,
      "grad_norm": 1.2302758693695068,
      "learning_rate": 6.7911296436694476e-06,
      "loss": 0.042,
      "step": 4560
    },
    {
      "epoch": 1.9533711909141807,
      "grad_norm": 1.3365907669067383,
      "learning_rate": 6.7721758908263845e-06,
      "loss": 0.0382,
      "step": 4580
    },
    {
      "epoch": 1.9619024767389162,
      "grad_norm": 1.6866707801818848,
      "learning_rate": 6.753222137983321e-06,
      "loss": 0.0396,
      "step": 4600
    },
    {
      "epoch": 1.9704337625636514,
      "grad_norm": 1.4687166213989258,
      "learning_rate": 6.734268385140258e-06,
      "loss": 0.0396,
      "step": 4620
    },
    {
      "epoch": 1.9789650483883867,
      "grad_norm": 1.8439620733261108,
      "learning_rate": 6.7153146322971955e-06,
      "loss": 0.0433,
      "step": 4640
    },
    {
      "epoch": 1.9874963342131222,
      "grad_norm": 1.6135731935501099,
      "learning_rate": 6.6963608794541325e-06,
      "loss": 0.0387,
      "step": 4660
    },
    {
      "epoch": 1.9960276200378577,
      "grad_norm": 1.687312126159668,
      "learning_rate": 6.6774071266110695e-06,
      "loss": 0.0425,
      "step": 4680
    },
    {
      "epoch": 2.0042656429123675,
      "grad_norm": 1.4164739847183228,
      "learning_rate": 6.6584533737680065e-06,
      "loss": 0.0219,
      "step": 4700
    },
    {
      "epoch": 2.012796928737103,
      "grad_norm": 1.090685486793518,
      "learning_rate": 6.639499620924944e-06,
      "loss": 0.0119,
      "step": 4720
    },
    {
      "epoch": 2.0213282145618385,
      "grad_norm": 0.36635822057724,
      "learning_rate": 6.620545868081881e-06,
      "loss": 0.0087,
      "step": 4740
    },
    {
      "epoch": 2.029859500386574,
      "grad_norm": 1.22542405128479,
      "learning_rate": 6.6015921152388175e-06,
      "loss": 0.008,
      "step": 4760
    },
    {
      "epoch": 2.038390786211309,
      "grad_norm": 2.2592661380767822,
      "learning_rate": 6.5826383623957545e-06,
      "loss": 0.0101,
      "step": 4780
    },
    {
      "epoch": 2.0469220720360446,
      "grad_norm": 2.1521353721618652,
      "learning_rate": 6.5636846095526914e-06,
      "loss": 0.0101,
      "step": 4800
    },
    {
      "epoch": 2.05545335786078,
      "grad_norm": 1.1646050214767456,
      "learning_rate": 6.544730856709629e-06,
      "loss": 0.0097,
      "step": 4820
    },
    {
      "epoch": 2.0639846436855156,
      "grad_norm": 1.3564586639404297,
      "learning_rate": 6.525777103866566e-06,
      "loss": 0.011,
      "step": 4840
    },
    {
      "epoch": 2.072515929510251,
      "grad_norm": 2.656953811645508,
      "learning_rate": 6.506823351023503e-06,
      "loss": 0.0107,
      "step": 4860
    },
    {
      "epoch": 2.081047215334986,
      "grad_norm": 1.278976559638977,
      "learning_rate": 6.487869598180441e-06,
      "loss": 0.0104,
      "step": 4880
    },
    {
      "epoch": 2.0895785011597217,
      "grad_norm": 1.7010754346847534,
      "learning_rate": 6.468915845337376e-06,
      "loss": 0.0079,
      "step": 4900
    },
    {
      "epoch": 2.098109786984457,
      "grad_norm": 0.37854596972465515,
      "learning_rate": 6.449962092494314e-06,
      "loss": 0.0112,
      "step": 4920
    },
    {
      "epoch": 2.1066410728091927,
      "grad_norm": 0.5341457724571228,
      "learning_rate": 6.431008339651251e-06,
      "loss": 0.0085,
      "step": 4940
    },
    {
      "epoch": 2.1151723586339277,
      "grad_norm": 1.7518031597137451,
      "learning_rate": 6.412054586808188e-06,
      "loss": 0.0091,
      "step": 4960
    },
    {
      "epoch": 2.123703644458663,
      "grad_norm": 1.051081657409668,
      "learning_rate": 6.393100833965126e-06,
      "loss": 0.0072,
      "step": 4980
    },
    {
      "epoch": 2.1322349302833987,
      "grad_norm": 0.9492483735084534,
      "learning_rate": 6.374147081122063e-06,
      "loss": 0.0121,
      "step": 5000
    },
    {
      "epoch": 2.1407662161081342,
      "grad_norm": 0.4071803390979767,
      "learning_rate": 6.355193328279e-06,
      "loss": 0.0101,
      "step": 5020
    },
    {
      "epoch": 2.1492975019328693,
      "grad_norm": 0.9973840713500977,
      "learning_rate": 6.336239575435937e-06,
      "loss": 0.0097,
      "step": 5040
    },
    {
      "epoch": 2.157828787757605,
      "grad_norm": 1.1420280933380127,
      "learning_rate": 6.317285822592873e-06,
      "loss": 0.0094,
      "step": 5060
    },
    {
      "epoch": 2.1663600735823403,
      "grad_norm": 0.6716717481613159,
      "learning_rate": 6.298332069749811e-06,
      "loss": 0.0117,
      "step": 5080
    },
    {
      "epoch": 2.174891359407076,
      "grad_norm": 2.322901964187622,
      "learning_rate": 6.279378316906748e-06,
      "loss": 0.0108,
      "step": 5100
    },
    {
      "epoch": 2.183422645231811,
      "grad_norm": 0.789028525352478,
      "learning_rate": 6.260424564063685e-06,
      "loss": 0.009,
      "step": 5120
    },
    {
      "epoch": 2.1919539310565463,
      "grad_norm": 0.6338241696357727,
      "learning_rate": 6.241470811220622e-06,
      "loss": 0.0096,
      "step": 5140
    },
    {
      "epoch": 2.200485216881282,
      "grad_norm": 0.6615838408470154,
      "learning_rate": 6.22251705837756e-06,
      "loss": 0.0133,
      "step": 5160
    },
    {
      "epoch": 2.2090165027060173,
      "grad_norm": 1.6907780170440674,
      "learning_rate": 6.203563305534497e-06,
      "loss": 0.0092,
      "step": 5180
    },
    {
      "epoch": 2.2175477885307524,
      "grad_norm": 0.41629061102867126,
      "learning_rate": 6.184609552691433e-06,
      "loss": 0.0095,
      "step": 5200
    },
    {
      "epoch": 2.226079074355488,
      "grad_norm": 0.8542633056640625,
      "learning_rate": 6.16565579984837e-06,
      "loss": 0.0074,
      "step": 5220
    },
    {
      "epoch": 2.2346103601802234,
      "grad_norm": 1.3374923467636108,
      "learning_rate": 6.146702047005308e-06,
      "loss": 0.0103,
      "step": 5240
    },
    {
      "epoch": 2.243141646004959,
      "grad_norm": 2.7343883514404297,
      "learning_rate": 6.127748294162245e-06,
      "loss": 0.0072,
      "step": 5260
    },
    {
      "epoch": 2.2516729318296944,
      "grad_norm": 1.877123475074768,
      "learning_rate": 6.108794541319182e-06,
      "loss": 0.0103,
      "step": 5280
    },
    {
      "epoch": 2.2602042176544295,
      "grad_norm": 2.583341598510742,
      "learning_rate": 6.089840788476119e-06,
      "loss": 0.0096,
      "step": 5300
    },
    {
      "epoch": 2.268735503479165,
      "grad_norm": 1.285857915878296,
      "learning_rate": 6.070887035633057e-06,
      "loss": 0.0103,
      "step": 5320
    },
    {
      "epoch": 2.2772667893039005,
      "grad_norm": 1.2056301832199097,
      "learning_rate": 6.051933282789993e-06,
      "loss": 0.0112,
      "step": 5340
    },
    {
      "epoch": 2.285798075128636,
      "grad_norm": 1.0615535974502563,
      "learning_rate": 6.03297952994693e-06,
      "loss": 0.0098,
      "step": 5360
    },
    {
      "epoch": 2.294329360953371,
      "grad_norm": 0.44282466173171997,
      "learning_rate": 6.014025777103867e-06,
      "loss": 0.0084,
      "step": 5380
    },
    {
      "epoch": 2.3028606467781065,
      "grad_norm": 2.153900384902954,
      "learning_rate": 5.995072024260804e-06,
      "loss": 0.0105,
      "step": 5400
    },
    {
      "epoch": 2.311391932602842,
      "grad_norm": 1.8648799657821655,
      "learning_rate": 5.9761182714177416e-06,
      "loss": 0.0081,
      "step": 5420
    },
    {
      "epoch": 2.3199232184275775,
      "grad_norm": 0.9898807406425476,
      "learning_rate": 5.9571645185746785e-06,
      "loss": 0.0126,
      "step": 5440
    },
    {
      "epoch": 2.3284545042523126,
      "grad_norm": 0.23171253502368927,
      "learning_rate": 5.9382107657316155e-06,
      "loss": 0.0082,
      "step": 5460
    },
    {
      "epoch": 2.336985790077048,
      "grad_norm": 1.4264339208602905,
      "learning_rate": 5.9192570128885525e-06,
      "loss": 0.0098,
      "step": 5480
    },
    {
      "epoch": 2.3455170759017836,
      "grad_norm": 1.2505953311920166,
      "learning_rate": 5.900303260045489e-06,
      "loss": 0.0111,
      "step": 5500
    },
    {
      "epoch": 2.354048361726519,
      "grad_norm": 1.9511337280273438,
      "learning_rate": 5.8813495072024265e-06,
      "loss": 0.0083,
      "step": 5520
    },
    {
      "epoch": 2.3625796475512546,
      "grad_norm": 0.9499781727790833,
      "learning_rate": 5.8623957543593635e-06,
      "loss": 0.0101,
      "step": 5540
    },
    {
      "epoch": 2.3711109333759897,
      "grad_norm": 0.8319998979568481,
      "learning_rate": 5.8434420015163005e-06,
      "loss": 0.0101,
      "step": 5560
    },
    {
      "epoch": 2.379642219200725,
      "grad_norm": 1.357875943183899,
      "learning_rate": 5.824488248673238e-06,
      "loss": 0.0099,
      "step": 5580
    },
    {
      "epoch": 2.3881735050254607,
      "grad_norm": 0.5524486303329468,
      "learning_rate": 5.805534495830175e-06,
      "loss": 0.0091,
      "step": 5600
    },
    {
      "epoch": 2.3967047908501957,
      "grad_norm": 1.1622227430343628,
      "learning_rate": 5.786580742987112e-06,
      "loss": 0.0121,
      "step": 5620
    },
    {
      "epoch": 2.4052360766749312,
      "grad_norm": 1.7766040563583374,
      "learning_rate": 5.7676269901440485e-06,
      "loss": 0.0104,
      "step": 5640
    },
    {
      "epoch": 2.4137673624996667,
      "grad_norm": 2.09213924407959,
      "learning_rate": 5.7486732373009854e-06,
      "loss": 0.01,
      "step": 5660
    },
    {
      "epoch": 2.4222986483244022,
      "grad_norm": 1.4346754550933838,
      "learning_rate": 5.729719484457923e-06,
      "loss": 0.0106,
      "step": 5680
    },
    {
      "epoch": 2.4308299341491377,
      "grad_norm": 1.8288928270339966,
      "learning_rate": 5.71076573161486e-06,
      "loss": 0.0105,
      "step": 5700
    },
    {
      "epoch": 2.439361219973873,
      "grad_norm": 0.6162159442901611,
      "learning_rate": 5.691811978771797e-06,
      "loss": 0.0108,
      "step": 5720
    },
    {
      "epoch": 2.4478925057986083,
      "grad_norm": 1.675646185874939,
      "learning_rate": 5.672858225928734e-06,
      "loss": 0.0127,
      "step": 5740
    },
    {
      "epoch": 2.456423791623344,
      "grad_norm": 1.510240077972412,
      "learning_rate": 5.653904473085672e-06,
      "loss": 0.0105,
      "step": 5760
    },
    {
      "epoch": 2.4649550774480793,
      "grad_norm": 1.4961411952972412,
      "learning_rate": 5.634950720242609e-06,
      "loss": 0.0097,
      "step": 5780
    },
    {
      "epoch": 2.4734863632728143,
      "grad_norm": 0.35774245858192444,
      "learning_rate": 5.615996967399545e-06,
      "loss": 0.0099,
      "step": 5800
    },
    {
      "epoch": 2.48201764909755,
      "grad_norm": 0.8895853757858276,
      "learning_rate": 5.597043214556482e-06,
      "loss": 0.008,
      "step": 5820
    },
    {
      "epoch": 2.4905489349222854,
      "grad_norm": 1.4842896461486816,
      "learning_rate": 5.578089461713419e-06,
      "loss": 0.0093,
      "step": 5840
    },
    {
      "epoch": 2.499080220747021,
      "grad_norm": 1.870625376701355,
      "learning_rate": 5.559135708870357e-06,
      "loss": 0.0115,
      "step": 5860
    },
    {
      "epoch": 2.507611506571756,
      "grad_norm": 0.5701575875282288,
      "learning_rate": 5.540181956027294e-06,
      "loss": 0.0115,
      "step": 5880
    },
    {
      "epoch": 2.5161427923964914,
      "grad_norm": 0.940045952796936,
      "learning_rate": 5.521228203184231e-06,
      "loss": 0.0081,
      "step": 5900
    },
    {
      "epoch": 2.524674078221227,
      "grad_norm": 1.8073272705078125,
      "learning_rate": 5.502274450341169e-06,
      "loss": 0.0131,
      "step": 5920
    },
    {
      "epoch": 2.5332053640459624,
      "grad_norm": 2.1115448474884033,
      "learning_rate": 5.483320697498104e-06,
      "loss": 0.0109,
      "step": 5940
    },
    {
      "epoch": 2.541736649870698,
      "grad_norm": 1.691671371459961,
      "learning_rate": 5.464366944655042e-06,
      "loss": 0.01,
      "step": 5960
    },
    {
      "epoch": 2.550267935695433,
      "grad_norm": 0.7164231538772583,
      "learning_rate": 5.445413191811979e-06,
      "loss": 0.009,
      "step": 5980
    },
    {
      "epoch": 2.5587992215201685,
      "grad_norm": 0.14574386179447174,
      "learning_rate": 5.426459438968916e-06,
      "loss": 0.0071,
      "step": 6000
    },
    {
      "epoch": 2.567330507344904,
      "grad_norm": 0.6741151213645935,
      "learning_rate": 5.407505686125854e-06,
      "loss": 0.0111,
      "step": 6020
    },
    {
      "epoch": 2.575861793169639,
      "grad_norm": 0.25166186690330505,
      "learning_rate": 5.388551933282791e-06,
      "loss": 0.0087,
      "step": 6040
    },
    {
      "epoch": 2.5843930789943745,
      "grad_norm": 0.7264940142631531,
      "learning_rate": 5.369598180439728e-06,
      "loss": 0.0084,
      "step": 6060
    },
    {
      "epoch": 2.59292436481911,
      "grad_norm": 1.4246364831924438,
      "learning_rate": 5.350644427596664e-06,
      "loss": 0.0078,
      "step": 6080
    },
    {
      "epoch": 2.6014556506438455,
      "grad_norm": 1.788421630859375,
      "learning_rate": 5.331690674753601e-06,
      "loss": 0.0105,
      "step": 6100
    },
    {
      "epoch": 2.609986936468581,
      "grad_norm": 0.10624293237924576,
      "learning_rate": 5.312736921910539e-06,
      "loss": 0.0094,
      "step": 6120
    },
    {
      "epoch": 2.618518222293316,
      "grad_norm": 1.0549075603485107,
      "learning_rate": 5.293783169067476e-06,
      "loss": 0.0121,
      "step": 6140
    },
    {
      "epoch": 2.6270495081180516,
      "grad_norm": 1.6213018894195557,
      "learning_rate": 5.274829416224413e-06,
      "loss": 0.0126,
      "step": 6160
    },
    {
      "epoch": 2.635580793942787,
      "grad_norm": 1.0270766019821167,
      "learning_rate": 5.25587566338135e-06,
      "loss": 0.0107,
      "step": 6180
    },
    {
      "epoch": 2.6441120797675226,
      "grad_norm": 1.140350341796875,
      "learning_rate": 5.236921910538288e-06,
      "loss": 0.0125,
      "step": 6200
    },
    {
      "epoch": 2.652643365592258,
      "grad_norm": 1.1595473289489746,
      "learning_rate": 5.217968157695225e-06,
      "loss": 0.0098,
      "step": 6220
    },
    {
      "epoch": 2.661174651416993,
      "grad_norm": 1.3219949007034302,
      "learning_rate": 5.199014404852161e-06,
      "loss": 0.0121,
      "step": 6240
    },
    {
      "epoch": 2.6697059372417287,
      "grad_norm": 1.4347470998764038,
      "learning_rate": 5.180060652009098e-06,
      "loss": 0.0078,
      "step": 6260
    },
    {
      "epoch": 2.678237223066464,
      "grad_norm": 1.3628147840499878,
      "learning_rate": 5.161106899166035e-06,
      "loss": 0.0116,
      "step": 6280
    },
    {
      "epoch": 2.6867685088911992,
      "grad_norm": 4.344017505645752,
      "learning_rate": 5.1421531463229726e-06,
      "loss": 0.0104,
      "step": 6300
    },
    {
      "epoch": 2.6952997947159347,
      "grad_norm": 1.0437442064285278,
      "learning_rate": 5.1231993934799095e-06,
      "loss": 0.0118,
      "step": 6320
    },
    {
      "epoch": 2.7038310805406702,
      "grad_norm": 1.151039481163025,
      "learning_rate": 5.1042456406368465e-06,
      "loss": 0.0117,
      "step": 6340
    },
    {
      "epoch": 2.7123623663654057,
      "grad_norm": 2.535295248031616,
      "learning_rate": 5.085291887793784e-06,
      "loss": 0.0119,
      "step": 6360
    },
    {
      "epoch": 2.7208936521901412,
      "grad_norm": 2.6435887813568115,
      "learning_rate": 5.0663381349507205e-06,
      "loss": 0.0093,
      "step": 6380
    },
    {
      "epoch": 2.7294249380148763,
      "grad_norm": 0.05117196589708328,
      "learning_rate": 5.0473843821076575e-06,
      "loss": 0.0077,
      "step": 6400
    },
    {
      "epoch": 2.737956223839612,
      "grad_norm": 0.24687546491622925,
      "learning_rate": 5.0284306292645945e-06,
      "loss": 0.0101,
      "step": 6420
    },
    {
      "epoch": 2.7464875096643473,
      "grad_norm": 0.9296615123748779,
      "learning_rate": 5.0094768764215315e-06,
      "loss": 0.0125,
      "step": 6440
    },
    {
      "epoch": 2.7550187954890824,
      "grad_norm": 1.5913169384002686,
      "learning_rate": 4.990523123578469e-06,
      "loss": 0.011,
      "step": 6460
    },
    {
      "epoch": 2.763550081313818,
      "grad_norm": 1.401011347770691,
      "learning_rate": 4.971569370735406e-06,
      "loss": 0.0112,
      "step": 6480
    },
    {
      "epoch": 2.7720813671385534,
      "grad_norm": 1.4355113506317139,
      "learning_rate": 4.952615617892343e-06,
      "loss": 0.0119,
      "step": 6500
    },
    {
      "epoch": 2.780612652963289,
      "grad_norm": 1.225611686706543,
      "learning_rate": 4.93366186504928e-06,
      "loss": 0.0083,
      "step": 6520
    },
    {
      "epoch": 2.7891439387880244,
      "grad_norm": 0.9704187512397766,
      "learning_rate": 4.914708112206217e-06,
      "loss": 0.008,
      "step": 6540
    },
    {
      "epoch": 2.7976752246127594,
      "grad_norm": 1.486378788948059,
      "learning_rate": 4.895754359363154e-06,
      "loss": 0.013,
      "step": 6560
    },
    {
      "epoch": 2.806206510437495,
      "grad_norm": 1.7279636859893799,
      "learning_rate": 4.876800606520091e-06,
      "loss": 0.0092,
      "step": 6580
    },
    {
      "epoch": 2.8147377962622304,
      "grad_norm": 0.18088912963867188,
      "learning_rate": 4.857846853677028e-06,
      "loss": 0.0113,
      "step": 6600
    },
    {
      "epoch": 2.823269082086966,
      "grad_norm": 0.42771095037460327,
      "learning_rate": 4.838893100833966e-06,
      "loss": 0.0117,
      "step": 6620
    },
    {
      "epoch": 2.8318003679117014,
      "grad_norm": 0.6307993531227112,
      "learning_rate": 4.819939347990902e-06,
      "loss": 0.0117,
      "step": 6640
    },
    {
      "epoch": 2.8403316537364365,
      "grad_norm": 0.6177353262901306,
      "learning_rate": 4.800985595147839e-06,
      "loss": 0.0104,
      "step": 6660
    },
    {
      "epoch": 2.848862939561172,
      "grad_norm": 1.5148552656173706,
      "learning_rate": 4.782031842304777e-06,
      "loss": 0.009,
      "step": 6680
    },
    {
      "epoch": 2.8573942253859075,
      "grad_norm": 0.19977141916751862,
      "learning_rate": 4.763078089461714e-06,
      "loss": 0.0132,
      "step": 6700
    },
    {
      "epoch": 2.8659255112106425,
      "grad_norm": 1.3229126930236816,
      "learning_rate": 4.744124336618651e-06,
      "loss": 0.0101,
      "step": 6720
    },
    {
      "epoch": 2.874456797035378,
      "grad_norm": 0.4895506501197815,
      "learning_rate": 4.725170583775588e-06,
      "loss": 0.0131,
      "step": 6740
    },
    {
      "epoch": 2.8829880828601135,
      "grad_norm": 0.5447596311569214,
      "learning_rate": 4.706216830932525e-06,
      "loss": 0.0104,
      "step": 6760
    },
    {
      "epoch": 2.891519368684849,
      "grad_norm": 1.3584192991256714,
      "learning_rate": 4.687263078089462e-06,
      "loss": 0.0095,
      "step": 6780
    },
    {
      "epoch": 2.9000506545095845,
      "grad_norm": 1.1620630025863647,
      "learning_rate": 4.668309325246399e-06,
      "loss": 0.0093,
      "step": 6800
    },
    {
      "epoch": 2.9085819403343196,
      "grad_norm": 1.1640702486038208,
      "learning_rate": 4.649355572403336e-06,
      "loss": 0.0098,
      "step": 6820
    },
    {
      "epoch": 2.917113226159055,
      "grad_norm": 1.6324512958526611,
      "learning_rate": 4.630401819560274e-06,
      "loss": 0.011,
      "step": 6840
    },
    {
      "epoch": 2.9256445119837906,
      "grad_norm": 0.8895303010940552,
      "learning_rate": 4.61144806671721e-06,
      "loss": 0.0132,
      "step": 6860
    },
    {
      "epoch": 2.934175797808526,
      "grad_norm": 1.5485059022903442,
      "learning_rate": 4.592494313874147e-06,
      "loss": 0.0112,
      "step": 6880
    },
    {
      "epoch": 2.9427070836332616,
      "grad_norm": 1.2173460721969604,
      "learning_rate": 4.573540561031085e-06,
      "loss": 0.0104,
      "step": 6900
    },
    {
      "epoch": 2.9512383694579967,
      "grad_norm": 2.0417559146881104,
      "learning_rate": 4.554586808188022e-06,
      "loss": 0.0098,
      "step": 6920
    },
    {
      "epoch": 2.959769655282732,
      "grad_norm": 0.8544695973396301,
      "learning_rate": 4.535633055344959e-06,
      "loss": 0.0116,
      "step": 6940
    },
    {
      "epoch": 2.9683009411074677,
      "grad_norm": 0.9825555682182312,
      "learning_rate": 4.516679302501896e-06,
      "loss": 0.011,
      "step": 6960
    },
    {
      "epoch": 2.9768322269322027,
      "grad_norm": 0.954212486743927,
      "learning_rate": 4.497725549658833e-06,
      "loss": 0.0095,
      "step": 6980
    },
    {
      "epoch": 2.9853635127569382,
      "grad_norm": 0.9126512408256531,
      "learning_rate": 4.47877179681577e-06,
      "loss": 0.0083,
      "step": 7000
    },
    {
      "epoch": 2.9938947985816737,
      "grad_norm": 2.5002565383911133,
      "learning_rate": 4.459818043972707e-06,
      "loss": 0.0084,
      "step": 7020
    },
    {
      "epoch": 3.002132821456184,
      "grad_norm": 0.34647369384765625,
      "learning_rate": 4.440864291129644e-06,
      "loss": 0.0099,
      "step": 7040
    },
    {
      "epoch": 3.010664107280919,
      "grad_norm": 0.9623392820358276,
      "learning_rate": 4.421910538286582e-06,
      "loss": 0.0038,
      "step": 7060
    },
    {
      "epoch": 3.0191953931056545,
      "grad_norm": 1.0727887153625488,
      "learning_rate": 4.402956785443518e-06,
      "loss": 0.0044,
      "step": 7080
    },
    {
      "epoch": 3.02772667893039,
      "grad_norm": 0.07575680315494537,
      "learning_rate": 4.384003032600455e-06,
      "loss": 0.0031,
      "step": 7100
    },
    {
      "epoch": 3.0362579647551255,
      "grad_norm": 0.2123115062713623,
      "learning_rate": 4.3650492797573926e-06,
      "loss": 0.0029,
      "step": 7120
    },
    {
      "epoch": 3.044789250579861,
      "grad_norm": 0.8604742884635925,
      "learning_rate": 4.3460955269143296e-06,
      "loss": 0.0027,
      "step": 7140
    },
    {
      "epoch": 3.053320536404596,
      "grad_norm": 0.1815633326768875,
      "learning_rate": 4.3271417740712666e-06,
      "loss": 0.0012,
      "step": 7160
    },
    {
      "epoch": 3.0618518222293316,
      "grad_norm": 0.10232730209827423,
      "learning_rate": 4.3081880212282035e-06,
      "loss": 0.0025,
      "step": 7180
    },
    {
      "epoch": 3.070383108054067,
      "grad_norm": 0.0489652194082737,
      "learning_rate": 4.2892342683851405e-06,
      "loss": 0.0043,
      "step": 7200
    },
    {
      "epoch": 3.0789143938788026,
      "grad_norm": 0.22823026776313782,
      "learning_rate": 4.2702805155420775e-06,
      "loss": 0.0025,
      "step": 7220
    },
    {
      "epoch": 3.0874456797035377,
      "grad_norm": 0.8362800478935242,
      "learning_rate": 4.2513267626990145e-06,
      "loss": 0.0044,
      "step": 7240
    },
    {
      "epoch": 3.095976965528273,
      "grad_norm": 0.561826765537262,
      "learning_rate": 4.2323730098559515e-06,
      "loss": 0.0049,
      "step": 7260
    },
    {
      "epoch": 3.1045082513530087,
      "grad_norm": 0.22158382833003998,
      "learning_rate": 4.213419257012889e-06,
      "loss": 0.0021,
      "step": 7280
    },
    {
      "epoch": 3.113039537177744,
      "grad_norm": 0.067241370677948,
      "learning_rate": 4.194465504169826e-06,
      "loss": 0.0026,
      "step": 7300
    },
    {
      "epoch": 3.1215708230024792,
      "grad_norm": 0.8698502779006958,
      "learning_rate": 4.1755117513267625e-06,
      "loss": 0.0026,
      "step": 7320
    },
    {
      "epoch": 3.1301021088272147,
      "grad_norm": 0.15161292254924774,
      "learning_rate": 4.1565579984837e-06,
      "loss": 0.0031,
      "step": 7340
    },
    {
      "epoch": 3.1386333946519502,
      "grad_norm": 1.1038371324539185,
      "learning_rate": 4.137604245640637e-06,
      "loss": 0.0035,
      "step": 7360
    },
    {
      "epoch": 3.1471646804766857,
      "grad_norm": 0.021679047495126724,
      "learning_rate": 4.118650492797574e-06,
      "loss": 0.0031,
      "step": 7380
    },
    {
      "epoch": 3.155695966301421,
      "grad_norm": 1.192242980003357,
      "learning_rate": 4.099696739954511e-06,
      "loss": 0.0032,
      "step": 7400
    },
    {
      "epoch": 3.1642272521261563,
      "grad_norm": 0.0809570923447609,
      "learning_rate": 4.080742987111448e-06,
      "loss": 0.003,
      "step": 7420
    },
    {
      "epoch": 3.172758537950892,
      "grad_norm": 0.5930222868919373,
      "learning_rate": 4.061789234268385e-06,
      "loss": 0.0032,
      "step": 7440
    },
    {
      "epoch": 3.1812898237756273,
      "grad_norm": 2.9435431957244873,
      "learning_rate": 4.042835481425322e-06,
      "loss": 0.0032,
      "step": 7460
    },
    {
      "epoch": 3.189821109600363,
      "grad_norm": 0.05303821712732315,
      "learning_rate": 4.023881728582259e-06,
      "loss": 0.0043,
      "step": 7480
    },
    {
      "epoch": 3.198352395425098,
      "grad_norm": 0.04530007392168045,
      "learning_rate": 4.004927975739197e-06,
      "loss": 0.0037,
      "step": 7500
    },
    {
      "epoch": 3.2068836812498334,
      "grad_norm": 0.13108056783676147,
      "learning_rate": 3.985974222896134e-06,
      "loss": 0.0043,
      "step": 7520
    },
    {
      "epoch": 3.215414967074569,
      "grad_norm": 0.9168871641159058,
      "learning_rate": 3.967020470053071e-06,
      "loss": 0.004,
      "step": 7540
    },
    {
      "epoch": 3.2239462528993044,
      "grad_norm": 0.10340914875268936,
      "learning_rate": 3.948066717210008e-06,
      "loss": 0.0032,
      "step": 7560
    },
    {
      "epoch": 3.2324775387240394,
      "grad_norm": 0.034129731357097626,
      "learning_rate": 3.929112964366945e-06,
      "loss": 0.0022,
      "step": 7580
    },
    {
      "epoch": 3.241008824548775,
      "grad_norm": 0.07525105774402618,
      "learning_rate": 3.910159211523882e-06,
      "loss": 0.002,
      "step": 7600
    },
    {
      "epoch": 3.2495401103735104,
      "grad_norm": 0.3244667053222656,
      "learning_rate": 3.891205458680819e-06,
      "loss": 0.0029,
      "step": 7620
    },
    {
      "epoch": 3.258071396198246,
      "grad_norm": 1.8554129600524902,
      "learning_rate": 3.872251705837756e-06,
      "loss": 0.0014,
      "step": 7640
    },
    {
      "epoch": 3.266602682022981,
      "grad_norm": 0.2312292456626892,
      "learning_rate": 3.853297952994693e-06,
      "loss": 0.002,
      "step": 7660
    },
    {
      "epoch": 3.2751339678477165,
      "grad_norm": 0.24867121875286102,
      "learning_rate": 3.83434420015163e-06,
      "loss": 0.0063,
      "step": 7680
    },
    {
      "epoch": 3.283665253672452,
      "grad_norm": 0.0984157845377922,
      "learning_rate": 3.815390447308567e-06,
      "loss": 0.0023,
      "step": 7700
    },
    {
      "epoch": 3.2921965394971875,
      "grad_norm": 0.12084456533193588,
      "learning_rate": 3.7964366944655044e-06,
      "loss": 0.003,
      "step": 7720
    },
    {
      "epoch": 3.3007278253219225,
      "grad_norm": 0.8528248071670532,
      "learning_rate": 3.777482941622442e-06,
      "loss": 0.0031,
      "step": 7740
    },
    {
      "epoch": 3.3007278253219225,
      "eval_loss": 4.151798725128174,
      "eval_runtime": 31.1359,
      "eval_samples_per_second": 64.202,
      "eval_steps_per_second": 2.023,
      "step": 7740
    },
    {
      "epoch": 3.309259111146658,
      "grad_norm": 0.2645531892776489,
      "learning_rate": 3.7585291887793784e-06,
      "loss": 0.0024,
      "step": 7760
    },
    {
      "epoch": 3.3177903969713936,
      "grad_norm": 0.4085790812969208,
      "learning_rate": 3.739575435936316e-06,
      "loss": 0.0021,
      "step": 7780
    },
    {
      "epoch": 3.326321682796129,
      "grad_norm": 0.6981127262115479,
      "learning_rate": 3.720621683093253e-06,
      "loss": 0.0042,
      "step": 7800
    },
    {
      "epoch": 3.334852968620864,
      "grad_norm": 1.337417483329773,
      "learning_rate": 3.7016679302501902e-06,
      "loss": 0.0042,
      "step": 7820
    },
    {
      "epoch": 3.3433842544455996,
      "grad_norm": 0.7960372567176819,
      "learning_rate": 3.682714177407127e-06,
      "loss": 0.0034,
      "step": 7840
    },
    {
      "epoch": 3.351915540270335,
      "grad_norm": 4.888955593109131,
      "learning_rate": 3.663760424564064e-06,
      "loss": 0.004,
      "step": 7860
    },
    {
      "epoch": 3.3604468260950706,
      "grad_norm": 0.09808972477912903,
      "learning_rate": 3.644806671721001e-06,
      "loss": 0.0044,
      "step": 7880
    },
    {
      "epoch": 3.368978111919806,
      "grad_norm": 0.024344004690647125,
      "learning_rate": 3.6258529188779378e-06,
      "loss": 0.0026,
      "step": 7900
    },
    {
      "epoch": 3.377509397744541,
      "grad_norm": 0.5522525310516357,
      "learning_rate": 3.606899166034875e-06,
      "loss": 0.0027,
      "step": 7920
    },
    {
      "epoch": 3.3860406835692767,
      "grad_norm": 1.2779390811920166,
      "learning_rate": 3.587945413191812e-06,
      "loss": 0.003,
      "step": 7940
    },
    {
      "epoch": 3.394571969394012,
      "grad_norm": 6.132818222045898,
      "learning_rate": 3.5689916603487496e-06,
      "loss": 0.0026,
      "step": 7960
    },
    {
      "epoch": 3.4031032552187477,
      "grad_norm": 1.7108488082885742,
      "learning_rate": 3.550037907505686e-06,
      "loss": 0.0024,
      "step": 7980
    },
    {
      "epoch": 3.4116345410434827,
      "grad_norm": 0.08271051943302155,
      "learning_rate": 3.5310841546626236e-06,
      "loss": 0.002,
      "step": 8000
    },
    {
      "epoch": 3.4201658268682182,
      "grad_norm": 0.08228762447834015,
      "learning_rate": 3.5121304018195606e-06,
      "loss": 0.0025,
      "step": 8020
    },
    {
      "epoch": 3.4286971126929537,
      "grad_norm": 0.21279829740524292,
      "learning_rate": 3.493176648976498e-06,
      "loss": 0.0049,
      "step": 8040
    },
    {
      "epoch": 3.4372283985176892,
      "grad_norm": 0.416486918926239,
      "learning_rate": 3.4742228961334345e-06,
      "loss": 0.0019,
      "step": 8060
    },
    {
      "epoch": 3.4457596843424243,
      "grad_norm": 0.4104134738445282,
      "learning_rate": 3.455269143290372e-06,
      "loss": 0.0013,
      "step": 8080
    },
    {
      "epoch": 3.45429097016716,
      "grad_norm": 0.13263651728630066,
      "learning_rate": 3.436315390447309e-06,
      "loss": 0.0018,
      "step": 8100
    },
    {
      "epoch": 3.4628222559918953,
      "grad_norm": 0.8483461141586304,
      "learning_rate": 3.4173616376042455e-06,
      "loss": 0.0042,
      "step": 8120
    },
    {
      "epoch": 3.471353541816631,
      "grad_norm": 2.8146026134490967,
      "learning_rate": 3.398407884761183e-06,
      "loss": 0.0047,
      "step": 8140
    },
    {
      "epoch": 3.4798848276413663,
      "grad_norm": 0.7375776171684265,
      "learning_rate": 3.37945413191812e-06,
      "loss": 0.0031,
      "step": 8160
    },
    {
      "epoch": 3.4884161134661014,
      "grad_norm": 0.04027794301509857,
      "learning_rate": 3.3605003790750573e-06,
      "loss": 0.0043,
      "step": 8180
    },
    {
      "epoch": 3.496947399290837,
      "grad_norm": 0.039342425763607025,
      "learning_rate": 3.341546626231994e-06,
      "loss": 0.0026,
      "step": 8200
    },
    {
      "epoch": 3.5054786851155724,
      "grad_norm": 0.04005169868469238,
      "learning_rate": 3.3225928733889313e-06,
      "loss": 0.0029,
      "step": 8220
    },
    {
      "epoch": 3.5140099709403074,
      "grad_norm": 0.2026693969964981,
      "learning_rate": 3.3036391205458683e-06,
      "loss": 0.0044,
      "step": 8240
    },
    {
      "epoch": 3.522541256765043,
      "grad_norm": 0.028166476637125015,
      "learning_rate": 3.2846853677028057e-06,
      "loss": 0.0036,
      "step": 8260
    },
    {
      "epoch": 3.5310725425897784,
      "grad_norm": 0.018797753378748894,
      "learning_rate": 3.2657316148597423e-06,
      "loss": 0.0019,
      "step": 8280
    },
    {
      "epoch": 3.539603828414514,
      "grad_norm": 0.40005919337272644,
      "learning_rate": 3.2467778620166797e-06,
      "loss": 0.0036,
      "step": 8300
    },
    {
      "epoch": 3.5481351142392494,
      "grad_norm": 0.09193804115056992,
      "learning_rate": 3.2278241091736167e-06,
      "loss": 0.0025,
      "step": 8320
    },
    {
      "epoch": 3.5566664000639845,
      "grad_norm": 0.6374313235282898,
      "learning_rate": 3.2088703563305533e-06,
      "loss": 0.0012,
      "step": 8340
    },
    {
      "epoch": 3.56519768588872,
      "grad_norm": 0.19366046786308289,
      "learning_rate": 3.1899166034874907e-06,
      "loss": 0.0025,
      "step": 8360
    },
    {
      "epoch": 3.5737289717134555,
      "grad_norm": 2.486030101776123,
      "learning_rate": 3.1709628506444277e-06,
      "loss": 0.0033,
      "step": 8380
    },
    {
      "epoch": 3.582260257538191,
      "grad_norm": 0.09278996288776398,
      "learning_rate": 3.152009097801365e-06,
      "loss": 0.0024,
      "step": 8400
    },
    {
      "epoch": 3.5907915433629265,
      "grad_norm": 0.2132110744714737,
      "learning_rate": 3.1330553449583017e-06,
      "loss": 0.0045,
      "step": 8420
    },
    {
      "epoch": 3.5993228291876616,
      "grad_norm": 3.1238815784454346,
      "learning_rate": 3.114101592115239e-06,
      "loss": 0.002,
      "step": 8440
    },
    {
      "epoch": 3.607854115012397,
      "grad_norm": 0.039155635982751846,
      "learning_rate": 3.095147839272176e-06,
      "loss": 0.0021,
      "step": 8460
    },
    {
      "epoch": 3.6163854008371326,
      "grad_norm": 0.7710346579551697,
      "learning_rate": 3.0761940864291135e-06,
      "loss": 0.0013,
      "step": 8480
    },
    {
      "epoch": 3.6249166866618676,
      "grad_norm": 0.08665268123149872,
      "learning_rate": 3.05724033358605e-06,
      "loss": 0.0036,
      "step": 8500
    },
    {
      "epoch": 3.633447972486603,
      "grad_norm": 0.04275016859173775,
      "learning_rate": 3.0382865807429875e-06,
      "loss": 0.0041,
      "step": 8520
    },
    {
      "epoch": 3.6419792583113386,
      "grad_norm": 0.03928758203983307,
      "learning_rate": 3.0193328278999244e-06,
      "loss": 0.0017,
      "step": 8540
    },
    {
      "epoch": 3.650510544136074,
      "grad_norm": 0.08351525664329529,
      "learning_rate": 3.000379075056862e-06,
      "loss": 0.0023,
      "step": 8560
    },
    {
      "epoch": 3.6590418299608096,
      "grad_norm": 0.43758830428123474,
      "learning_rate": 2.9814253222137984e-06,
      "loss": 0.0033,
      "step": 8580
    },
    {
      "epoch": 3.6675731157855447,
      "grad_norm": 0.35547274351119995,
      "learning_rate": 2.962471569370736e-06,
      "loss": 0.0031,
      "step": 8600
    },
    {
      "epoch": 3.67610440161028,
      "grad_norm": 0.3207659125328064,
      "learning_rate": 2.943517816527673e-06,
      "loss": 0.0034,
      "step": 8620
    },
    {
      "epoch": 3.6846356874350157,
      "grad_norm": 0.14399904012680054,
      "learning_rate": 2.9245640636846094e-06,
      "loss": 0.0031,
      "step": 8640
    },
    {
      "epoch": 3.6931669732597507,
      "grad_norm": 0.16562822461128235,
      "learning_rate": 2.905610310841547e-06,
      "loss": 0.0023,
      "step": 8660
    },
    {
      "epoch": 3.7016982590844862,
      "grad_norm": 0.24492059648036957,
      "learning_rate": 2.886656557998484e-06,
      "loss": 0.0015,
      "step": 8680
    },
    {
      "epoch": 3.7102295449092217,
      "grad_norm": 0.1925899088382721,
      "learning_rate": 2.8677028051554212e-06,
      "loss": 0.0033,
      "step": 8700
    },
    {
      "epoch": 3.7187608307339572,
      "grad_norm": 1.0039784908294678,
      "learning_rate": 2.848749052312358e-06,
      "loss": 0.0048,
      "step": 8720
    },
    {
      "epoch": 3.7272921165586927,
      "grad_norm": 0.11641588807106018,
      "learning_rate": 2.829795299469295e-06,
      "loss": 0.0027,
      "step": 8740
    },
    {
      "epoch": 3.735823402383428,
      "grad_norm": 1.552340030670166,
      "learning_rate": 2.810841546626232e-06,
      "loss": 0.0038,
      "step": 8760
    },
    {
      "epoch": 3.7443546882081633,
      "grad_norm": 0.11755397915840149,
      "learning_rate": 2.7918877937831696e-06,
      "loss": 0.0021,
      "step": 8780
    },
    {
      "epoch": 3.752885974032899,
      "grad_norm": 0.06779001653194427,
      "learning_rate": 2.772934040940106e-06,
      "loss": 0.0045,
      "step": 8800
    },
    {
      "epoch": 3.7614172598576343,
      "grad_norm": 0.9942015409469604,
      "learning_rate": 2.7539802880970436e-06,
      "loss": 0.0034,
      "step": 8820
    },
    {
      "epoch": 3.76994854568237,
      "grad_norm": 0.11363588273525238,
      "learning_rate": 2.7350265352539806e-06,
      "loss": 0.0025,
      "step": 8840
    },
    {
      "epoch": 3.778479831507105,
      "grad_norm": 1.0309412479400635,
      "learning_rate": 2.716072782410917e-06,
      "loss": 0.0021,
      "step": 8860
    },
    {
      "epoch": 3.7870111173318404,
      "grad_norm": 1.6397391557693481,
      "learning_rate": 2.6971190295678546e-06,
      "loss": 0.0036,
      "step": 8880
    },
    {
      "epoch": 3.795542403156576,
      "grad_norm": 4.052779674530029,
      "learning_rate": 2.6781652767247916e-06,
      "loss": 0.0034,
      "step": 8900
    },
    {
      "epoch": 3.804073688981311,
      "grad_norm": 1.3127354383468628,
      "learning_rate": 2.659211523881729e-06,
      "loss": 0.0026,
      "step": 8920
    },
    {
      "epoch": 3.8126049748060464,
      "grad_norm": 0.9733906388282776,
      "learning_rate": 2.6402577710386655e-06,
      "loss": 0.0039,
      "step": 8940
    },
    {
      "epoch": 3.821136260630782,
      "grad_norm": 0.22169658541679382,
      "learning_rate": 2.621304018195603e-06,
      "loss": 0.0032,
      "step": 8960
    },
    {
      "epoch": 3.8296675464555174,
      "grad_norm": 0.06241186708211899,
      "learning_rate": 2.60235026535254e-06,
      "loss": 0.002,
      "step": 8980
    },
    {
      "epoch": 3.838198832280253,
      "grad_norm": 0.3109017014503479,
      "learning_rate": 2.5833965125094774e-06,
      "loss": 0.0037,
      "step": 9000
    },
    {
      "epoch": 3.846730118104988,
      "grad_norm": 2.047908306121826,
      "learning_rate": 2.564442759666414e-06,
      "loss": 0.0024,
      "step": 9020
    },
    {
      "epoch": 3.8552614039297235,
      "grad_norm": 0.8636813759803772,
      "learning_rate": 2.5454890068233513e-06,
      "loss": 0.0026,
      "step": 9040
    },
    {
      "epoch": 3.863792689754459,
      "grad_norm": 1.536450743675232,
      "learning_rate": 2.5265352539802883e-06,
      "loss": 0.0027,
      "step": 9060
    },
    {
      "epoch": 3.872323975579194,
      "grad_norm": 1.5373494625091553,
      "learning_rate": 2.5075815011372257e-06,
      "loss": 0.0026,
      "step": 9080
    },
    {
      "epoch": 3.88085526140393,
      "grad_norm": 1.4031990766525269,
      "learning_rate": 2.4886277482941623e-06,
      "loss": 0.0046,
      "step": 9100
    },
    {
      "epoch": 3.889386547228665,
      "grad_norm": 0.9179314970970154,
      "learning_rate": 2.4696739954510997e-06,
      "loss": 0.004,
      "step": 9120
    },
    {
      "epoch": 3.8979178330534006,
      "grad_norm": 0.06218860298395157,
      "learning_rate": 2.4507202426080363e-06,
      "loss": 0.0023,
      "step": 9140
    },
    {
      "epoch": 3.906449118878136,
      "grad_norm": 1.6940932273864746,
      "learning_rate": 2.4317664897649737e-06,
      "loss": 0.0039,
      "step": 9160
    },
    {
      "epoch": 3.914980404702871,
      "grad_norm": 1.4627866744995117,
      "learning_rate": 2.4128127369219107e-06,
      "loss": 0.0025,
      "step": 9180
    },
    {
      "epoch": 3.9235116905276066,
      "grad_norm": 0.02235567569732666,
      "learning_rate": 2.3938589840788477e-06,
      "loss": 0.004,
      "step": 9200
    },
    {
      "epoch": 3.932042976352342,
      "grad_norm": 1.1782233715057373,
      "learning_rate": 2.3749052312357847e-06,
      "loss": 0.0026,
      "step": 9220
    },
    {
      "epoch": 3.9405742621770776,
      "grad_norm": 0.03918863832950592,
      "learning_rate": 2.355951478392722e-06,
      "loss": 0.0029,
      "step": 9240
    },
    {
      "epoch": 3.949105548001813,
      "grad_norm": 2.514486789703369,
      "learning_rate": 2.336997725549659e-06,
      "loss": 0.0025,
      "step": 9260
    },
    {
      "epoch": 3.957636833826548,
      "grad_norm": 0.5067291855812073,
      "learning_rate": 2.318043972706596e-06,
      "loss": 0.0042,
      "step": 9280
    },
    {
      "epoch": 3.9661681196512837,
      "grad_norm": 0.39393165707588196,
      "learning_rate": 2.299090219863533e-06,
      "loss": 0.0013,
      "step": 9300
    },
    {
      "epoch": 3.974699405476019,
      "grad_norm": 1.2272114753723145,
      "learning_rate": 2.2801364670204705e-06,
      "loss": 0.0026,
      "step": 9320
    },
    {
      "epoch": 3.9832306913007542,
      "grad_norm": 1.3414461612701416,
      "learning_rate": 2.2611827141774075e-06,
      "loss": 0.0035,
      "step": 9340
    },
    {
      "epoch": 3.9917619771254897,
      "grad_norm": 0.923495352268219,
      "learning_rate": 2.242228961334344e-06,
      "loss": 0.0029,
      "step": 9360
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.8160938620567322,
      "learning_rate": 2.2232752084912815e-06,
      "loss": 0.0028,
      "step": 9380
    },
    {
      "epoch": 4.008531285824735,
      "grad_norm": 0.07927578687667847,
      "learning_rate": 2.2043214556482185e-06,
      "loss": 0.0011,
      "step": 9400
    },
    {
      "epoch": 4.017062571649471,
      "grad_norm": 0.013283725827932358,
      "learning_rate": 2.1853677028051554e-06,
      "loss": 0.0011,
      "step": 9420
    },
    {
      "epoch": 4.025593857474206,
      "grad_norm": 0.03220760449767113,
      "learning_rate": 2.1664139499620924e-06,
      "loss": 0.0019,
      "step": 9440
    },
    {
      "epoch": 4.034125143298942,
      "grad_norm": 0.05171350762248039,
      "learning_rate": 2.14746019711903e-06,
      "loss": 0.0011,
      "step": 9460
    },
    {
      "epoch": 4.042656429123677,
      "grad_norm": 0.012312555685639381,
      "learning_rate": 2.128506444275967e-06,
      "loss": 0.0006,
      "step": 9480
    },
    {
      "epoch": 4.051187714948412,
      "grad_norm": 0.04316498339176178,
      "learning_rate": 2.109552691432904e-06,
      "loss": 0.0005,
      "step": 9500
    },
    {
      "epoch": 4.059719000773148,
      "grad_norm": 0.03560129180550575,
      "learning_rate": 2.090598938589841e-06,
      "loss": 0.0017,
      "step": 9520
    },
    {
      "epoch": 4.068250286597883,
      "grad_norm": 0.022697078064084053,
      "learning_rate": 2.0716451857467782e-06,
      "loss": 0.0007,
      "step": 9540
    },
    {
      "epoch": 4.076781572422618,
      "grad_norm": 0.0041651553474366665,
      "learning_rate": 2.0526914329037152e-06,
      "loss": 0.0006,
      "step": 9560
    },
    {
      "epoch": 4.085312858247354,
      "grad_norm": 0.9984560012817383,
      "learning_rate": 2.0337376800606522e-06,
      "loss": 0.0011,
      "step": 9580
    },
    {
      "epoch": 4.093844144072089,
      "grad_norm": 0.0503467433154583,
      "learning_rate": 2.014783927217589e-06,
      "loss": 0.0003,
      "step": 9600
    },
    {
      "epoch": 4.102375429896825,
      "grad_norm": 0.010060282424092293,
      "learning_rate": 1.995830174374526e-06,
      "loss": 0.0005,
      "step": 9620
    },
    {
      "epoch": 4.11090671572156,
      "grad_norm": 0.002143596298992634,
      "learning_rate": 1.9768764215314636e-06,
      "loss": 0.0004,
      "step": 9640
    },
    {
      "epoch": 4.119438001546295,
      "grad_norm": 0.013449793681502342,
      "learning_rate": 1.9579226686884e-06,
      "loss": 0.0001,
      "step": 9660
    },
    {
      "epoch": 4.127969287371031,
      "grad_norm": 0.0031724958680570126,
      "learning_rate": 1.9389689158453376e-06,
      "loss": 0.0003,
      "step": 9680
    },
    {
      "epoch": 4.136500573195766,
      "grad_norm": 0.13765302300453186,
      "learning_rate": 1.9200151630022746e-06,
      "loss": 0.0005,
      "step": 9700
    },
    {
      "epoch": 4.145031859020502,
      "grad_norm": 0.0029892136808484793,
      "learning_rate": 1.9010614101592118e-06,
      "loss": 0.0013,
      "step": 9720
    },
    {
      "epoch": 4.153563144845237,
      "grad_norm": 0.0015808646567165852,
      "learning_rate": 1.8821076573161488e-06,
      "loss": 0.0008,
      "step": 9740
    },
    {
      "epoch": 4.162094430669972,
      "grad_norm": 0.2099493145942688,
      "learning_rate": 1.863153904473086e-06,
      "loss": 0.0017,
      "step": 9760
    },
    {
      "epoch": 4.170625716494708,
      "grad_norm": 0.009884202852845192,
      "learning_rate": 1.8442001516300228e-06,
      "loss": 0.0004,
      "step": 9780
    },
    {
      "epoch": 4.179157002319443,
      "grad_norm": 0.041608549654483795,
      "learning_rate": 1.8252463987869602e-06,
      "loss": 0.0008,
      "step": 9800
    },
    {
      "epoch": 4.187688288144178,
      "grad_norm": 0.10235095769166946,
      "learning_rate": 1.806292645943897e-06,
      "loss": 0.0002,
      "step": 9820
    },
    {
      "epoch": 4.196219573968914,
      "grad_norm": 0.0036619852762669325,
      "learning_rate": 1.7873388931008342e-06,
      "loss": 0.0007,
      "step": 9840
    },
    {
      "epoch": 4.204750859793649,
      "grad_norm": 0.009832346811890602,
      "learning_rate": 1.7683851402577712e-06,
      "loss": 0.0002,
      "step": 9860
    },
    {
      "epoch": 4.213282145618385,
      "grad_norm": 0.004748732317239046,
      "learning_rate": 1.7494313874147081e-06,
      "loss": 0.0012,
      "step": 9880
    },
    {
      "epoch": 4.22181343144312,
      "grad_norm": 0.12899354100227356,
      "learning_rate": 1.7304776345716453e-06,
      "loss": 0.0007,
      "step": 9900
    },
    {
      "epoch": 4.230344717267855,
      "grad_norm": 0.0022239191457629204,
      "learning_rate": 1.7115238817285823e-06,
      "loss": 0.0002,
      "step": 9920
    },
    {
      "epoch": 4.238876003092591,
      "grad_norm": 0.01424858346581459,
      "learning_rate": 1.6925701288855195e-06,
      "loss": 0.0003,
      "step": 9940
    },
    {
      "epoch": 4.247407288917326,
      "grad_norm": 0.033092234283685684,
      "learning_rate": 1.6736163760424565e-06,
      "loss": 0.0001,
      "step": 9960
    },
    {
      "epoch": 4.2559385747420615,
      "grad_norm": 0.07591279596090317,
      "learning_rate": 1.6546626231993937e-06,
      "loss": 0.0007,
      "step": 9980
    },
    {
      "epoch": 4.264469860566797,
      "grad_norm": 0.04896365851163864,
      "learning_rate": 1.6357088703563307e-06,
      "loss": 0.0009,
      "step": 10000
    },
    {
      "epoch": 4.2730011463915325,
      "grad_norm": 0.04198634624481201,
      "learning_rate": 1.616755117513268e-06,
      "loss": 0.001,
      "step": 10020
    },
    {
      "epoch": 4.2815324322162684,
      "grad_norm": 0.001103536575101316,
      "learning_rate": 1.5978013646702047e-06,
      "loss": 0.0004,
      "step": 10040
    },
    {
      "epoch": 4.2900637180410035,
      "grad_norm": 0.004211086314171553,
      "learning_rate": 1.5788476118271421e-06,
      "loss": 0.0013,
      "step": 10060
    },
    {
      "epoch": 4.298595003865739,
      "grad_norm": 0.15704445540905,
      "learning_rate": 1.559893858984079e-06,
      "loss": 0.0004,
      "step": 10080
    },
    {
      "epoch": 4.3071262896904745,
      "grad_norm": 0.004661478102207184,
      "learning_rate": 1.5409401061410159e-06,
      "loss": 0.0008,
      "step": 10100
    },
    {
      "epoch": 4.31565757551521,
      "grad_norm": 0.06700389832258224,
      "learning_rate": 1.521986353297953e-06,
      "loss": 0.0009,
      "step": 10120
    },
    {
      "epoch": 4.324188861339945,
      "grad_norm": 0.014283936470746994,
      "learning_rate": 1.50303260045489e-06,
      "loss": 0.0001,
      "step": 10140
    },
    {
      "epoch": 4.332720147164681,
      "grad_norm": 0.002240395173430443,
      "learning_rate": 1.4840788476118273e-06,
      "loss": 0.0006,
      "step": 10160
    },
    {
      "epoch": 4.341251432989416,
      "grad_norm": 0.0024789085146039724,
      "learning_rate": 1.4651250947687643e-06,
      "loss": 0.0008,
      "step": 10180
    },
    {
      "epoch": 4.349782718814152,
      "grad_norm": 0.061689529567956924,
      "learning_rate": 1.4461713419257015e-06,
      "loss": 0.0005,
      "step": 10200
    },
    {
      "epoch": 4.358314004638887,
      "grad_norm": 0.010046861134469509,
      "learning_rate": 1.4272175890826385e-06,
      "loss": 0.001,
      "step": 10220
    },
    {
      "epoch": 4.366845290463622,
      "grad_norm": 0.006659022998064756,
      "learning_rate": 1.4082638362395757e-06,
      "loss": 0.0003,
      "step": 10240
    },
    {
      "epoch": 4.375376576288358,
      "grad_norm": 0.00152122532017529,
      "learning_rate": 1.3893100833965127e-06,
      "loss": 0.0006,
      "step": 10260
    },
    {
      "epoch": 4.383907862113093,
      "grad_norm": 0.004036005586385727,
      "learning_rate": 1.3703563305534499e-06,
      "loss": 0.001,
      "step": 10280
    },
    {
      "epoch": 4.392439147937829,
      "grad_norm": 0.0033223882783204317,
      "learning_rate": 1.3514025777103866e-06,
      "loss": 0.0003,
      "step": 10300
    },
    {
      "epoch": 4.400970433762564,
      "grad_norm": 0.0016641718102619052,
      "learning_rate": 1.332448824867324e-06,
      "loss": 0.0008,
      "step": 10320
    },
    {
      "epoch": 4.409501719587299,
      "grad_norm": 0.010670769028365612,
      "learning_rate": 1.3134950720242608e-06,
      "loss": 0.0003,
      "step": 10340
    },
    {
      "epoch": 4.418033005412035,
      "grad_norm": 0.04593042656779289,
      "learning_rate": 1.2945413191811978e-06,
      "loss": 0.0005,
      "step": 10360
    },
    {
      "epoch": 4.42656429123677,
      "grad_norm": 0.007252163253724575,
      "learning_rate": 1.275587566338135e-06,
      "loss": 0.0007,
      "step": 10380
    },
    {
      "epoch": 4.435095577061505,
      "grad_norm": 0.6145280003547668,
      "learning_rate": 1.256633813495072e-06,
      "loss": 0.0009,
      "step": 10400
    },
    {
      "epoch": 4.443626862886241,
      "grad_norm": 0.07417486608028412,
      "learning_rate": 1.2376800606520092e-06,
      "loss": 0.0003,
      "step": 10420
    },
    {
      "epoch": 4.452158148710976,
      "grad_norm": 0.0672876238822937,
      "learning_rate": 1.2187263078089462e-06,
      "loss": 0.0005,
      "step": 10440
    },
    {
      "epoch": 4.460689434535712,
      "grad_norm": 0.022692449390888214,
      "learning_rate": 1.1997725549658834e-06,
      "loss": 0.0009,
      "step": 10460
    },
    {
      "epoch": 4.469220720360447,
      "grad_norm": 0.026050206273794174,
      "learning_rate": 1.1808188021228204e-06,
      "loss": 0.0003,
      "step": 10480
    },
    {
      "epoch": 4.477752006185182,
      "grad_norm": 0.19089975953102112,
      "learning_rate": 1.1618650492797574e-06,
      "loss": 0.0003,
      "step": 10500
    },
    {
      "epoch": 4.486283292009918,
      "grad_norm": 0.0078501645475626,
      "learning_rate": 1.1429112964366946e-06,
      "loss": 0.0005,
      "step": 10520
    },
    {
      "epoch": 4.494814577834653,
      "grad_norm": 0.0032521337270736694,
      "learning_rate": 1.1239575435936316e-06,
      "loss": 0.0011,
      "step": 10540
    },
    {
      "epoch": 4.503345863659389,
      "grad_norm": 0.02235543541610241,
      "learning_rate": 1.1050037907505686e-06,
      "loss": 0.0004,
      "step": 10560
    },
    {
      "epoch": 4.511877149484124,
      "grad_norm": 0.00296384422108531,
      "learning_rate": 1.0860500379075058e-06,
      "loss": 0.0001,
      "step": 10580
    },
    {
      "epoch": 4.520408435308859,
      "grad_norm": 0.02340189926326275,
      "learning_rate": 1.0670962850644428e-06,
      "loss": 0.0005,
      "step": 10600
    },
    {
      "epoch": 4.528939721133595,
      "grad_norm": 0.10533617436885834,
      "learning_rate": 1.04814253222138e-06,
      "loss": 0.0009,
      "step": 10620
    },
    {
      "epoch": 4.53747100695833,
      "grad_norm": 0.11890547722578049,
      "learning_rate": 1.029188779378317e-06,
      "loss": 0.0012,
      "step": 10640
    },
    {
      "epoch": 4.546002292783065,
      "grad_norm": 0.0861683338880539,
      "learning_rate": 1.0102350265352542e-06,
      "loss": 0.0003,
      "step": 10660
    },
    {
      "epoch": 4.554533578607801,
      "grad_norm": 0.006066606845706701,
      "learning_rate": 9.912812736921912e-07,
      "loss": 0.0002,
      "step": 10680
    },
    {
      "epoch": 4.563064864432536,
      "grad_norm": 0.07083293795585632,
      "learning_rate": 9.723275208491282e-07,
      "loss": 0.0016,
      "step": 10700
    },
    {
      "epoch": 4.571596150257272,
      "grad_norm": 0.1241740807890892,
      "learning_rate": 9.533737680060654e-07,
      "loss": 0.0007,
      "step": 10720
    },
    {
      "epoch": 4.580127436082007,
      "grad_norm": 0.17968176305294037,
      "learning_rate": 9.344200151630023e-07,
      "loss": 0.001,
      "step": 10740
    },
    {
      "epoch": 4.588658721906742,
      "grad_norm": 0.016164515167474747,
      "learning_rate": 9.154662623199393e-07,
      "loss": 0.0007,
      "step": 10760
    },
    {
      "epoch": 4.597190007731478,
      "grad_norm": 0.011523464694619179,
      "learning_rate": 8.965125094768764e-07,
      "loss": 0.0002,
      "step": 10780
    },
    {
      "epoch": 4.605721293556213,
      "grad_norm": 0.02625366859138012,
      "learning_rate": 8.775587566338135e-07,
      "loss": 0.0004,
      "step": 10800
    },
    {
      "epoch": 4.614252579380949,
      "grad_norm": 0.01763170026242733,
      "learning_rate": 8.586050037907506e-07,
      "loss": 0.0006,
      "step": 10820
    },
    {
      "epoch": 4.622783865205684,
      "grad_norm": 0.7697904109954834,
      "learning_rate": 8.396512509476877e-07,
      "loss": 0.0009,
      "step": 10840
    },
    {
      "epoch": 4.631315151030419,
      "grad_norm": 0.5940852165222168,
      "learning_rate": 8.206974981046248e-07,
      "loss": 0.001,
      "step": 10860
    },
    {
      "epoch": 4.639846436855155,
      "grad_norm": 0.006833167281001806,
      "learning_rate": 8.017437452615618e-07,
      "loss": 0.0002,
      "step": 10880
    },
    {
      "epoch": 4.64837772267989,
      "grad_norm": 0.017851483076810837,
      "learning_rate": 7.827899924184989e-07,
      "loss": 0.0007,
      "step": 10900
    },
    {
      "epoch": 4.656909008504625,
      "grad_norm": 0.10836722701787949,
      "learning_rate": 7.63836239575436e-07,
      "loss": 0.001,
      "step": 10920
    },
    {
      "epoch": 4.665440294329361,
      "grad_norm": 0.013410048559308052,
      "learning_rate": 7.448824867323731e-07,
      "loss": 0.0002,
      "step": 10940
    },
    {
      "epoch": 4.673971580154096,
      "grad_norm": 0.04352269321680069,
      "learning_rate": 7.259287338893102e-07,
      "loss": 0.0005,
      "step": 10960
    },
    {
      "epoch": 4.682502865978831,
      "grad_norm": 0.4454873204231262,
      "learning_rate": 7.069749810462471e-07,
      "loss": 0.0005,
      "step": 10980
    },
    {
      "epoch": 4.691034151803567,
      "grad_norm": 9.674689292907715,
      "learning_rate": 6.880212282031842e-07,
      "loss": 0.0012,
      "step": 11000
    },
    {
      "epoch": 4.699565437628302,
      "grad_norm": 0.037218909710645676,
      "learning_rate": 6.690674753601213e-07,
      "loss": 0.0006,
      "step": 11020
    },
    {
      "epoch": 4.708096723453038,
      "grad_norm": 0.0015893258387222886,
      "learning_rate": 6.501137225170584e-07,
      "loss": 0.0006,
      "step": 11040
    },
    {
      "epoch": 4.716628009277773,
      "grad_norm": 0.027050230652093887,
      "learning_rate": 6.311599696739955e-07,
      "loss": 0.0001,
      "step": 11060
    },
    {
      "epoch": 4.725159295102509,
      "grad_norm": 0.008479244075715542,
      "learning_rate": 6.122062168309326e-07,
      "loss": 0.0001,
      "step": 11080
    },
    {
      "epoch": 4.733690580927244,
      "grad_norm": 0.08716579526662827,
      "learning_rate": 5.932524639878697e-07,
      "loss": 0.0012,
      "step": 11100
    },
    {
      "epoch": 4.742221866751979,
      "grad_norm": 0.011437938548624516,
      "learning_rate": 5.742987111448068e-07,
      "loss": 0.0004,
      "step": 11120
    },
    {
      "epoch": 4.750753152576715,
      "grad_norm": 0.0015223623486235738,
      "learning_rate": 5.553449583017438e-07,
      "loss": 0.0014,
      "step": 11140
    },
    {
      "epoch": 4.75928443840145,
      "grad_norm": 0.011975160799920559,
      "learning_rate": 5.363912054586809e-07,
      "loss": 0.0005,
      "step": 11160
    },
    {
      "epoch": 4.767815724226185,
      "grad_norm": 1.778279423713684,
      "learning_rate": 5.17437452615618e-07,
      "loss": 0.0017,
      "step": 11180
    },
    {
      "epoch": 4.776347010050921,
      "grad_norm": 0.1836637705564499,
      "learning_rate": 4.98483699772555e-07,
      "loss": 0.0005,
      "step": 11200
    },
    {
      "epoch": 4.784878295875656,
      "grad_norm": 0.014867596328258514,
      "learning_rate": 4.79529946929492e-07,
      "loss": 0.0011,
      "step": 11220
    },
    {
      "epoch": 4.793409581700391,
      "grad_norm": 0.14129219949245453,
      "learning_rate": 4.6057619408642915e-07,
      "loss": 0.001,
      "step": 11240
    },
    {
      "epoch": 4.801940867525127,
      "grad_norm": 0.04961676895618439,
      "learning_rate": 4.4162244124336624e-07,
      "loss": 0.0001,
      "step": 11260
    },
    {
      "epoch": 4.8104721533498624,
      "grad_norm": 0.019348613917827606,
      "learning_rate": 4.2266868840030334e-07,
      "loss": 0.0006,
      "step": 11280
    },
    {
      "epoch": 4.819003439174598,
      "grad_norm": 0.3725990355014801,
      "learning_rate": 4.0371493555724033e-07,
      "loss": 0.0003,
      "step": 11300
    },
    {
      "epoch": 4.8275347249993334,
      "grad_norm": 0.019072607159614563,
      "learning_rate": 3.8476118271417743e-07,
      "loss": 0.001,
      "step": 11320
    },
    {
      "epoch": 4.8360660108240685,
      "grad_norm": 0.10579651594161987,
      "learning_rate": 3.658074298711145e-07,
      "loss": 0.0003,
      "step": 11340
    },
    {
      "epoch": 4.8445972966488045,
      "grad_norm": 0.09878198057413101,
      "learning_rate": 3.4685367702805157e-07,
      "loss": 0.0003,
      "step": 11360
    },
    {
      "epoch": 4.8531285824735395,
      "grad_norm": 0.002708085812628269,
      "learning_rate": 3.2789992418498867e-07,
      "loss": 0.0007,
      "step": 11380
    },
    {
      "epoch": 4.8616598682982755,
      "grad_norm": 0.0034098317846655846,
      "learning_rate": 3.089461713419257e-07,
      "loss": 0.0007,
      "step": 11400
    },
    {
      "epoch": 4.8701911541230105,
      "grad_norm": 0.00923614390194416,
      "learning_rate": 2.899924184988628e-07,
      "loss": 0.0004,
      "step": 11420
    },
    {
      "epoch": 4.878722439947746,
      "grad_norm": 0.018803080543875694,
      "learning_rate": 2.710386656557999e-07,
      "loss": 0.0006,
      "step": 11440
    },
    {
      "epoch": 4.8872537257724815,
      "grad_norm": 0.21641628444194794,
      "learning_rate": 2.5208491281273695e-07,
      "loss": 0.0004,
      "step": 11460
    },
    {
      "epoch": 4.895785011597217,
      "grad_norm": 0.09547491371631622,
      "learning_rate": 2.3313115996967402e-07,
      "loss": 0.0004,
      "step": 11480
    },
    {
      "epoch": 4.904316297421952,
      "grad_norm": 0.05295610427856445,
      "learning_rate": 2.141774071266111e-07,
      "loss": 0.0007,
      "step": 11500
    },
    {
      "epoch": 4.912847583246688,
      "grad_norm": 0.007411174941807985,
      "learning_rate": 1.9522365428354816e-07,
      "loss": 0.0003,
      "step": 11520
    },
    {
      "epoch": 4.921378869071423,
      "grad_norm": 0.1345755159854889,
      "learning_rate": 1.7626990144048523e-07,
      "loss": 0.0003,
      "step": 11540
    },
    {
      "epoch": 4.929910154896159,
      "grad_norm": 0.0014988465700298548,
      "learning_rate": 1.573161485974223e-07,
      "loss": 0.0012,
      "step": 11560
    },
    {
      "epoch": 4.938441440720894,
      "grad_norm": 0.002164877485483885,
      "learning_rate": 1.3836239575435937e-07,
      "loss": 0.0006,
      "step": 11580
    },
    {
      "epoch": 4.946972726545629,
      "grad_norm": 0.005400863476097584,
      "learning_rate": 1.1940864291129644e-07,
      "loss": 0.0007,
      "step": 11600
    },
    {
      "epoch": 4.951238369457997,
      "eval_loss": 4.886780738830566,
      "eval_runtime": 31.123,
      "eval_samples_per_second": 64.229,
      "eval_steps_per_second": 2.024,
      "step": 11610
    },
    {
      "epoch": 4.955504012370365,
      "grad_norm": 0.06068026274442673,
      "learning_rate": 1.0045489006823351e-07,
      "loss": 0.0007,
      "step": 11620
    },
    {
      "epoch": 4.9640352981951,
      "grad_norm": 0.03974202275276184,
      "learning_rate": 8.15011372251706e-08,
      "loss": 0.0006,
      "step": 11640
    },
    {
      "epoch": 4.972566584019836,
      "grad_norm": 0.023319492116570473,
      "learning_rate": 6.254738438210765e-08,
      "loss": 0.0005,
      "step": 11660
    },
    {
      "epoch": 4.981097869844571,
      "grad_norm": 0.009742189198732376,
      "learning_rate": 4.359363153904474e-08,
      "loss": 0.0003,
      "step": 11680
    },
    {
      "epoch": 4.989629155669306,
      "grad_norm": 0.044924017041921616,
      "learning_rate": 2.4639878695981805e-08,
      "loss": 0.0014,
      "step": 11700
    },
    {
      "epoch": 4.998160441494042,
      "grad_norm": 0.0015150674153119326,
      "learning_rate": 5.686125852918878e-09,
      "loss": 0.0005,
      "step": 11720
    }
  ],
  "logging_steps": 20,
  "max_steps": 11725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.588230322555216e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
