{
  "best_global_step": 4500,
  "best_metric": 0.9068389007781128,
  "best_model_checkpoint": "output/neodictabert_hebnli/checkpoint-4500",
  "epoch": 15.307101727447217,
  "eval_steps": 500,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06824482832160375,
      "grad_norm": 13.229594230651855,
      "learning_rate": 2.3750000000000003e-07,
      "loss": 0.9523,
      "step": 20
    },
    {
      "epoch": 0.1364896566432075,
      "grad_norm": 10.995268821716309,
      "learning_rate": 4.875000000000001e-07,
      "loss": 0.9195,
      "step": 40
    },
    {
      "epoch": 0.20473448496481125,
      "grad_norm": 4.659383773803711,
      "learning_rate": 7.375e-07,
      "loss": 0.7999,
      "step": 60
    },
    {
      "epoch": 0.272979313286415,
      "grad_norm": 3.7748515605926514,
      "learning_rate": 9.875e-07,
      "loss": 0.6886,
      "step": 80
    },
    {
      "epoch": 0.3412241416080188,
      "grad_norm": 3.3671653270721436,
      "learning_rate": 1.2375e-06,
      "loss": 0.6365,
      "step": 100
    },
    {
      "epoch": 0.4094689699296225,
      "grad_norm": 4.874194622039795,
      "learning_rate": 1.4875000000000002e-06,
      "loss": 0.5797,
      "step": 120
    },
    {
      "epoch": 0.4777137982512263,
      "grad_norm": 4.138864040374756,
      "learning_rate": 1.7375e-06,
      "loss": 0.4671,
      "step": 140
    },
    {
      "epoch": 0.54595862657283,
      "grad_norm": 2.8977315425872803,
      "learning_rate": 1.9875000000000005e-06,
      "loss": 0.4015,
      "step": 160
    },
    {
      "epoch": 0.6142034548944337,
      "grad_norm": 4.179311275482178,
      "learning_rate": 2.2375e-06,
      "loss": 0.3583,
      "step": 180
    },
    {
      "epoch": 0.6824482832160376,
      "grad_norm": 2.794947862625122,
      "learning_rate": 2.4875000000000003e-06,
      "loss": 0.332,
      "step": 200
    },
    {
      "epoch": 0.7506931115376413,
      "grad_norm": 3.051008701324463,
      "learning_rate": 2.7375e-06,
      "loss": 0.3102,
      "step": 220
    },
    {
      "epoch": 0.818937939859245,
      "grad_norm": 3.2432940006256104,
      "learning_rate": 2.9875e-06,
      "loss": 0.3005,
      "step": 240
    },
    {
      "epoch": 0.8871827681808488,
      "grad_norm": 2.0139214992523193,
      "learning_rate": 3.2375e-06,
      "loss": 0.2871,
      "step": 260
    },
    {
      "epoch": 0.9554275965024526,
      "grad_norm": 2.1561145782470703,
      "learning_rate": 3.4875000000000005e-06,
      "loss": 0.2775,
      "step": 280
    },
    {
      "epoch": 1.020473448496481,
      "grad_norm": 3.0419864654541016,
      "learning_rate": 3.7375000000000006e-06,
      "loss": 0.2748,
      "step": 300
    },
    {
      "epoch": 1.088718276818085,
      "grad_norm": 2.100241184234619,
      "learning_rate": 3.9875e-06,
      "loss": 0.258,
      "step": 320
    },
    {
      "epoch": 1.1569631051396887,
      "grad_norm": 2.605081558227539,
      "learning_rate": 4.2375000000000005e-06,
      "loss": 0.252,
      "step": 340
    },
    {
      "epoch": 1.2252079334612924,
      "grad_norm": 2.4726929664611816,
      "learning_rate": 4.4875e-06,
      "loss": 0.254,
      "step": 360
    },
    {
      "epoch": 1.2934527617828961,
      "grad_norm": 2.381175994873047,
      "learning_rate": 4.737500000000001e-06,
      "loss": 0.2557,
      "step": 380
    },
    {
      "epoch": 1.3616975901044999,
      "grad_norm": 2.1920220851898193,
      "learning_rate": 4.987500000000001e-06,
      "loss": 0.2388,
      "step": 400
    },
    {
      "epoch": 1.4299424184261036,
      "grad_norm": 2.2929000854492188,
      "learning_rate": 5.237500000000001e-06,
      "loss": 0.2349,
      "step": 420
    },
    {
      "epoch": 1.4981872467477073,
      "grad_norm": 1.764335036277771,
      "learning_rate": 5.4875e-06,
      "loss": 0.2363,
      "step": 440
    },
    {
      "epoch": 1.566432075069311,
      "grad_norm": 4.557657241821289,
      "learning_rate": 5.7375000000000005e-06,
      "loss": 0.2317,
      "step": 460
    },
    {
      "epoch": 1.6346769033909148,
      "grad_norm": 3.303147792816162,
      "learning_rate": 5.987500000000001e-06,
      "loss": 0.2268,
      "step": 480
    },
    {
      "epoch": 1.7029217317125187,
      "grad_norm": 1.7480404376983643,
      "learning_rate": 6.237500000000001e-06,
      "loss": 0.2246,
      "step": 500
    },
    {
      "epoch": 1.7029217317125187,
      "eval_accuracy": 0.9004502251125562,
      "eval_loss": 0.2353295385837555,
      "eval_macro_f1": 0.8847406976444337,
      "eval_macro_precision": 0.8944082461012604,
      "eval_macro_recall": 0.8769113774166548,
      "eval_runtime": 1.5204,
      "eval_samples_per_second": 1314.767,
      "eval_steps_per_second": 41.436,
      "step": 500
    },
    {
      "epoch": 1.7711665600341224,
      "grad_norm": 2.7898473739624023,
      "learning_rate": 6.487500000000001e-06,
      "loss": 0.2256,
      "step": 520
    },
    {
      "epoch": 1.8394113883557262,
      "grad_norm": 4.756233215332031,
      "learning_rate": 6.7375e-06,
      "loss": 0.2243,
      "step": 540
    },
    {
      "epoch": 1.9076562166773299,
      "grad_norm": 1.8916926383972168,
      "learning_rate": 6.9875000000000004e-06,
      "loss": 0.2246,
      "step": 560
    },
    {
      "epoch": 1.9759010449989338,
      "grad_norm": 2.3069212436676025,
      "learning_rate": 7.237500000000001e-06,
      "loss": 0.2211,
      "step": 580
    },
    {
      "epoch": 2.040946896992962,
      "grad_norm": 3.2760133743286133,
      "learning_rate": 7.487500000000001e-06,
      "loss": 0.1972,
      "step": 600
    },
    {
      "epoch": 2.109191725314566,
      "grad_norm": 1.9408864974975586,
      "learning_rate": 7.737500000000002e-06,
      "loss": 0.1788,
      "step": 620
    },
    {
      "epoch": 2.17743655363617,
      "grad_norm": 1.6799167394638062,
      "learning_rate": 7.987500000000001e-06,
      "loss": 0.182,
      "step": 640
    },
    {
      "epoch": 2.2456813819577737,
      "grad_norm": 2.8093373775482178,
      "learning_rate": 8.2375e-06,
      "loss": 0.1776,
      "step": 660
    },
    {
      "epoch": 2.3139262102793774,
      "grad_norm": 3.637073040008545,
      "learning_rate": 8.487500000000001e-06,
      "loss": 0.1815,
      "step": 680
    },
    {
      "epoch": 2.382171038600981,
      "grad_norm": 2.41477108001709,
      "learning_rate": 8.7375e-06,
      "loss": 0.1735,
      "step": 700
    },
    {
      "epoch": 2.450415866922585,
      "grad_norm": 1.6497291326522827,
      "learning_rate": 8.987500000000002e-06,
      "loss": 0.1774,
      "step": 720
    },
    {
      "epoch": 2.5186606952441886,
      "grad_norm": 2.3575339317321777,
      "learning_rate": 9.237500000000001e-06,
      "loss": 0.1695,
      "step": 740
    },
    {
      "epoch": 2.5869055235657923,
      "grad_norm": 1.9446232318878174,
      "learning_rate": 9.4875e-06,
      "loss": 0.1797,
      "step": 760
    },
    {
      "epoch": 2.655150351887396,
      "grad_norm": 2.1192786693573,
      "learning_rate": 9.737500000000001e-06,
      "loss": 0.1772,
      "step": 780
    },
    {
      "epoch": 2.7233951802089997,
      "grad_norm": 2.006601572036743,
      "learning_rate": 9.9875e-06,
      "loss": 0.172,
      "step": 800
    },
    {
      "epoch": 2.7916400085306035,
      "grad_norm": 2.503490924835205,
      "learning_rate": 9.973611111111113e-06,
      "loss": 0.1726,
      "step": 820
    },
    {
      "epoch": 2.859884836852207,
      "grad_norm": 4.28354024887085,
      "learning_rate": 9.945833333333334e-06,
      "loss": 0.192,
      "step": 840
    },
    {
      "epoch": 2.928129665173811,
      "grad_norm": 1.573967695236206,
      "learning_rate": 9.918055555555557e-06,
      "loss": 0.1793,
      "step": 860
    },
    {
      "epoch": 2.9963744934954146,
      "grad_norm": 2.4747016429901123,
      "learning_rate": 9.890277777777778e-06,
      "loss": 0.1692,
      "step": 880
    },
    {
      "epoch": 3.0614203454894433,
      "grad_norm": 1.8316216468811035,
      "learning_rate": 9.862500000000001e-06,
      "loss": 0.1109,
      "step": 900
    },
    {
      "epoch": 3.129665173811047,
      "grad_norm": 2.38267183303833,
      "learning_rate": 9.834722222222222e-06,
      "loss": 0.0997,
      "step": 920
    },
    {
      "epoch": 3.1979100021326508,
      "grad_norm": 1.8474434614181519,
      "learning_rate": 9.806944444444445e-06,
      "loss": 0.094,
      "step": 940
    },
    {
      "epoch": 3.2661548304542545,
      "grad_norm": 1.754220724105835,
      "learning_rate": 9.779166666666668e-06,
      "loss": 0.1031,
      "step": 960
    },
    {
      "epoch": 3.334399658775858,
      "grad_norm": 2.10326886177063,
      "learning_rate": 9.751388888888889e-06,
      "loss": 0.1034,
      "step": 980
    },
    {
      "epoch": 3.4026444870974624,
      "grad_norm": 4.3625969886779785,
      "learning_rate": 9.723611111111112e-06,
      "loss": 0.1036,
      "step": 1000
    },
    {
      "epoch": 3.4026444870974624,
      "eval_accuracy": 0.9099549774887443,
      "eval_loss": 0.2886158525943756,
      "eval_macro_f1": 0.8954308312525283,
      "eval_macro_precision": 0.9069527380124589,
      "eval_macro_recall": 0.886321104600916,
      "eval_runtime": 1.5239,
      "eval_samples_per_second": 1311.801,
      "eval_steps_per_second": 41.342,
      "step": 1000
    },
    {
      "epoch": 3.470889315419066,
      "grad_norm": 2.0342442989349365,
      "learning_rate": 9.695833333333335e-06,
      "loss": 0.1055,
      "step": 1020
    },
    {
      "epoch": 3.53913414374067,
      "grad_norm": 2.0551536083221436,
      "learning_rate": 9.668055555555556e-06,
      "loss": 0.1003,
      "step": 1040
    },
    {
      "epoch": 3.6073789720622735,
      "grad_norm": 1.9623254537582397,
      "learning_rate": 9.640277777777779e-06,
      "loss": 0.0997,
      "step": 1060
    },
    {
      "epoch": 3.6756238003838773,
      "grad_norm": 1.9381473064422607,
      "learning_rate": 9.612500000000002e-06,
      "loss": 0.1049,
      "step": 1080
    },
    {
      "epoch": 3.743868628705481,
      "grad_norm": 2.3460187911987305,
      "learning_rate": 9.584722222222223e-06,
      "loss": 0.0996,
      "step": 1100
    },
    {
      "epoch": 3.8121134570270847,
      "grad_norm": 4.940620422363281,
      "learning_rate": 9.556944444444446e-06,
      "loss": 0.1046,
      "step": 1120
    },
    {
      "epoch": 3.8803582853486884,
      "grad_norm": 2.3299105167388916,
      "learning_rate": 9.529166666666667e-06,
      "loss": 0.1041,
      "step": 1140
    },
    {
      "epoch": 3.948603113670292,
      "grad_norm": 1.900478482246399,
      "learning_rate": 9.50138888888889e-06,
      "loss": 0.1009,
      "step": 1160
    },
    {
      "epoch": 4.013648965664321,
      "grad_norm": 1.803680658340454,
      "learning_rate": 9.473611111111112e-06,
      "loss": 0.0982,
      "step": 1180
    },
    {
      "epoch": 4.081893793985924,
      "grad_norm": 1.9441876411437988,
      "learning_rate": 9.445833333333334e-06,
      "loss": 0.0481,
      "step": 1200
    },
    {
      "epoch": 4.150138622307528,
      "grad_norm": 2.2627625465393066,
      "learning_rate": 9.418055555555557e-06,
      "loss": 0.0476,
      "step": 1220
    },
    {
      "epoch": 4.218383450629132,
      "grad_norm": 1.6409752368927002,
      "learning_rate": 9.39027777777778e-06,
      "loss": 0.0463,
      "step": 1240
    },
    {
      "epoch": 4.286628278950736,
      "grad_norm": 4.9245500564575195,
      "learning_rate": 9.3625e-06,
      "loss": 0.0474,
      "step": 1260
    },
    {
      "epoch": 4.35487310727234,
      "grad_norm": 2.491840362548828,
      "learning_rate": 9.334722222222223e-06,
      "loss": 0.0387,
      "step": 1280
    },
    {
      "epoch": 4.423117935593943,
      "grad_norm": 1.6191877126693726,
      "learning_rate": 9.306944444444446e-06,
      "loss": 0.0432,
      "step": 1300
    },
    {
      "epoch": 4.491362763915547,
      "grad_norm": 2.7632925510406494,
      "learning_rate": 9.279166666666667e-06,
      "loss": 0.049,
      "step": 1320
    },
    {
      "epoch": 4.559607592237151,
      "grad_norm": 2.041132688522339,
      "learning_rate": 9.251388888888889e-06,
      "loss": 0.047,
      "step": 1340
    },
    {
      "epoch": 4.627852420558755,
      "grad_norm": 1.6421185731887817,
      "learning_rate": 9.223611111111112e-06,
      "loss": 0.0458,
      "step": 1360
    },
    {
      "epoch": 4.696097248880358,
      "grad_norm": 1.4515917301177979,
      "learning_rate": 9.195833333333334e-06,
      "loss": 0.0463,
      "step": 1380
    },
    {
      "epoch": 4.764342077201962,
      "grad_norm": 2.658942937850952,
      "learning_rate": 9.168055555555556e-06,
      "loss": 0.0472,
      "step": 1400
    },
    {
      "epoch": 4.8325869055235655,
      "grad_norm": 1.8767811059951782,
      "learning_rate": 9.140277777777778e-06,
      "loss": 0.0469,
      "step": 1420
    },
    {
      "epoch": 4.90083173384517,
      "grad_norm": 2.7717671394348145,
      "learning_rate": 9.112500000000001e-06,
      "loss": 0.0501,
      "step": 1440
    },
    {
      "epoch": 4.969076562166773,
      "grad_norm": 2.406165838241577,
      "learning_rate": 9.084722222222222e-06,
      "loss": 0.047,
      "step": 1460
    },
    {
      "epoch": 5.034122414160802,
      "grad_norm": 1.960829257965088,
      "learning_rate": 9.056944444444445e-06,
      "loss": 0.034,
      "step": 1480
    },
    {
      "epoch": 5.102367242482406,
      "grad_norm": 1.1211026906967163,
      "learning_rate": 9.029166666666668e-06,
      "loss": 0.0256,
      "step": 1500
    },
    {
      "epoch": 5.102367242482406,
      "eval_accuracy": 0.9114557278639319,
      "eval_loss": 0.3963800072669983,
      "eval_macro_f1": 0.8987554714417709,
      "eval_macro_precision": 0.9026444113194902,
      "eval_macro_recall": 0.8952079746488011,
      "eval_runtime": 1.5114,
      "eval_samples_per_second": 1322.579,
      "eval_steps_per_second": 41.682,
      "step": 1500
    },
    {
      "epoch": 5.170612070804009,
      "grad_norm": 1.1658989191055298,
      "learning_rate": 9.00138888888889e-06,
      "loss": 0.0223,
      "step": 1520
    },
    {
      "epoch": 5.238856899125613,
      "grad_norm": 2.1223230361938477,
      "learning_rate": 8.973611111111112e-06,
      "loss": 0.0233,
      "step": 1540
    },
    {
      "epoch": 5.3071017274472165,
      "grad_norm": 2.5816333293914795,
      "learning_rate": 8.945833333333333e-06,
      "loss": 0.0248,
      "step": 1560
    },
    {
      "epoch": 5.375346555768821,
      "grad_norm": 1.2086541652679443,
      "learning_rate": 8.918055555555556e-06,
      "loss": 0.0246,
      "step": 1580
    },
    {
      "epoch": 5.443591384090425,
      "grad_norm": 2.3308701515197754,
      "learning_rate": 8.890277777777777e-06,
      "loss": 0.0237,
      "step": 1600
    },
    {
      "epoch": 5.511836212412028,
      "grad_norm": 2.633740186691284,
      "learning_rate": 8.8625e-06,
      "loss": 0.0251,
      "step": 1620
    },
    {
      "epoch": 5.580081040733631,
      "grad_norm": 2.079171657562256,
      "learning_rate": 8.834722222222223e-06,
      "loss": 0.0266,
      "step": 1640
    },
    {
      "epoch": 5.648325869055236,
      "grad_norm": 2.026318311691284,
      "learning_rate": 8.806944444444446e-06,
      "loss": 0.0243,
      "step": 1660
    },
    {
      "epoch": 5.71657069737684,
      "grad_norm": 2.4550650119781494,
      "learning_rate": 8.779166666666667e-06,
      "loss": 0.0283,
      "step": 1680
    },
    {
      "epoch": 5.784815525698443,
      "grad_norm": 1.9872909784317017,
      "learning_rate": 8.75138888888889e-06,
      "loss": 0.0248,
      "step": 1700
    },
    {
      "epoch": 5.853060354020047,
      "grad_norm": 1.9609404802322388,
      "learning_rate": 8.723611111111113e-06,
      "loss": 0.0233,
      "step": 1720
    },
    {
      "epoch": 5.9213051823416505,
      "grad_norm": 2.73828125,
      "learning_rate": 8.695833333333334e-06,
      "loss": 0.0287,
      "step": 1740
    },
    {
      "epoch": 5.989550010663255,
      "grad_norm": 2.384631633758545,
      "learning_rate": 8.668055555555557e-06,
      "loss": 0.0268,
      "step": 1760
    },
    {
      "epoch": 6.054595862657283,
      "grad_norm": 1.7406880855560303,
      "learning_rate": 8.640277777777778e-06,
      "loss": 0.0172,
      "step": 1780
    },
    {
      "epoch": 6.122840690978887,
      "grad_norm": 2.519322633743286,
      "learning_rate": 8.612500000000001e-06,
      "loss": 0.0129,
      "step": 1800
    },
    {
      "epoch": 6.191085519300491,
      "grad_norm": 1.4439630508422852,
      "learning_rate": 8.584722222222222e-06,
      "loss": 0.0139,
      "step": 1820
    },
    {
      "epoch": 6.259330347622094,
      "grad_norm": 1.0657715797424316,
      "learning_rate": 8.556944444444445e-06,
      "loss": 0.0135,
      "step": 1840
    },
    {
      "epoch": 6.327575175943698,
      "grad_norm": 3.1537914276123047,
      "learning_rate": 8.529166666666668e-06,
      "loss": 0.0169,
      "step": 1860
    },
    {
      "epoch": 6.3958200042653015,
      "grad_norm": 2.1319949626922607,
      "learning_rate": 8.501388888888889e-06,
      "loss": 0.0142,
      "step": 1880
    },
    {
      "epoch": 6.464064832586906,
      "grad_norm": 2.2437126636505127,
      "learning_rate": 8.473611111111112e-06,
      "loss": 0.0156,
      "step": 1900
    },
    {
      "epoch": 6.532309660908509,
      "grad_norm": 0.403990238904953,
      "learning_rate": 8.445833333333335e-06,
      "loss": 0.0119,
      "step": 1920
    },
    {
      "epoch": 6.600554489230113,
      "grad_norm": 2.2999415397644043,
      "learning_rate": 8.418055555555556e-06,
      "loss": 0.0195,
      "step": 1940
    },
    {
      "epoch": 6.668799317551716,
      "grad_norm": 1.7898942232131958,
      "learning_rate": 8.390277777777779e-06,
      "loss": 0.0164,
      "step": 1960
    },
    {
      "epoch": 6.737044145873321,
      "grad_norm": 1.1996853351593018,
      "learning_rate": 8.362500000000002e-06,
      "loss": 0.017,
      "step": 1980
    },
    {
      "epoch": 6.805288974194925,
      "grad_norm": 3.3387136459350586,
      "learning_rate": 8.334722222222223e-06,
      "loss": 0.0156,
      "step": 2000
    },
    {
      "epoch": 6.805288974194925,
      "eval_accuracy": 0.9154577288644322,
      "eval_loss": 0.523997962474823,
      "eval_macro_f1": 0.9034874735207699,
      "eval_macro_precision": 0.906689139232401,
      "eval_macro_recall": 0.9005193411773246,
      "eval_runtime": 1.5259,
      "eval_samples_per_second": 1310.049,
      "eval_steps_per_second": 41.287,
      "step": 2000
    },
    {
      "epoch": 6.873533802516528,
      "grad_norm": 1.3796337842941284,
      "learning_rate": 8.306944444444444e-06,
      "loss": 0.0204,
      "step": 2020
    },
    {
      "epoch": 6.941778630838132,
      "grad_norm": 1.3348454236984253,
      "learning_rate": 8.279166666666667e-06,
      "loss": 0.0227,
      "step": 2040
    },
    {
      "epoch": 7.00682448283216,
      "grad_norm": 1.7586826086044312,
      "learning_rate": 8.25138888888889e-06,
      "loss": 0.0181,
      "step": 2060
    },
    {
      "epoch": 7.075069311153764,
      "grad_norm": 1.74224054813385,
      "learning_rate": 8.223611111111111e-06,
      "loss": 0.0082,
      "step": 2080
    },
    {
      "epoch": 7.143314139475368,
      "grad_norm": 1.960184097290039,
      "learning_rate": 8.195833333333334e-06,
      "loss": 0.0092,
      "step": 2100
    },
    {
      "epoch": 7.211558967796972,
      "grad_norm": 1.2461036443710327,
      "learning_rate": 8.168055555555557e-06,
      "loss": 0.0104,
      "step": 2120
    },
    {
      "epoch": 7.279803796118576,
      "grad_norm": 0.73761385679245,
      "learning_rate": 8.140277777777778e-06,
      "loss": 0.01,
      "step": 2140
    },
    {
      "epoch": 7.348048624440179,
      "grad_norm": 0.9471715092658997,
      "learning_rate": 8.1125e-06,
      "loss": 0.0118,
      "step": 2160
    },
    {
      "epoch": 7.416293452761783,
      "grad_norm": 1.7159961462020874,
      "learning_rate": 8.084722222222224e-06,
      "loss": 0.0106,
      "step": 2180
    },
    {
      "epoch": 7.4845382810833865,
      "grad_norm": 0.4722912311553955,
      "learning_rate": 8.056944444444446e-06,
      "loss": 0.0106,
      "step": 2200
    },
    {
      "epoch": 7.552783109404991,
      "grad_norm": 2.1011977195739746,
      "learning_rate": 8.029166666666668e-06,
      "loss": 0.012,
      "step": 2220
    },
    {
      "epoch": 7.621027937726594,
      "grad_norm": 4.780627727508545,
      "learning_rate": 8.001388888888889e-06,
      "loss": 0.0133,
      "step": 2240
    },
    {
      "epoch": 7.689272766048198,
      "grad_norm": 0.9830724596977234,
      "learning_rate": 7.973611111111112e-06,
      "loss": 0.0109,
      "step": 2260
    },
    {
      "epoch": 7.757517594369801,
      "grad_norm": 5.327651500701904,
      "learning_rate": 7.945833333333334e-06,
      "loss": 0.0135,
      "step": 2280
    },
    {
      "epoch": 7.8257624226914055,
      "grad_norm": 2.735158920288086,
      "learning_rate": 7.918055555555556e-06,
      "loss": 0.0123,
      "step": 2300
    },
    {
      "epoch": 7.894007251013009,
      "grad_norm": 0.4879564940929413,
      "learning_rate": 7.890277777777779e-06,
      "loss": 0.0108,
      "step": 2320
    },
    {
      "epoch": 7.962252079334613,
      "grad_norm": 1.2157069444656372,
      "learning_rate": 7.862500000000001e-06,
      "loss": 0.0112,
      "step": 2340
    },
    {
      "epoch": 8.027297931328642,
      "grad_norm": 0.37643101811408997,
      "learning_rate": 7.834722222222223e-06,
      "loss": 0.007,
      "step": 2360
    },
    {
      "epoch": 8.095542759650245,
      "grad_norm": 6.463437557220459,
      "learning_rate": 7.806944444444445e-06,
      "loss": 0.0062,
      "step": 2380
    },
    {
      "epoch": 8.163787587971848,
      "grad_norm": 3.136403799057007,
      "learning_rate": 7.779166666666668e-06,
      "loss": 0.0049,
      "step": 2400
    },
    {
      "epoch": 8.232032416293453,
      "grad_norm": 6.111144542694092,
      "learning_rate": 7.75138888888889e-06,
      "loss": 0.0081,
      "step": 2420
    },
    {
      "epoch": 8.300277244615057,
      "grad_norm": 1.3807328939437866,
      "learning_rate": 7.723611111111112e-06,
      "loss": 0.0083,
      "step": 2440
    },
    {
      "epoch": 8.36852207293666,
      "grad_norm": 4.629593372344971,
      "learning_rate": 7.695833333333333e-06,
      "loss": 0.0094,
      "step": 2460
    },
    {
      "epoch": 8.436766901258263,
      "grad_norm": 0.8827385902404785,
      "learning_rate": 7.668055555555556e-06,
      "loss": 0.0084,
      "step": 2480
    },
    {
      "epoch": 8.505011729579868,
      "grad_norm": 3.4700849056243896,
      "learning_rate": 7.640277777777778e-06,
      "loss": 0.0072,
      "step": 2500
    },
    {
      "epoch": 8.505011729579868,
      "eval_accuracy": 0.9069534767383692,
      "eval_loss": 0.5849171876907349,
      "eval_macro_f1": 0.8936505048979564,
      "eval_macro_precision": 0.8973099037107165,
      "eval_macro_recall": 0.8903009434112061,
      "eval_runtime": 1.5063,
      "eval_samples_per_second": 1327.061,
      "eval_steps_per_second": 41.823,
      "step": 2500
    },
    {
      "epoch": 8.573256557901471,
      "grad_norm": 2.364086866378784,
      "learning_rate": 7.6125e-06,
      "loss": 0.008,
      "step": 2520
    },
    {
      "epoch": 8.641501386223075,
      "grad_norm": 2.970183849334717,
      "learning_rate": 7.584722222222222e-06,
      "loss": 0.0075,
      "step": 2540
    },
    {
      "epoch": 8.70974621454468,
      "grad_norm": 3.0012502670288086,
      "learning_rate": 7.556944444444445e-06,
      "loss": 0.0069,
      "step": 2560
    },
    {
      "epoch": 8.777991042866283,
      "grad_norm": 1.0818895101547241,
      "learning_rate": 7.529166666666667e-06,
      "loss": 0.0121,
      "step": 2580
    },
    {
      "epoch": 8.846235871187886,
      "grad_norm": 3.0267703533172607,
      "learning_rate": 7.501388888888889e-06,
      "loss": 0.0073,
      "step": 2600
    },
    {
      "epoch": 8.91448069950949,
      "grad_norm": 0.9307467341423035,
      "learning_rate": 7.473611111111112e-06,
      "loss": 0.0066,
      "step": 2620
    },
    {
      "epoch": 8.982725527831095,
      "grad_norm": 3.374030828475952,
      "learning_rate": 7.445833333333334e-06,
      "loss": 0.0089,
      "step": 2640
    },
    {
      "epoch": 9.047771379825123,
      "grad_norm": 4.822526931762695,
      "learning_rate": 7.418055555555557e-06,
      "loss": 0.0058,
      "step": 2660
    },
    {
      "epoch": 9.116016208146727,
      "grad_norm": 0.5769908428192139,
      "learning_rate": 7.390277777777778e-06,
      "loss": 0.0048,
      "step": 2680
    },
    {
      "epoch": 9.18426103646833,
      "grad_norm": 1.4675275087356567,
      "learning_rate": 7.3625e-06,
      "loss": 0.0038,
      "step": 2700
    },
    {
      "epoch": 9.252505864789933,
      "grad_norm": 2.993509531021118,
      "learning_rate": 7.334722222222222e-06,
      "loss": 0.0052,
      "step": 2720
    },
    {
      "epoch": 9.320750693111538,
      "grad_norm": 1.147059440612793,
      "learning_rate": 7.306944444444445e-06,
      "loss": 0.0045,
      "step": 2740
    },
    {
      "epoch": 9.388995521433142,
      "grad_norm": 3.0099570751190186,
      "learning_rate": 7.279166666666667e-06,
      "loss": 0.0051,
      "step": 2760
    },
    {
      "epoch": 9.457240349754745,
      "grad_norm": 6.3510565757751465,
      "learning_rate": 7.251388888888889e-06,
      "loss": 0.0055,
      "step": 2780
    },
    {
      "epoch": 9.525485178076348,
      "grad_norm": 3.6911778450012207,
      "learning_rate": 7.223611111111112e-06,
      "loss": 0.0054,
      "step": 2800
    },
    {
      "epoch": 9.593730006397953,
      "grad_norm": 0.2537742257118225,
      "learning_rate": 7.195833333333334e-06,
      "loss": 0.0033,
      "step": 2820
    },
    {
      "epoch": 9.661974834719556,
      "grad_norm": 3.6999735832214355,
      "learning_rate": 7.168055555555556e-06,
      "loss": 0.0061,
      "step": 2840
    },
    {
      "epoch": 9.73021966304116,
      "grad_norm": 1.6360400915145874,
      "learning_rate": 7.140277777777779e-06,
      "loss": 0.0055,
      "step": 2860
    },
    {
      "epoch": 9.798464491362765,
      "grad_norm": 2.9058361053466797,
      "learning_rate": 7.112500000000001e-06,
      "loss": 0.0071,
      "step": 2880
    },
    {
      "epoch": 9.866709319684368,
      "grad_norm": 0.6449500322341919,
      "learning_rate": 7.084722222222222e-06,
      "loss": 0.0061,
      "step": 2900
    },
    {
      "epoch": 9.934954148005971,
      "grad_norm": 0.18363939225673676,
      "learning_rate": 7.056944444444445e-06,
      "loss": 0.0071,
      "step": 2920
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.4396514296531677,
      "learning_rate": 7.029166666666667e-06,
      "loss": 0.0064,
      "step": 2940
    },
    {
      "epoch": 10.068244828321603,
      "grad_norm": 0.06060492992401123,
      "learning_rate": 7.001388888888889e-06,
      "loss": 0.0025,
      "step": 2960
    },
    {
      "epoch": 10.136489656643208,
      "grad_norm": 0.46857473254203796,
      "learning_rate": 6.973611111111112e-06,
      "loss": 0.0031,
      "step": 2980
    },
    {
      "epoch": 10.204734484964812,
      "grad_norm": 3.8683981895446777,
      "learning_rate": 6.945833333333334e-06,
      "loss": 0.0044,
      "step": 3000
    },
    {
      "epoch": 10.204734484964812,
      "eval_accuracy": 0.9034517258629314,
      "eval_loss": 0.6934652924537659,
      "eval_macro_f1": 0.8909849464188584,
      "eval_macro_precision": 0.889665547017385,
      "eval_macro_recall": 0.892354376915347,
      "eval_runtime": 1.5185,
      "eval_samples_per_second": 1316.414,
      "eval_steps_per_second": 41.488,
      "step": 3000
    },
    {
      "epoch": 10.272979313286415,
      "grad_norm": 2.427304744720459,
      "learning_rate": 6.918055555555556e-06,
      "loss": 0.0037,
      "step": 3020
    },
    {
      "epoch": 10.341224141608018,
      "grad_norm": 2.12630558013916,
      "learning_rate": 6.890277777777779e-06,
      "loss": 0.0049,
      "step": 3040
    },
    {
      "epoch": 10.409468969929623,
      "grad_norm": 1.2109248638153076,
      "learning_rate": 6.862500000000001e-06,
      "loss": 0.0039,
      "step": 3060
    },
    {
      "epoch": 10.477713798251227,
      "grad_norm": 0.0949244275689125,
      "learning_rate": 6.834722222222223e-06,
      "loss": 0.0037,
      "step": 3080
    },
    {
      "epoch": 10.54595862657283,
      "grad_norm": 5.501417636871338,
      "learning_rate": 6.806944444444446e-06,
      "loss": 0.0047,
      "step": 3100
    },
    {
      "epoch": 10.614203454894433,
      "grad_norm": 0.7196930050849915,
      "learning_rate": 6.779166666666667e-06,
      "loss": 0.0059,
      "step": 3120
    },
    {
      "epoch": 10.682448283216038,
      "grad_norm": 3.2089128494262695,
      "learning_rate": 6.751388888888889e-06,
      "loss": 0.0032,
      "step": 3140
    },
    {
      "epoch": 10.750693111537641,
      "grad_norm": 1.9569413661956787,
      "learning_rate": 6.723611111111112e-06,
      "loss": 0.0061,
      "step": 3160
    },
    {
      "epoch": 10.818937939859245,
      "grad_norm": 2.021953582763672,
      "learning_rate": 6.695833333333334e-06,
      "loss": 0.0043,
      "step": 3180
    },
    {
      "epoch": 10.88718276818085,
      "grad_norm": 1.2646056413650513,
      "learning_rate": 6.668055555555556e-06,
      "loss": 0.0036,
      "step": 3200
    },
    {
      "epoch": 10.955427596502453,
      "grad_norm": 3.3740932941436768,
      "learning_rate": 6.640277777777779e-06,
      "loss": 0.0057,
      "step": 3220
    },
    {
      "epoch": 11.020473448496482,
      "grad_norm": 0.29691949486732483,
      "learning_rate": 6.612500000000001e-06,
      "loss": 0.0053,
      "step": 3240
    },
    {
      "epoch": 11.088718276818085,
      "grad_norm": 1.4463212490081787,
      "learning_rate": 6.584722222222223e-06,
      "loss": 0.0031,
      "step": 3260
    },
    {
      "epoch": 11.156963105139688,
      "grad_norm": 0.52019202709198,
      "learning_rate": 6.5569444444444455e-06,
      "loss": 0.0026,
      "step": 3280
    },
    {
      "epoch": 11.225207933461292,
      "grad_norm": 0.11835174262523651,
      "learning_rate": 6.5291666666666675e-06,
      "loss": 0.0039,
      "step": 3300
    },
    {
      "epoch": 11.293452761782897,
      "grad_norm": 0.35391518473625183,
      "learning_rate": 6.5013888888888896e-06,
      "loss": 0.0021,
      "step": 3320
    },
    {
      "epoch": 11.3616975901045,
      "grad_norm": 1.7961195707321167,
      "learning_rate": 6.473611111111112e-06,
      "loss": 0.0032,
      "step": 3340
    },
    {
      "epoch": 11.429942418426103,
      "grad_norm": 5.728837013244629,
      "learning_rate": 6.445833333333334e-06,
      "loss": 0.0047,
      "step": 3360
    },
    {
      "epoch": 11.498187246747708,
      "grad_norm": 1.2441978454589844,
      "learning_rate": 6.418055555555556e-06,
      "loss": 0.0032,
      "step": 3380
    },
    {
      "epoch": 11.566432075069311,
      "grad_norm": 1.7789126634597778,
      "learning_rate": 6.390277777777778e-06,
      "loss": 0.0048,
      "step": 3400
    },
    {
      "epoch": 11.634676903390915,
      "grad_norm": 0.2008301317691803,
      "learning_rate": 6.3625000000000005e-06,
      "loss": 0.0032,
      "step": 3420
    },
    {
      "epoch": 11.702921731712518,
      "grad_norm": 1.9502017498016357,
      "learning_rate": 6.3347222222222225e-06,
      "loss": 0.0033,
      "step": 3440
    },
    {
      "epoch": 11.771166560034123,
      "grad_norm": 0.3959953486919403,
      "learning_rate": 6.306944444444445e-06,
      "loss": 0.0041,
      "step": 3460
    },
    {
      "epoch": 11.839411388355726,
      "grad_norm": 0.6872938275337219,
      "learning_rate": 6.279166666666667e-06,
      "loss": 0.0037,
      "step": 3480
    },
    {
      "epoch": 11.90765621667733,
      "grad_norm": 2.0513947010040283,
      "learning_rate": 6.251388888888889e-06,
      "loss": 0.0057,
      "step": 3500
    },
    {
      "epoch": 11.90765621667733,
      "eval_accuracy": 0.9094547273636818,
      "eval_loss": 0.6507842540740967,
      "eval_macro_f1": 0.8972880413846707,
      "eval_macro_precision": 0.8977564430499188,
      "eval_macro_recall": 0.8968253158125155,
      "eval_runtime": 1.5199,
      "eval_samples_per_second": 1315.211,
      "eval_steps_per_second": 41.45,
      "step": 3500
    },
    {
      "epoch": 11.975901044998933,
      "grad_norm": 6.044793605804443,
      "learning_rate": 6.223611111111112e-06,
      "loss": 0.0067,
      "step": 3520
    },
    {
      "epoch": 12.040946896992962,
      "grad_norm": 2.816484212875366,
      "learning_rate": 6.195833333333334e-06,
      "loss": 0.003,
      "step": 3540
    },
    {
      "epoch": 12.109191725314567,
      "grad_norm": 4.140778064727783,
      "learning_rate": 6.168055555555556e-06,
      "loss": 0.0022,
      "step": 3560
    },
    {
      "epoch": 12.17743655363617,
      "grad_norm": 0.13693204522132874,
      "learning_rate": 6.1402777777777775e-06,
      "loss": 0.0021,
      "step": 3580
    },
    {
      "epoch": 12.245681381957773,
      "grad_norm": 0.4039716124534607,
      "learning_rate": 6.1125e-06,
      "loss": 0.0024,
      "step": 3600
    },
    {
      "epoch": 12.313926210279377,
      "grad_norm": 0.052819475531578064,
      "learning_rate": 6.084722222222222e-06,
      "loss": 0.0025,
      "step": 3620
    },
    {
      "epoch": 12.382171038600982,
      "grad_norm": 1.560268521308899,
      "learning_rate": 6.056944444444444e-06,
      "loss": 0.0033,
      "step": 3640
    },
    {
      "epoch": 12.450415866922585,
      "grad_norm": 9.093276977539062,
      "learning_rate": 6.029166666666667e-06,
      "loss": 0.0043,
      "step": 3660
    },
    {
      "epoch": 12.518660695244188,
      "grad_norm": 0.9509903788566589,
      "learning_rate": 6.001388888888889e-06,
      "loss": 0.0023,
      "step": 3680
    },
    {
      "epoch": 12.586905523565793,
      "grad_norm": 3.4257009029388428,
      "learning_rate": 5.973611111111111e-06,
      "loss": 0.0029,
      "step": 3700
    },
    {
      "epoch": 12.655150351887396,
      "grad_norm": 0.02706819586455822,
      "learning_rate": 5.945833333333334e-06,
      "loss": 0.0041,
      "step": 3720
    },
    {
      "epoch": 12.723395180209,
      "grad_norm": 5.314725875854492,
      "learning_rate": 5.918055555555556e-06,
      "loss": 0.0027,
      "step": 3740
    },
    {
      "epoch": 12.791640008530603,
      "grad_norm": 2.2238190174102783,
      "learning_rate": 5.890277777777779e-06,
      "loss": 0.0038,
      "step": 3760
    },
    {
      "epoch": 12.859884836852208,
      "grad_norm": 4.600825786590576,
      "learning_rate": 5.862500000000001e-06,
      "loss": 0.0044,
      "step": 3780
    },
    {
      "epoch": 12.928129665173811,
      "grad_norm": 1.710140347480774,
      "learning_rate": 5.834722222222222e-06,
      "loss": 0.0035,
      "step": 3800
    },
    {
      "epoch": 12.996374493495415,
      "grad_norm": 1.3956730365753174,
      "learning_rate": 5.806944444444444e-06,
      "loss": 0.0029,
      "step": 3820
    },
    {
      "epoch": 13.061420345489443,
      "grad_norm": 0.09341356158256531,
      "learning_rate": 5.779166666666667e-06,
      "loss": 0.0018,
      "step": 3840
    },
    {
      "epoch": 13.129665173811047,
      "grad_norm": 0.19729119539260864,
      "learning_rate": 5.751388888888889e-06,
      "loss": 0.0011,
      "step": 3860
    },
    {
      "epoch": 13.197910002132652,
      "grad_norm": 0.22213374078273773,
      "learning_rate": 5.723611111111111e-06,
      "loss": 0.0025,
      "step": 3880
    },
    {
      "epoch": 13.266154830454255,
      "grad_norm": 3.7547481060028076,
      "learning_rate": 5.695833333333334e-06,
      "loss": 0.0021,
      "step": 3900
    },
    {
      "epoch": 13.334399658775858,
      "grad_norm": 0.03689102828502655,
      "learning_rate": 5.668055555555556e-06,
      "loss": 0.0025,
      "step": 3920
    },
    {
      "epoch": 13.402644487097461,
      "grad_norm": 0.02501070126891136,
      "learning_rate": 5.640277777777778e-06,
      "loss": 0.0008,
      "step": 3940
    },
    {
      "epoch": 13.470889315419067,
      "grad_norm": 0.020902171730995178,
      "learning_rate": 5.612500000000001e-06,
      "loss": 0.0028,
      "step": 3960
    },
    {
      "epoch": 13.53913414374067,
      "grad_norm": 3.1884820461273193,
      "learning_rate": 5.584722222222223e-06,
      "loss": 0.0028,
      "step": 3980
    },
    {
      "epoch": 13.607378972062273,
      "grad_norm": 6.655941009521484,
      "learning_rate": 5.556944444444446e-06,
      "loss": 0.0018,
      "step": 4000
    },
    {
      "epoch": 13.607378972062273,
      "eval_accuracy": 0.9149574787393697,
      "eval_loss": 0.7518956065177917,
      "eval_macro_f1": 0.9027988485626484,
      "eval_macro_precision": 0.9065416676287898,
      "eval_macro_recall": 0.8993698494035345,
      "eval_runtime": 1.5256,
      "eval_samples_per_second": 1310.284,
      "eval_steps_per_second": 41.295,
      "step": 4000
    },
    {
      "epoch": 13.675623800383876,
      "grad_norm": 0.49831727147102356,
      "learning_rate": 5.529166666666667e-06,
      "loss": 0.0062,
      "step": 4020
    },
    {
      "epoch": 13.743868628705481,
      "grad_norm": 1.2944979667663574,
      "learning_rate": 5.501388888888889e-06,
      "loss": 0.0046,
      "step": 4040
    },
    {
      "epoch": 13.812113457027085,
      "grad_norm": 2.7832796573638916,
      "learning_rate": 5.473611111111111e-06,
      "loss": 0.0047,
      "step": 4060
    },
    {
      "epoch": 13.880358285348688,
      "grad_norm": 1.721737027168274,
      "learning_rate": 5.445833333333334e-06,
      "loss": 0.0029,
      "step": 4080
    },
    {
      "epoch": 13.948603113670291,
      "grad_norm": 3.023157835006714,
      "learning_rate": 5.418055555555556e-06,
      "loss": 0.0028,
      "step": 4100
    },
    {
      "epoch": 14.01364896566432,
      "grad_norm": 0.015122739598155022,
      "learning_rate": 5.390277777777778e-06,
      "loss": 0.0025,
      "step": 4120
    },
    {
      "epoch": 14.081893793985925,
      "grad_norm": 0.02428651973605156,
      "learning_rate": 5.362500000000001e-06,
      "loss": 0.0013,
      "step": 4140
    },
    {
      "epoch": 14.150138622307528,
      "grad_norm": 7.1201066970825195,
      "learning_rate": 5.334722222222223e-06,
      "loss": 0.0015,
      "step": 4160
    },
    {
      "epoch": 14.218383450629132,
      "grad_norm": 0.008991439826786518,
      "learning_rate": 5.306944444444445e-06,
      "loss": 0.0008,
      "step": 4180
    },
    {
      "epoch": 14.286628278950737,
      "grad_norm": 7.35733699798584,
      "learning_rate": 5.279166666666668e-06,
      "loss": 0.0017,
      "step": 4200
    },
    {
      "epoch": 14.35487310727234,
      "grad_norm": 0.8837898969650269,
      "learning_rate": 5.25138888888889e-06,
      "loss": 0.0019,
      "step": 4220
    },
    {
      "epoch": 14.423117935593943,
      "grad_norm": 0.0036298995837569237,
      "learning_rate": 5.223611111111112e-06,
      "loss": 0.0011,
      "step": 4240
    },
    {
      "epoch": 14.491362763915546,
      "grad_norm": 1.0525931119918823,
      "learning_rate": 5.195833333333334e-06,
      "loss": 0.0019,
      "step": 4260
    },
    {
      "epoch": 14.559607592237152,
      "grad_norm": 0.044009871780872345,
      "learning_rate": 5.168055555555556e-06,
      "loss": 0.0014,
      "step": 4280
    },
    {
      "epoch": 14.627852420558755,
      "grad_norm": 0.5525549054145813,
      "learning_rate": 5.140277777777778e-06,
      "loss": 0.0027,
      "step": 4300
    },
    {
      "epoch": 14.696097248880358,
      "grad_norm": 0.7206804156303406,
      "learning_rate": 5.112500000000001e-06,
      "loss": 0.0026,
      "step": 4320
    },
    {
      "epoch": 14.764342077201961,
      "grad_norm": 0.25027355551719666,
      "learning_rate": 5.084722222222223e-06,
      "loss": 0.0017,
      "step": 4340
    },
    {
      "epoch": 14.832586905523566,
      "grad_norm": 0.5713391304016113,
      "learning_rate": 5.056944444444445e-06,
      "loss": 0.002,
      "step": 4360
    },
    {
      "epoch": 14.90083173384517,
      "grad_norm": 2.9490909576416016,
      "learning_rate": 5.0291666666666675e-06,
      "loss": 0.0014,
      "step": 4380
    },
    {
      "epoch": 14.969076562166773,
      "grad_norm": 0.18238288164138794,
      "learning_rate": 5.0013888888888895e-06,
      "loss": 0.0023,
      "step": 4400
    },
    {
      "epoch": 15.034122414160802,
      "grad_norm": 0.2040543258190155,
      "learning_rate": 4.9736111111111115e-06,
      "loss": 0.002,
      "step": 4420
    },
    {
      "epoch": 15.102367242482405,
      "grad_norm": 3.0770111083984375,
      "learning_rate": 4.9458333333333336e-06,
      "loss": 0.001,
      "step": 4440
    },
    {
      "epoch": 15.17061207080401,
      "grad_norm": 0.039149198681116104,
      "learning_rate": 4.9180555555555556e-06,
      "loss": 0.0011,
      "step": 4460
    },
    {
      "epoch": 15.238856899125613,
      "grad_norm": 0.0921538844704628,
      "learning_rate": 4.8902777777777784e-06,
      "loss": 0.0013,
      "step": 4480
    },
    {
      "epoch": 15.307101727447217,
      "grad_norm": 0.008618799969553947,
      "learning_rate": 4.8625000000000005e-06,
      "loss": 0.0007,
      "step": 4500
    },
    {
      "epoch": 15.307101727447217,
      "eval_accuracy": 0.9184592296148074,
      "eval_loss": 0.7488622069358826,
      "eval_macro_f1": 0.9068389007781128,
      "eval_macro_precision": 0.9104333070317511,
      "eval_macro_recall": 0.9035317241582681,
      "eval_runtime": 1.5078,
      "eval_samples_per_second": 1325.73,
      "eval_steps_per_second": 41.781,
      "step": 4500
    }
  ],
  "logging_steps": 20,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 28,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.78029569102515e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
