{
  "best_global_step": 8000,
  "best_metric": 84.22676178497052,
  "best_model_checkpoint": "output/mt5-xl_hebnli/checkpoint-8000",
  "epoch": 2.5592257858114054,
  "eval_steps": 500,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006398464368551547,
      "grad_norm": 55.8962287902832,
      "learning_rate": 2.3750000000000003e-07,
      "loss": 12.5322,
      "step": 20
    },
    {
      "epoch": 0.012796928737103095,
      "grad_norm": 63.03684997558594,
      "learning_rate": 4.875000000000001e-07,
      "loss": 12.0761,
      "step": 40
    },
    {
      "epoch": 0.019195393105654643,
      "grad_norm": 58.259490966796875,
      "learning_rate": 7.375e-07,
      "loss": 11.462,
      "step": 60
    },
    {
      "epoch": 0.02559385747420619,
      "grad_norm": 66.75473022460938,
      "learning_rate": 9.875e-07,
      "loss": 10.9955,
      "step": 80
    },
    {
      "epoch": 0.031992321842757736,
      "grad_norm": 77.37329864501953,
      "learning_rate": 1.2375e-06,
      "loss": 10.2146,
      "step": 100
    },
    {
      "epoch": 0.038390786211309286,
      "grad_norm": 56.90958023071289,
      "learning_rate": 1.4875000000000002e-06,
      "loss": 9.5429,
      "step": 120
    },
    {
      "epoch": 0.044789250579860836,
      "grad_norm": 42.50389099121094,
      "learning_rate": 1.7375e-06,
      "loss": 8.7301,
      "step": 140
    },
    {
      "epoch": 0.05118771494841238,
      "grad_norm": 31.5867862701416,
      "learning_rate": 1.9875000000000005e-06,
      "loss": 7.9129,
      "step": 160
    },
    {
      "epoch": 0.05758617931696393,
      "grad_norm": 70.47509002685547,
      "learning_rate": 2.2375e-06,
      "loss": 7.1903,
      "step": 180
    },
    {
      "epoch": 0.06398464368551547,
      "grad_norm": 29.2584171295166,
      "learning_rate": 2.4875000000000003e-06,
      "loss": 6.3578,
      "step": 200
    },
    {
      "epoch": 0.07038310805406703,
      "grad_norm": 46.4965705871582,
      "learning_rate": 2.7375e-06,
      "loss": 5.4485,
      "step": 220
    },
    {
      "epoch": 0.07678157242261857,
      "grad_norm": 33.314720153808594,
      "learning_rate": 2.9875e-06,
      "loss": 4.4692,
      "step": 240
    },
    {
      "epoch": 0.08318003679117011,
      "grad_norm": 27.631128311157227,
      "learning_rate": 3.2375e-06,
      "loss": 3.5252,
      "step": 260
    },
    {
      "epoch": 0.08957850115972167,
      "grad_norm": 118.36449432373047,
      "learning_rate": 3.4875000000000005e-06,
      "loss": 2.6781,
      "step": 280
    },
    {
      "epoch": 0.09597696552827321,
      "grad_norm": 62.94856643676758,
      "learning_rate": 3.7375000000000006e-06,
      "loss": 1.91,
      "step": 300
    },
    {
      "epoch": 0.10237542989682476,
      "grad_norm": 10.82402515411377,
      "learning_rate": 3.9875e-06,
      "loss": 1.1902,
      "step": 320
    },
    {
      "epoch": 0.10877389426537631,
      "grad_norm": 8.231573104858398,
      "learning_rate": 4.2375000000000005e-06,
      "loss": 0.7635,
      "step": 340
    },
    {
      "epoch": 0.11517235863392786,
      "grad_norm": 5.425424098968506,
      "learning_rate": 4.4875e-06,
      "loss": 0.6239,
      "step": 360
    },
    {
      "epoch": 0.1215708230024794,
      "grad_norm": 7.70555305480957,
      "learning_rate": 4.737500000000001e-06,
      "loss": 0.5041,
      "step": 380
    },
    {
      "epoch": 0.12796928737103094,
      "grad_norm": 13.817839622497559,
      "learning_rate": 4.987500000000001e-06,
      "loss": 0.4704,
      "step": 400
    },
    {
      "epoch": 0.1343677517395825,
      "grad_norm": 4.735315799713135,
      "learning_rate": 5.237500000000001e-06,
      "loss": 0.4598,
      "step": 420
    },
    {
      "epoch": 0.14076621610813406,
      "grad_norm": 15.188695907592773,
      "learning_rate": 5.4875e-06,
      "loss": 0.4374,
      "step": 440
    },
    {
      "epoch": 0.1471646804766856,
      "grad_norm": 6.300380706787109,
      "learning_rate": 5.7375000000000005e-06,
      "loss": 0.4091,
      "step": 460
    },
    {
      "epoch": 0.15356314484523714,
      "grad_norm": 8.370138168334961,
      "learning_rate": 5.987500000000001e-06,
      "loss": 0.4118,
      "step": 480
    },
    {
      "epoch": 0.15996160921378869,
      "grad_norm": 6.732928276062012,
      "learning_rate": 6.237500000000001e-06,
      "loss": 0.3892,
      "step": 500
    },
    {
      "epoch": 0.15996160921378869,
      "eval_accuracy": 41.220610305152576,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 0.3044140030440491,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 51.9285042332976,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 44.60905349793741,
      "eval_loss": 0.29401466250419617,
      "eval_macro_f1": 32.28065724475969,
      "eval_runtime": 53.9379,
      "eval_samples_per_second": 37.061,
      "eval_steps_per_second": 1.168,
      "step": 500
    },
    {
      "epoch": 0.16636007358234023,
      "grad_norm": 2.9905686378479004,
      "learning_rate": 6.487500000000001e-06,
      "loss": 0.3833,
      "step": 520
    },
    {
      "epoch": 0.1727585379508918,
      "grad_norm": 2.2548351287841797,
      "learning_rate": 6.7375e-06,
      "loss": 0.3804,
      "step": 540
    },
    {
      "epoch": 0.17915700231944334,
      "grad_norm": 6.1654558181762695,
      "learning_rate": 6.9875000000000004e-06,
      "loss": 0.3706,
      "step": 560
    },
    {
      "epoch": 0.18555546668799489,
      "grad_norm": 2.709010601043701,
      "learning_rate": 7.237500000000001e-06,
      "loss": 0.3583,
      "step": 580
    },
    {
      "epoch": 0.19195393105654643,
      "grad_norm": 2.5797903537750244,
      "learning_rate": 7.487500000000001e-06,
      "loss": 0.3519,
      "step": 600
    },
    {
      "epoch": 0.19835239542509797,
      "grad_norm": 9.403497695922852,
      "learning_rate": 7.737500000000002e-06,
      "loss": 0.3374,
      "step": 620
    },
    {
      "epoch": 0.20475085979364951,
      "grad_norm": 2.5768871307373047,
      "learning_rate": 7.987500000000001e-06,
      "loss": 0.3346,
      "step": 640
    },
    {
      "epoch": 0.21114932416220109,
      "grad_norm": 14.141643524169922,
      "learning_rate": 8.2375e-06,
      "loss": 0.3302,
      "step": 660
    },
    {
      "epoch": 0.21754778853075263,
      "grad_norm": 1.9655077457427979,
      "learning_rate": 8.487500000000001e-06,
      "loss": 0.3117,
      "step": 680
    },
    {
      "epoch": 0.22394625289930417,
      "grad_norm": 4.39089298248291,
      "learning_rate": 8.7375e-06,
      "loss": 0.3079,
      "step": 700
    },
    {
      "epoch": 0.23034471726785571,
      "grad_norm": 3.464536428451538,
      "learning_rate": 8.987500000000002e-06,
      "loss": 0.3052,
      "step": 720
    },
    {
      "epoch": 0.23674318163640726,
      "grad_norm": 49.42022705078125,
      "learning_rate": 9.237500000000001e-06,
      "loss": 0.2912,
      "step": 740
    },
    {
      "epoch": 0.2431416460049588,
      "grad_norm": 2.0905425548553467,
      "learning_rate": 9.4875e-06,
      "loss": 0.2727,
      "step": 760
    },
    {
      "epoch": 0.24954011037351037,
      "grad_norm": 2.9325814247131348,
      "learning_rate": 9.737500000000001e-06,
      "loss": 0.2677,
      "step": 780
    },
    {
      "epoch": 0.2559385747420619,
      "grad_norm": 2.3089356422424316,
      "learning_rate": 9.9875e-06,
      "loss": 0.2652,
      "step": 800
    },
    {
      "epoch": 0.26233703911061346,
      "grad_norm": 2.4333839416503906,
      "learning_rate": 9.973611111111113e-06,
      "loss": 0.2599,
      "step": 820
    },
    {
      "epoch": 0.268735503479165,
      "grad_norm": 3.2863564491271973,
      "learning_rate": 9.945833333333334e-06,
      "loss": 0.2304,
      "step": 840
    },
    {
      "epoch": 0.27513396784771654,
      "grad_norm": 2.679483652114868,
      "learning_rate": 9.918055555555557e-06,
      "loss": 0.2431,
      "step": 860
    },
    {
      "epoch": 0.2815324322162681,
      "grad_norm": 3.236112117767334,
      "learning_rate": 9.890277777777778e-06,
      "loss": 0.2276,
      "step": 880
    },
    {
      "epoch": 0.28793089658481963,
      "grad_norm": 2.9375736713409424,
      "learning_rate": 9.862500000000001e-06,
      "loss": 0.2269,
      "step": 900
    },
    {
      "epoch": 0.2943293609533712,
      "grad_norm": 2.657123327255249,
      "learning_rate": 9.834722222222222e-06,
      "loss": 0.2172,
      "step": 920
    },
    {
      "epoch": 0.3007278253219227,
      "grad_norm": 4.015468120574951,
      "learning_rate": 9.806944444444445e-06,
      "loss": 0.2122,
      "step": 940
    },
    {
      "epoch": 0.3071262896904743,
      "grad_norm": 4.512309551239014,
      "learning_rate": 9.779166666666668e-06,
      "loss": 0.2251,
      "step": 960
    },
    {
      "epoch": 0.31352475405902586,
      "grad_norm": 2.2848916053771973,
      "learning_rate": 9.751388888888889e-06,
      "loss": 0.2125,
      "step": 980
    },
    {
      "epoch": 0.31992321842757737,
      "grad_norm": 2.271963357925415,
      "learning_rate": 9.723611111111112e-06,
      "loss": 0.2158,
      "step": 1000
    },
    {
      "epoch": 0.31992321842757737,
      "eval_accuracy": 77.18859429714857,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 79.7111913357351,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 72.18390804597203,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 79.51070336390937,
      "eval_loss": 0.15889815986156464,
      "eval_macro_f1": 77.13526758187216,
      "eval_runtime": 53.2683,
      "eval_samples_per_second": 37.527,
      "eval_steps_per_second": 1.183,
      "step": 1000
    },
    {
      "epoch": 0.32632168279612894,
      "grad_norm": 1.829918384552002,
      "learning_rate": 9.695833333333335e-06,
      "loss": 0.2167,
      "step": 1020
    },
    {
      "epoch": 0.33272014716468046,
      "grad_norm": 6.761082172393799,
      "learning_rate": 9.668055555555556e-06,
      "loss": 0.2024,
      "step": 1040
    },
    {
      "epoch": 0.33911861153323203,
      "grad_norm": 2.328329086303711,
      "learning_rate": 9.640277777777779e-06,
      "loss": 0.1974,
      "step": 1060
    },
    {
      "epoch": 0.3455170759017836,
      "grad_norm": 1.6913836002349854,
      "learning_rate": 9.612500000000002e-06,
      "loss": 0.2111,
      "step": 1080
    },
    {
      "epoch": 0.3519155402703351,
      "grad_norm": 2.617983102798462,
      "learning_rate": 9.584722222222223e-06,
      "loss": 0.2061,
      "step": 1100
    },
    {
      "epoch": 0.3583140046388867,
      "grad_norm": 2.1948177814483643,
      "learning_rate": 9.556944444444446e-06,
      "loss": 0.1993,
      "step": 1120
    },
    {
      "epoch": 0.3647124690074382,
      "grad_norm": 2.641573667526245,
      "learning_rate": 9.529166666666667e-06,
      "loss": 0.1911,
      "step": 1140
    },
    {
      "epoch": 0.37111093337598977,
      "grad_norm": 2.616065740585327,
      "learning_rate": 9.50138888888889e-06,
      "loss": 0.2024,
      "step": 1160
    },
    {
      "epoch": 0.3775093977445413,
      "grad_norm": 1.7375192642211914,
      "learning_rate": 9.473611111111112e-06,
      "loss": 0.1907,
      "step": 1180
    },
    {
      "epoch": 0.38390786211309286,
      "grad_norm": 5.160122394561768,
      "learning_rate": 9.445833333333334e-06,
      "loss": 0.1955,
      "step": 1200
    },
    {
      "epoch": 0.39030632648164443,
      "grad_norm": 1.911939024925232,
      "learning_rate": 9.418055555555557e-06,
      "loss": 0.1879,
      "step": 1220
    },
    {
      "epoch": 0.39670479085019594,
      "grad_norm": 2.0255022048950195,
      "learning_rate": 9.39027777777778e-06,
      "loss": 0.2027,
      "step": 1240
    },
    {
      "epoch": 0.4031032552187475,
      "grad_norm": 1.7348384857177734,
      "learning_rate": 9.3625e-06,
      "loss": 0.197,
      "step": 1260
    },
    {
      "epoch": 0.40950171958729903,
      "grad_norm": 1.4401706457138062,
      "learning_rate": 9.334722222222223e-06,
      "loss": 0.1902,
      "step": 1280
    },
    {
      "epoch": 0.4159001839558506,
      "grad_norm": 22.58856773376465,
      "learning_rate": 9.306944444444446e-06,
      "loss": 0.1772,
      "step": 1300
    },
    {
      "epoch": 0.42229864832440217,
      "grad_norm": 2.417928695678711,
      "learning_rate": 9.279166666666667e-06,
      "loss": 0.1951,
      "step": 1320
    },
    {
      "epoch": 0.4286971126929537,
      "grad_norm": 1.7203630208969116,
      "learning_rate": 9.251388888888889e-06,
      "loss": 0.1728,
      "step": 1340
    },
    {
      "epoch": 0.43509557706150526,
      "grad_norm": 1.8023314476013184,
      "learning_rate": 9.223611111111112e-06,
      "loss": 0.1813,
      "step": 1360
    },
    {
      "epoch": 0.44149404143005677,
      "grad_norm": 1.6735652685165405,
      "learning_rate": 9.195833333333334e-06,
      "loss": 0.1805,
      "step": 1380
    },
    {
      "epoch": 0.44789250579860834,
      "grad_norm": 1.5455421209335327,
      "learning_rate": 9.168055555555556e-06,
      "loss": 0.1834,
      "step": 1400
    },
    {
      "epoch": 0.45429097016715986,
      "grad_norm": 1.7185386419296265,
      "learning_rate": 9.140277777777778e-06,
      "loss": 0.1727,
      "step": 1420
    },
    {
      "epoch": 0.46068943453571143,
      "grad_norm": 1.5663002729415894,
      "learning_rate": 9.112500000000001e-06,
      "loss": 0.1864,
      "step": 1440
    },
    {
      "epoch": 0.467087898904263,
      "grad_norm": 1.4114925861358643,
      "learning_rate": 9.084722222222222e-06,
      "loss": 0.1788,
      "step": 1460
    },
    {
      "epoch": 0.4734863632728145,
      "grad_norm": 1.8712960481643677,
      "learning_rate": 9.056944444444445e-06,
      "loss": 0.1754,
      "step": 1480
    },
    {
      "epoch": 0.4798848276413661,
      "grad_norm": 1.3866032361984253,
      "learning_rate": 9.029166666666668e-06,
      "loss": 0.1743,
      "step": 1500
    },
    {
      "epoch": 0.4798848276413661,
      "eval_accuracy": 81.09054527263632,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 82.60233918128156,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 77.39520958083334,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 83.30757341576009,
      "eval_loss": 0.14197486639022827,
      "eval_macro_f1": 81.10170739262499,
      "eval_runtime": 53.1969,
      "eval_samples_per_second": 37.577,
      "eval_steps_per_second": 1.184,
      "step": 1500
    },
    {
      "epoch": 0.4862832920099176,
      "grad_norm": 3.2337422370910645,
      "learning_rate": 9.00138888888889e-06,
      "loss": 0.1763,
      "step": 1520
    },
    {
      "epoch": 0.49268175637846917,
      "grad_norm": 1.752805233001709,
      "learning_rate": 8.973611111111112e-06,
      "loss": 0.1806,
      "step": 1540
    },
    {
      "epoch": 0.49908022074702074,
      "grad_norm": 1.545333743095398,
      "learning_rate": 8.945833333333333e-06,
      "loss": 0.1811,
      "step": 1560
    },
    {
      "epoch": 0.5054786851155723,
      "grad_norm": 1.6153254508972168,
      "learning_rate": 8.918055555555556e-06,
      "loss": 0.1673,
      "step": 1580
    },
    {
      "epoch": 0.5118771494841238,
      "grad_norm": 1.7813714742660522,
      "learning_rate": 8.890277777777777e-06,
      "loss": 0.1673,
      "step": 1600
    },
    {
      "epoch": 0.5182756138526754,
      "grad_norm": 2.3877809047698975,
      "learning_rate": 8.8625e-06,
      "loss": 0.1639,
      "step": 1620
    },
    {
      "epoch": 0.5246740782212269,
      "grad_norm": 1.575144648551941,
      "learning_rate": 8.834722222222223e-06,
      "loss": 0.1689,
      "step": 1640
    },
    {
      "epoch": 0.5310725425897784,
      "grad_norm": 1.7972936630249023,
      "learning_rate": 8.806944444444446e-06,
      "loss": 0.1811,
      "step": 1660
    },
    {
      "epoch": 0.53747100695833,
      "grad_norm": 1.6098238229751587,
      "learning_rate": 8.779166666666667e-06,
      "loss": 0.1631,
      "step": 1680
    },
    {
      "epoch": 0.5438694713268816,
      "grad_norm": 2.3595306873321533,
      "learning_rate": 8.75138888888889e-06,
      "loss": 0.1696,
      "step": 1700
    },
    {
      "epoch": 0.5502679356954331,
      "grad_norm": 1.7325917482376099,
      "learning_rate": 8.723611111111113e-06,
      "loss": 0.1719,
      "step": 1720
    },
    {
      "epoch": 0.5566664000639846,
      "grad_norm": 1.5546882152557373,
      "learning_rate": 8.695833333333334e-06,
      "loss": 0.1757,
      "step": 1740
    },
    {
      "epoch": 0.5630648644325362,
      "grad_norm": 2.1290135383605957,
      "learning_rate": 8.668055555555557e-06,
      "loss": 0.1664,
      "step": 1760
    },
    {
      "epoch": 0.5694633288010877,
      "grad_norm": 1.317030668258667,
      "learning_rate": 8.640277777777778e-06,
      "loss": 0.1718,
      "step": 1780
    },
    {
      "epoch": 0.5758617931696393,
      "grad_norm": 3.6283175945281982,
      "learning_rate": 8.612500000000001e-06,
      "loss": 0.1711,
      "step": 1800
    },
    {
      "epoch": 0.5822602575381909,
      "grad_norm": 1.9954015016555786,
      "learning_rate": 8.584722222222222e-06,
      "loss": 0.1589,
      "step": 1820
    },
    {
      "epoch": 0.5886587219067424,
      "grad_norm": 1.4675853252410889,
      "learning_rate": 8.556944444444445e-06,
      "loss": 0.1679,
      "step": 1840
    },
    {
      "epoch": 0.5950571862752939,
      "grad_norm": 1.4804939031600952,
      "learning_rate": 8.529166666666668e-06,
      "loss": 0.157,
      "step": 1860
    },
    {
      "epoch": 0.6014556506438454,
      "grad_norm": 1.6414334774017334,
      "learning_rate": 8.501388888888889e-06,
      "loss": 0.1681,
      "step": 1880
    },
    {
      "epoch": 0.6078541150123971,
      "grad_norm": 1.5729728937149048,
      "learning_rate": 8.473611111111112e-06,
      "loss": 0.1646,
      "step": 1900
    },
    {
      "epoch": 0.6142525793809486,
      "grad_norm": 1.2926231622695923,
      "learning_rate": 8.445833333333335e-06,
      "loss": 0.1605,
      "step": 1920
    },
    {
      "epoch": 0.6206510437495001,
      "grad_norm": 1.4543880224227905,
      "learning_rate": 8.418055555555556e-06,
      "loss": 0.1667,
      "step": 1940
    },
    {
      "epoch": 0.6270495081180517,
      "grad_norm": 1.741237759590149,
      "learning_rate": 8.390277777777779e-06,
      "loss": 0.1509,
      "step": 1960
    },
    {
      "epoch": 0.6334479724866032,
      "grad_norm": 1.7812472581863403,
      "learning_rate": 8.362500000000002e-06,
      "loss": 0.163,
      "step": 1980
    },
    {
      "epoch": 0.6398464368551547,
      "grad_norm": 1.9795199632644653,
      "learning_rate": 8.334722222222223e-06,
      "loss": 0.1643,
      "step": 2000
    },
    {
      "epoch": 0.6398464368551547,
      "eval_accuracy": 82.3911955977989,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 83.60655737704418,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 79.12584777693547,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 84.42437923250064,
      "eval_loss": 0.13439518213272095,
      "eval_macro_f1": 82.38559479549343,
      "eval_runtime": 53.2606,
      "eval_samples_per_second": 37.532,
      "eval_steps_per_second": 1.183,
      "step": 2000
    },
    {
      "epoch": 0.6462449012237063,
      "grad_norm": 1.820122480392456,
      "learning_rate": 8.306944444444444e-06,
      "loss": 0.1591,
      "step": 2020
    },
    {
      "epoch": 0.6526433655922579,
      "grad_norm": 1.237679123878479,
      "learning_rate": 8.279166666666667e-06,
      "loss": 0.1496,
      "step": 2040
    },
    {
      "epoch": 0.6590418299608094,
      "grad_norm": 1.5870989561080933,
      "learning_rate": 8.25138888888889e-06,
      "loss": 0.1467,
      "step": 2060
    },
    {
      "epoch": 0.6654402943293609,
      "grad_norm": 1.3363348245620728,
      "learning_rate": 8.223611111111111e-06,
      "loss": 0.1577,
      "step": 2080
    },
    {
      "epoch": 0.6718387586979125,
      "grad_norm": 2.002352476119995,
      "learning_rate": 8.195833333333334e-06,
      "loss": 0.1513,
      "step": 2100
    },
    {
      "epoch": 0.6782372230664641,
      "grad_norm": 1.5844058990478516,
      "learning_rate": 8.168055555555557e-06,
      "loss": 0.1517,
      "step": 2120
    },
    {
      "epoch": 0.6846356874350156,
      "grad_norm": 1.8815325498580933,
      "learning_rate": 8.140277777777778e-06,
      "loss": 0.1614,
      "step": 2140
    },
    {
      "epoch": 0.6910341518035672,
      "grad_norm": 3.284083127975464,
      "learning_rate": 8.1125e-06,
      "loss": 0.1566,
      "step": 2160
    },
    {
      "epoch": 0.6974326161721187,
      "grad_norm": 1.768692970275879,
      "learning_rate": 8.084722222222224e-06,
      "loss": 0.1613,
      "step": 2180
    },
    {
      "epoch": 0.7038310805406702,
      "grad_norm": 1.2685624361038208,
      "learning_rate": 8.056944444444446e-06,
      "loss": 0.1559,
      "step": 2200
    },
    {
      "epoch": 0.7102295449092217,
      "grad_norm": 1.5781059265136719,
      "learning_rate": 8.029166666666668e-06,
      "loss": 0.1624,
      "step": 2220
    },
    {
      "epoch": 0.7166280092777734,
      "grad_norm": 1.2891712188720703,
      "learning_rate": 8.001388888888889e-06,
      "loss": 0.1607,
      "step": 2240
    },
    {
      "epoch": 0.7230264736463249,
      "grad_norm": 1.7940466403961182,
      "learning_rate": 7.973611111111112e-06,
      "loss": 0.1524,
      "step": 2260
    },
    {
      "epoch": 0.7294249380148764,
      "grad_norm": 1.509101152420044,
      "learning_rate": 7.945833333333334e-06,
      "loss": 0.1451,
      "step": 2280
    },
    {
      "epoch": 0.735823402383428,
      "grad_norm": 1.3213515281677246,
      "learning_rate": 7.918055555555556e-06,
      "loss": 0.152,
      "step": 2300
    },
    {
      "epoch": 0.7422218667519795,
      "grad_norm": 2.415363073348999,
      "learning_rate": 7.890277777777779e-06,
      "loss": 0.1471,
      "step": 2320
    },
    {
      "epoch": 0.7486203311205311,
      "grad_norm": 1.106009602546692,
      "learning_rate": 7.862500000000001e-06,
      "loss": 0.1516,
      "step": 2340
    },
    {
      "epoch": 0.7550187954890826,
      "grad_norm": 1.770003318786621,
      "learning_rate": 7.834722222222223e-06,
      "loss": 0.142,
      "step": 2360
    },
    {
      "epoch": 0.7614172598576342,
      "grad_norm": 1.388822317123413,
      "learning_rate": 7.806944444444445e-06,
      "loss": 0.1558,
      "step": 2380
    },
    {
      "epoch": 0.7678157242261857,
      "grad_norm": 1.185498833656311,
      "learning_rate": 7.779166666666668e-06,
      "loss": 0.1523,
      "step": 2400
    },
    {
      "epoch": 0.7742141885947372,
      "grad_norm": 2.025808095932007,
      "learning_rate": 7.75138888888889e-06,
      "loss": 0.1525,
      "step": 2420
    },
    {
      "epoch": 0.7806126529632889,
      "grad_norm": 1.5595358610153198,
      "learning_rate": 7.723611111111112e-06,
      "loss": 0.153,
      "step": 2440
    },
    {
      "epoch": 0.7870111173318404,
      "grad_norm": 1.1271979808807373,
      "learning_rate": 7.695833333333333e-06,
      "loss": 0.1486,
      "step": 2460
    },
    {
      "epoch": 0.7934095817003919,
      "grad_norm": 1.8485300540924072,
      "learning_rate": 7.668055555555556e-06,
      "loss": 0.1591,
      "step": 2480
    },
    {
      "epoch": 0.7998080460689434,
      "grad_norm": 1.6214964389801025,
      "learning_rate": 7.640277777777778e-06,
      "loss": 0.1443,
      "step": 2500
    },
    {
      "epoch": 0.7998080460689434,
      "eval_accuracy": 83.09154577288645,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 83.79804069328814,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 79.97097242379763,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 85.69218870842501,
      "eval_loss": 0.12512663006782532,
      "eval_macro_f1": 83.15373394183693,
      "eval_runtime": 53.2336,
      "eval_samples_per_second": 37.551,
      "eval_steps_per_second": 1.183,
      "step": 2500
    },
    {
      "epoch": 0.806206510437495,
      "grad_norm": 1.3121129274368286,
      "learning_rate": 7.6125e-06,
      "loss": 0.1421,
      "step": 2520
    },
    {
      "epoch": 0.8126049748060465,
      "grad_norm": 1.6822651624679565,
      "learning_rate": 7.584722222222222e-06,
      "loss": 0.1464,
      "step": 2540
    },
    {
      "epoch": 0.8190034391745981,
      "grad_norm": 1.5936713218688965,
      "learning_rate": 7.556944444444445e-06,
      "loss": 0.1538,
      "step": 2560
    },
    {
      "epoch": 0.8254019035431497,
      "grad_norm": 1.7154912948608398,
      "learning_rate": 7.529166666666667e-06,
      "loss": 0.1548,
      "step": 2580
    },
    {
      "epoch": 0.8318003679117012,
      "grad_norm": 1.5460435152053833,
      "learning_rate": 7.501388888888889e-06,
      "loss": 0.1458,
      "step": 2600
    },
    {
      "epoch": 0.8381988322802527,
      "grad_norm": 1.7719483375549316,
      "learning_rate": 7.473611111111112e-06,
      "loss": 0.1576,
      "step": 2620
    },
    {
      "epoch": 0.8445972966488043,
      "grad_norm": 1.6733125448226929,
      "learning_rate": 7.445833333333334e-06,
      "loss": 0.1456,
      "step": 2640
    },
    {
      "epoch": 0.8509957610173559,
      "grad_norm": 1.2505993843078613,
      "learning_rate": 7.418055555555557e-06,
      "loss": 0.1437,
      "step": 2660
    },
    {
      "epoch": 0.8573942253859074,
      "grad_norm": 1.200074553489685,
      "learning_rate": 7.390277777777778e-06,
      "loss": 0.1514,
      "step": 2680
    },
    {
      "epoch": 0.8637926897544589,
      "grad_norm": 1.801369071006775,
      "learning_rate": 7.3625e-06,
      "loss": 0.1461,
      "step": 2700
    },
    {
      "epoch": 0.8701911541230105,
      "grad_norm": 1.4775493144989014,
      "learning_rate": 7.334722222222222e-06,
      "loss": 0.1497,
      "step": 2720
    },
    {
      "epoch": 0.876589618491562,
      "grad_norm": 1.2554240226745605,
      "learning_rate": 7.306944444444445e-06,
      "loss": 0.1566,
      "step": 2740
    },
    {
      "epoch": 0.8829880828601135,
      "grad_norm": 1.313733696937561,
      "learning_rate": 7.279166666666667e-06,
      "loss": 0.1428,
      "step": 2760
    },
    {
      "epoch": 0.8893865472286652,
      "grad_norm": 2.6263914108276367,
      "learning_rate": 7.251388888888889e-06,
      "loss": 0.1513,
      "step": 2780
    },
    {
      "epoch": 0.8957850115972167,
      "grad_norm": 1.6627012491226196,
      "learning_rate": 7.223611111111112e-06,
      "loss": 0.1509,
      "step": 2800
    },
    {
      "epoch": 0.9021834759657682,
      "grad_norm": 2.0204994678497314,
      "learning_rate": 7.195833333333334e-06,
      "loss": 0.1413,
      "step": 2820
    },
    {
      "epoch": 0.9085819403343197,
      "grad_norm": 1.4025715589523315,
      "learning_rate": 7.168055555555556e-06,
      "loss": 0.1468,
      "step": 2840
    },
    {
      "epoch": 0.9149804047028713,
      "grad_norm": 1.9601175785064697,
      "learning_rate": 7.140277777777779e-06,
      "loss": 0.145,
      "step": 2860
    },
    {
      "epoch": 0.9213788690714229,
      "grad_norm": 1.2932285070419312,
      "learning_rate": 7.112500000000001e-06,
      "loss": 0.1412,
      "step": 2880
    },
    {
      "epoch": 0.9277773334399744,
      "grad_norm": 1.448630928993225,
      "learning_rate": 7.084722222222222e-06,
      "loss": 0.1514,
      "step": 2900
    },
    {
      "epoch": 0.934175797808526,
      "grad_norm": 1.9285110235214233,
      "learning_rate": 7.056944444444445e-06,
      "loss": 0.1506,
      "step": 2920
    },
    {
      "epoch": 0.9405742621770775,
      "grad_norm": 1.4278697967529297,
      "learning_rate": 7.029166666666667e-06,
      "loss": 0.1507,
      "step": 2940
    },
    {
      "epoch": 0.946972726545629,
      "grad_norm": 1.1761984825134277,
      "learning_rate": 7.001388888888889e-06,
      "loss": 0.1439,
      "step": 2960
    },
    {
      "epoch": 0.9533711909141805,
      "grad_norm": 1.4047878980636597,
      "learning_rate": 6.973611111111112e-06,
      "loss": 0.1437,
      "step": 2980
    },
    {
      "epoch": 0.9597696552827322,
      "grad_norm": 1.5730077028274536,
      "learning_rate": 6.945833333333334e-06,
      "loss": 0.1395,
      "step": 3000
    },
    {
      "epoch": 0.9597696552827322,
      "eval_accuracy": 83.49174587293648,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.52830188678746,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 79.85401459853514,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 86.26247122025596,
      "eval_loss": 0.12416643649339676,
      "eval_macro_f1": 83.5482625685262,
      "eval_runtime": 53.1999,
      "eval_samples_per_second": 37.575,
      "eval_steps_per_second": 1.184,
      "step": 3000
    },
    {
      "epoch": 0.9661681196512837,
      "grad_norm": 1.5028938055038452,
      "learning_rate": 6.918055555555556e-06,
      "loss": 0.1423,
      "step": 3020
    },
    {
      "epoch": 0.9725665840198352,
      "grad_norm": 1.353806972503662,
      "learning_rate": 6.890277777777779e-06,
      "loss": 0.139,
      "step": 3040
    },
    {
      "epoch": 0.9789650483883868,
      "grad_norm": 1.4363960027694702,
      "learning_rate": 6.862500000000001e-06,
      "loss": 0.138,
      "step": 3060
    },
    {
      "epoch": 0.9853635127569383,
      "grad_norm": 2.4085166454315186,
      "learning_rate": 6.834722222222223e-06,
      "loss": 0.1464,
      "step": 3080
    },
    {
      "epoch": 0.9917619771254899,
      "grad_norm": 1.3940861225128174,
      "learning_rate": 6.806944444444446e-06,
      "loss": 0.1417,
      "step": 3100
    },
    {
      "epoch": 0.9981604414940415,
      "grad_norm": 1.013555884361267,
      "learning_rate": 6.779166666666667e-06,
      "loss": 0.145,
      "step": 3120
    },
    {
      "epoch": 1.0044789250579862,
      "grad_norm": 1.2860418558120728,
      "learning_rate": 6.751388888888889e-06,
      "loss": 0.1319,
      "step": 3140
    },
    {
      "epoch": 1.0108773894265377,
      "grad_norm": 1.1983709335327148,
      "learning_rate": 6.723611111111112e-06,
      "loss": 0.1379,
      "step": 3160
    },
    {
      "epoch": 1.0172758537950892,
      "grad_norm": 16.28317642211914,
      "learning_rate": 6.695833333333334e-06,
      "loss": 0.1437,
      "step": 3180
    },
    {
      "epoch": 1.0236743181636407,
      "grad_norm": 1.5035420656204224,
      "learning_rate": 6.668055555555556e-06,
      "loss": 0.1395,
      "step": 3200
    },
    {
      "epoch": 1.0300727825321923,
      "grad_norm": 1.2704880237579346,
      "learning_rate": 6.640277777777779e-06,
      "loss": 0.1403,
      "step": 3220
    },
    {
      "epoch": 1.0364712469007438,
      "grad_norm": 1.0381174087524414,
      "learning_rate": 6.612500000000001e-06,
      "loss": 0.1367,
      "step": 3240
    },
    {
      "epoch": 1.0428697112692953,
      "grad_norm": 2.720247745513916,
      "learning_rate": 6.584722222222223e-06,
      "loss": 0.1319,
      "step": 3260
    },
    {
      "epoch": 1.049268175637847,
      "grad_norm": 1.3481806516647339,
      "learning_rate": 6.5569444444444455e-06,
      "loss": 0.1431,
      "step": 3280
    },
    {
      "epoch": 1.0556666400063985,
      "grad_norm": 1.2315043210983276,
      "learning_rate": 6.5291666666666675e-06,
      "loss": 0.1386,
      "step": 3300
    },
    {
      "epoch": 1.06206510437495,
      "grad_norm": 5.447081089019775,
      "learning_rate": 6.5013888888888896e-06,
      "loss": 0.1331,
      "step": 3320
    },
    {
      "epoch": 1.0684635687435016,
      "grad_norm": 1.6076685190200806,
      "learning_rate": 6.473611111111112e-06,
      "loss": 0.137,
      "step": 3340
    },
    {
      "epoch": 1.074862033112053,
      "grad_norm": 1.1448838710784912,
      "learning_rate": 6.445833333333334e-06,
      "loss": 0.1397,
      "step": 3360
    },
    {
      "epoch": 1.0812604974806046,
      "grad_norm": 1.621160626411438,
      "learning_rate": 6.418055555555556e-06,
      "loss": 0.1295,
      "step": 3380
    },
    {
      "epoch": 1.0876589618491561,
      "grad_norm": 3.8939192295074463,
      "learning_rate": 6.390277777777778e-06,
      "loss": 0.1271,
      "step": 3400
    },
    {
      "epoch": 1.0940574262177079,
      "grad_norm": 1.2209595441818237,
      "learning_rate": 6.3625000000000005e-06,
      "loss": 0.1429,
      "step": 3420
    },
    {
      "epoch": 1.1004558905862594,
      "grad_norm": 1.0356320142745972,
      "learning_rate": 6.3347222222222225e-06,
      "loss": 0.1313,
      "step": 3440
    },
    {
      "epoch": 1.1068543549548109,
      "grad_norm": 1.1064785718917847,
      "learning_rate": 6.306944444444445e-06,
      "loss": 0.1363,
      "step": 3460
    },
    {
      "epoch": 1.1132528193233624,
      "grad_norm": 1.382346749305725,
      "learning_rate": 6.279166666666667e-06,
      "loss": 0.133,
      "step": 3480
    },
    {
      "epoch": 1.119651283691914,
      "grad_norm": 1.3349441289901733,
      "learning_rate": 6.251388888888889e-06,
      "loss": 0.1322,
      "step": 3500
    },
    {
      "epoch": 1.119651283691914,
      "eval_accuracy": 82.94147073536769,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 83.83604021654565,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 79.62016070123678,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 85.47904191616267,
      "eval_loss": 0.1223585456609726,
      "eval_macro_f1": 82.9784142779817,
      "eval_runtime": 53.0118,
      "eval_samples_per_second": 37.709,
      "eval_steps_per_second": 1.188,
      "step": 3500
    },
    {
      "epoch": 1.1260497480604654,
      "grad_norm": 2.7349436283111572,
      "learning_rate": 6.223611111111112e-06,
      "loss": 0.1366,
      "step": 3520
    },
    {
      "epoch": 1.132448212429017,
      "grad_norm": 2.8000717163085938,
      "learning_rate": 6.195833333333334e-06,
      "loss": 0.1301,
      "step": 3540
    },
    {
      "epoch": 1.1388466767975687,
      "grad_norm": 2.4830808639526367,
      "learning_rate": 6.168055555555556e-06,
      "loss": 0.1344,
      "step": 3560
    },
    {
      "epoch": 1.1452451411661202,
      "grad_norm": 1.4359968900680542,
      "learning_rate": 6.1402777777777775e-06,
      "loss": 0.1149,
      "step": 3580
    },
    {
      "epoch": 1.1516436055346717,
      "grad_norm": 0.9236611127853394,
      "learning_rate": 6.1125e-06,
      "loss": 0.128,
      "step": 3600
    },
    {
      "epoch": 1.1580420699032232,
      "grad_norm": 2.2834813594818115,
      "learning_rate": 6.084722222222222e-06,
      "loss": 0.1449,
      "step": 3620
    },
    {
      "epoch": 1.1644405342717747,
      "grad_norm": 1.542372226715088,
      "learning_rate": 6.056944444444444e-06,
      "loss": 0.1326,
      "step": 3640
    },
    {
      "epoch": 1.1708389986403263,
      "grad_norm": 1.2967947721481323,
      "learning_rate": 6.029166666666667e-06,
      "loss": 0.1279,
      "step": 3660
    },
    {
      "epoch": 1.1772374630088778,
      "grad_norm": 1.433348536491394,
      "learning_rate": 6.001388888888889e-06,
      "loss": 0.1291,
      "step": 3680
    },
    {
      "epoch": 1.1836359273774295,
      "grad_norm": 1.390032172203064,
      "learning_rate": 5.973611111111111e-06,
      "loss": 0.129,
      "step": 3700
    },
    {
      "epoch": 1.190034391745981,
      "grad_norm": 1.4197343587875366,
      "learning_rate": 5.945833333333334e-06,
      "loss": 0.1358,
      "step": 3720
    },
    {
      "epoch": 1.1964328561145325,
      "grad_norm": 1.2360644340515137,
      "learning_rate": 5.918055555555556e-06,
      "loss": 0.1335,
      "step": 3740
    },
    {
      "epoch": 1.202831320483084,
      "grad_norm": 1.1986080408096313,
      "learning_rate": 5.890277777777779e-06,
      "loss": 0.133,
      "step": 3760
    },
    {
      "epoch": 1.2092297848516356,
      "grad_norm": 1.2091552019119263,
      "learning_rate": 5.862500000000001e-06,
      "loss": 0.1332,
      "step": 3780
    },
    {
      "epoch": 1.215628249220187,
      "grad_norm": 1.7385998964309692,
      "learning_rate": 5.834722222222222e-06,
      "loss": 0.1445,
      "step": 3800
    },
    {
      "epoch": 1.2220267135887388,
      "grad_norm": 1.2532761096954346,
      "learning_rate": 5.806944444444444e-06,
      "loss": 0.1294,
      "step": 3820
    },
    {
      "epoch": 1.2284251779572903,
      "grad_norm": 1.2015511989593506,
      "learning_rate": 5.779166666666667e-06,
      "loss": 0.1323,
      "step": 3840
    },
    {
      "epoch": 1.2348236423258419,
      "grad_norm": 1.6207876205444336,
      "learning_rate": 5.751388888888889e-06,
      "loss": 0.1506,
      "step": 3860
    },
    {
      "epoch": 1.2412221066943934,
      "grad_norm": 6.886016368865967,
      "learning_rate": 5.723611111111111e-06,
      "loss": 0.1367,
      "step": 3880
    },
    {
      "epoch": 1.2476205710629449,
      "grad_norm": 1.2328814268112183,
      "learning_rate": 5.695833333333334e-06,
      "loss": 0.1392,
      "step": 3900
    },
    {
      "epoch": 1.2540190354314964,
      "grad_norm": 1.3221237659454346,
      "learning_rate": 5.668055555555556e-06,
      "loss": 0.1325,
      "step": 3920
    },
    {
      "epoch": 1.260417499800048,
      "grad_norm": 2.379272937774658,
      "learning_rate": 5.640277777777778e-06,
      "loss": 0.1286,
      "step": 3940
    },
    {
      "epoch": 1.2668159641685994,
      "grad_norm": 2.001695394515991,
      "learning_rate": 5.612500000000001e-06,
      "loss": 0.1262,
      "step": 3960
    },
    {
      "epoch": 1.2732144285371512,
      "grad_norm": 1.577652931213379,
      "learning_rate": 5.584722222222223e-06,
      "loss": 0.1416,
      "step": 3980
    },
    {
      "epoch": 1.2796128929057027,
      "grad_norm": 1.457804560661316,
      "learning_rate": 5.556944444444446e-06,
      "loss": 0.1254,
      "step": 4000
    },
    {
      "epoch": 1.2796128929057027,
      "eval_accuracy": 83.69184592296148,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.62732919254158,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 80.52708638359677,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 86.01190476189977,
      "eval_loss": 0.11859586834907532,
      "eval_macro_f1": 83.72210677934605,
      "eval_runtime": 53.0509,
      "eval_samples_per_second": 37.681,
      "eval_steps_per_second": 1.188,
      "step": 4000
    },
    {
      "epoch": 1.2860113572742542,
      "grad_norm": 1.5605539083480835,
      "learning_rate": 5.529166666666667e-06,
      "loss": 0.1395,
      "step": 4020
    },
    {
      "epoch": 1.2924098216428057,
      "grad_norm": 1.3177242279052734,
      "learning_rate": 5.501388888888889e-06,
      "loss": 0.1314,
      "step": 4040
    },
    {
      "epoch": 1.2988082860113572,
      "grad_norm": 0.9158018231391907,
      "learning_rate": 5.473611111111111e-06,
      "loss": 0.145,
      "step": 4060
    },
    {
      "epoch": 1.3052067503799087,
      "grad_norm": 1.3463902473449707,
      "learning_rate": 5.445833333333334e-06,
      "loss": 0.1359,
      "step": 4080
    },
    {
      "epoch": 1.3116052147484605,
      "grad_norm": 1.8106907606124878,
      "learning_rate": 5.418055555555556e-06,
      "loss": 0.1228,
      "step": 4100
    },
    {
      "epoch": 1.318003679117012,
      "grad_norm": 1.2566708326339722,
      "learning_rate": 5.390277777777778e-06,
      "loss": 0.1336,
      "step": 4120
    },
    {
      "epoch": 1.3244021434855635,
      "grad_norm": 2.1305487155914307,
      "learning_rate": 5.362500000000001e-06,
      "loss": 0.135,
      "step": 4140
    },
    {
      "epoch": 1.330800607854115,
      "grad_norm": 1.4261271953582764,
      "learning_rate": 5.334722222222223e-06,
      "loss": 0.1318,
      "step": 4160
    },
    {
      "epoch": 1.3371990722226665,
      "grad_norm": 1.191239595413208,
      "learning_rate": 5.306944444444445e-06,
      "loss": 0.1257,
      "step": 4180
    },
    {
      "epoch": 1.343597536591218,
      "grad_norm": 2.4770522117614746,
      "learning_rate": 5.279166666666668e-06,
      "loss": 0.1233,
      "step": 4200
    },
    {
      "epoch": 1.3499960009597696,
      "grad_norm": 1.570376992225647,
      "learning_rate": 5.25138888888889e-06,
      "loss": 0.1383,
      "step": 4220
    },
    {
      "epoch": 1.356394465328321,
      "grad_norm": 2.6727373600006104,
      "learning_rate": 5.223611111111112e-06,
      "loss": 0.1259,
      "step": 4240
    },
    {
      "epoch": 1.3627929296968728,
      "grad_norm": 1.6307108402252197,
      "learning_rate": 5.195833333333334e-06,
      "loss": 0.127,
      "step": 4260
    },
    {
      "epoch": 1.3691913940654243,
      "grad_norm": 1.084938645362854,
      "learning_rate": 5.168055555555556e-06,
      "loss": 0.1297,
      "step": 4280
    },
    {
      "epoch": 1.3755898584339759,
      "grad_norm": 1.3407225608825684,
      "learning_rate": 5.140277777777778e-06,
      "loss": 0.1339,
      "step": 4300
    },
    {
      "epoch": 1.3819883228025274,
      "grad_norm": 1.945648431777954,
      "learning_rate": 5.112500000000001e-06,
      "loss": 0.1322,
      "step": 4320
    },
    {
      "epoch": 1.3883867871710789,
      "grad_norm": 1.4227076768875122,
      "learning_rate": 5.084722222222223e-06,
      "loss": 0.1255,
      "step": 4340
    },
    {
      "epoch": 1.3947852515396306,
      "grad_norm": 1.2567055225372314,
      "learning_rate": 5.056944444444445e-06,
      "loss": 0.1392,
      "step": 4360
    },
    {
      "epoch": 1.4011837159081821,
      "grad_norm": 0.998769998550415,
      "learning_rate": 5.0291666666666675e-06,
      "loss": 0.1306,
      "step": 4380
    },
    {
      "epoch": 1.4075821802767337,
      "grad_norm": 1.3849749565124512,
      "learning_rate": 5.0013888888888895e-06,
      "loss": 0.1354,
      "step": 4400
    },
    {
      "epoch": 1.4139806446452852,
      "grad_norm": 1.616286039352417,
      "learning_rate": 4.9736111111111115e-06,
      "loss": 0.1318,
      "step": 4420
    },
    {
      "epoch": 1.4203791090138367,
      "grad_norm": 1.2827144861221313,
      "learning_rate": 4.9458333333333336e-06,
      "loss": 0.1342,
      "step": 4440
    },
    {
      "epoch": 1.4267775733823882,
      "grad_norm": 1.0500288009643555,
      "learning_rate": 4.9180555555555556e-06,
      "loss": 0.1304,
      "step": 4460
    },
    {
      "epoch": 1.4331760377509397,
      "grad_norm": 2.041322946548462,
      "learning_rate": 4.8902777777777784e-06,
      "loss": 0.1273,
      "step": 4480
    },
    {
      "epoch": 1.4395745021194912,
      "grad_norm": 1.3780614137649536,
      "learning_rate": 4.8625000000000005e-06,
      "loss": 0.1323,
      "step": 4500
    },
    {
      "epoch": 1.4395745021194912,
      "eval_accuracy": 83.59179589794897,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.28351309706741,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 80.53293856402166,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 85.98962194217438,
      "eval_loss": 0.11831403523683548,
      "eval_macro_f1": 83.60202453442115,
      "eval_runtime": 53.0392,
      "eval_samples_per_second": 37.689,
      "eval_steps_per_second": 1.188,
      "step": 4500
    },
    {
      "epoch": 1.4459729664880427,
      "grad_norm": 1.364373803138733,
      "learning_rate": 4.8347222222222225e-06,
      "loss": 0.1184,
      "step": 4520
    },
    {
      "epoch": 1.4523714308565945,
      "grad_norm": 1.5012692213058472,
      "learning_rate": 4.8069444444444445e-06,
      "loss": 0.1354,
      "step": 4540
    },
    {
      "epoch": 1.458769895225146,
      "grad_norm": 1.2447988986968994,
      "learning_rate": 4.779166666666667e-06,
      "loss": 0.1273,
      "step": 4560
    },
    {
      "epoch": 1.4651683595936975,
      "grad_norm": 1.437512993812561,
      "learning_rate": 4.751388888888889e-06,
      "loss": 0.1367,
      "step": 4580
    },
    {
      "epoch": 1.471566823962249,
      "grad_norm": 3.16300368309021,
      "learning_rate": 4.723611111111111e-06,
      "loss": 0.1216,
      "step": 4600
    },
    {
      "epoch": 1.4779652883308005,
      "grad_norm": 1.6714075803756714,
      "learning_rate": 4.695833333333334e-06,
      "loss": 0.1316,
      "step": 4620
    },
    {
      "epoch": 1.4843637526993523,
      "grad_norm": 1.1415753364562988,
      "learning_rate": 4.6680555555555554e-06,
      "loss": 0.1283,
      "step": 4640
    },
    {
      "epoch": 1.4907622170679038,
      "grad_norm": 0.9768179655075073,
      "learning_rate": 4.640277777777778e-06,
      "loss": 0.1264,
      "step": 4660
    },
    {
      "epoch": 1.4971606814364553,
      "grad_norm": 1.2648159265518188,
      "learning_rate": 4.6125e-06,
      "loss": 0.1236,
      "step": 4680
    },
    {
      "epoch": 1.5035591458050068,
      "grad_norm": 1.399183750152588,
      "learning_rate": 4.584722222222222e-06,
      "loss": 0.1314,
      "step": 4700
    },
    {
      "epoch": 1.5099576101735583,
      "grad_norm": 0.9404553771018982,
      "learning_rate": 4.556944444444445e-06,
      "loss": 0.1304,
      "step": 4720
    },
    {
      "epoch": 1.5163560745421099,
      "grad_norm": 1.0571967363357544,
      "learning_rate": 4.529166666666667e-06,
      "loss": 0.1284,
      "step": 4740
    },
    {
      "epoch": 1.5227545389106614,
      "grad_norm": 1.6717848777770996,
      "learning_rate": 4.501388888888889e-06,
      "loss": 0.1236,
      "step": 4760
    },
    {
      "epoch": 1.5291530032792129,
      "grad_norm": 1.4150135517120361,
      "learning_rate": 4.473611111111111e-06,
      "loss": 0.1255,
      "step": 4780
    },
    {
      "epoch": 1.5355514676477644,
      "grad_norm": 0.9791259169578552,
      "learning_rate": 4.445833333333333e-06,
      "loss": 0.129,
      "step": 4800
    },
    {
      "epoch": 1.5419499320163161,
      "grad_norm": 1.781592607498169,
      "learning_rate": 4.418055555555556e-06,
      "loss": 0.131,
      "step": 4820
    },
    {
      "epoch": 1.5483483963848677,
      "grad_norm": 1.1875683069229126,
      "learning_rate": 4.390277777777778e-06,
      "loss": 0.1263,
      "step": 4840
    },
    {
      "epoch": 1.5547468607534192,
      "grad_norm": 1.1594496965408325,
      "learning_rate": 4.362500000000001e-06,
      "loss": 0.12,
      "step": 4860
    },
    {
      "epoch": 1.5611453251219707,
      "grad_norm": 1.2274001836776733,
      "learning_rate": 4.334722222222222e-06,
      "loss": 0.1308,
      "step": 4880
    },
    {
      "epoch": 1.5675437894905224,
      "grad_norm": 1.1162277460098267,
      "learning_rate": 4.306944444444445e-06,
      "loss": 0.1208,
      "step": 4900
    },
    {
      "epoch": 1.573942253859074,
      "grad_norm": 1.3098863363265991,
      "learning_rate": 4.279166666666667e-06,
      "loss": 0.1247,
      "step": 4920
    },
    {
      "epoch": 1.5803407182276255,
      "grad_norm": 1.2428823709487915,
      "learning_rate": 4.251388888888889e-06,
      "loss": 0.1277,
      "step": 4940
    },
    {
      "epoch": 1.586739182596177,
      "grad_norm": 1.667866587638855,
      "learning_rate": 4.223611111111112e-06,
      "loss": 0.1348,
      "step": 4960
    },
    {
      "epoch": 1.5931376469647285,
      "grad_norm": 1.443360447883606,
      "learning_rate": 4.195833333333333e-06,
      "loss": 0.1336,
      "step": 4980
    },
    {
      "epoch": 1.59953611133328,
      "grad_norm": 1.107629656791687,
      "learning_rate": 4.168055555555556e-06,
      "loss": 0.1318,
      "step": 5000
    },
    {
      "epoch": 1.59953611133328,
      "eval_accuracy": 83.69184592296148,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.24242424241925,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 80.11569052783304,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 86.94980694980194,
      "eval_loss": 0.11776749044656754,
      "eval_macro_f1": 83.76930724001808,
      "eval_runtime": 53.0743,
      "eval_samples_per_second": 37.664,
      "eval_steps_per_second": 1.187,
      "step": 5000
    },
    {
      "epoch": 1.6059345757018315,
      "grad_norm": 1.3735603094100952,
      "learning_rate": 4.140277777777778e-06,
      "loss": 0.1234,
      "step": 5020
    },
    {
      "epoch": 1.612333040070383,
      "grad_norm": 1.4667818546295166,
      "learning_rate": 4.1125e-06,
      "loss": 0.13,
      "step": 5040
    },
    {
      "epoch": 1.6187315044389345,
      "grad_norm": 1.4646625518798828,
      "learning_rate": 4.084722222222223e-06,
      "loss": 0.1387,
      "step": 5060
    },
    {
      "epoch": 1.625129968807486,
      "grad_norm": 6.639502048492432,
      "learning_rate": 4.056944444444445e-06,
      "loss": 0.1257,
      "step": 5080
    },
    {
      "epoch": 1.6315284331760378,
      "grad_norm": 1.4246517419815063,
      "learning_rate": 4.029166666666667e-06,
      "loss": 0.1264,
      "step": 5100
    },
    {
      "epoch": 1.6379268975445893,
      "grad_norm": 1.0651012659072876,
      "learning_rate": 4.001388888888889e-06,
      "loss": 0.1259,
      "step": 5120
    },
    {
      "epoch": 1.6443253619131408,
      "grad_norm": 1.0883320569992065,
      "learning_rate": 3.973611111111112e-06,
      "loss": 0.1267,
      "step": 5140
    },
    {
      "epoch": 1.6507238262816923,
      "grad_norm": 1.5068814754486084,
      "learning_rate": 3.945833333333334e-06,
      "loss": 0.127,
      "step": 5160
    },
    {
      "epoch": 1.657122290650244,
      "grad_norm": 0.9907966256141663,
      "learning_rate": 3.918055555555556e-06,
      "loss": 0.1253,
      "step": 5180
    },
    {
      "epoch": 1.6635207550187956,
      "grad_norm": 1.2244279384613037,
      "learning_rate": 3.890277777777778e-06,
      "loss": 0.1246,
      "step": 5200
    },
    {
      "epoch": 1.669919219387347,
      "grad_norm": 1.1833322048187256,
      "learning_rate": 3.8625e-06,
      "loss": 0.1293,
      "step": 5220
    },
    {
      "epoch": 1.6763176837558986,
      "grad_norm": 1.3180510997772217,
      "learning_rate": 3.834722222222223e-06,
      "loss": 0.1213,
      "step": 5240
    },
    {
      "epoch": 1.6827161481244501,
      "grad_norm": 1.9908335208892822,
      "learning_rate": 3.8069444444444447e-06,
      "loss": 0.1364,
      "step": 5260
    },
    {
      "epoch": 1.6891146124930017,
      "grad_norm": 1.1384903192520142,
      "learning_rate": 3.779166666666667e-06,
      "loss": 0.1291,
      "step": 5280
    },
    {
      "epoch": 1.6955130768615532,
      "grad_norm": 0.7568871378898621,
      "learning_rate": 3.751388888888889e-06,
      "loss": 0.1161,
      "step": 5300
    },
    {
      "epoch": 1.7019115412301047,
      "grad_norm": 1.6477103233337402,
      "learning_rate": 3.7236111111111112e-06,
      "loss": 0.1371,
      "step": 5320
    },
    {
      "epoch": 1.7083100055986562,
      "grad_norm": 2.432793140411377,
      "learning_rate": 3.6958333333333337e-06,
      "loss": 0.1246,
      "step": 5340
    },
    {
      "epoch": 1.7147084699672077,
      "grad_norm": 1.0639684200286865,
      "learning_rate": 3.6680555555555557e-06,
      "loss": 0.1305,
      "step": 5360
    },
    {
      "epoch": 1.7211069343357595,
      "grad_norm": 1.2356215715408325,
      "learning_rate": 3.640277777777778e-06,
      "loss": 0.1254,
      "step": 5380
    },
    {
      "epoch": 1.727505398704311,
      "grad_norm": 1.456745982170105,
      "learning_rate": 3.6125000000000006e-06,
      "loss": 0.1181,
      "step": 5400
    },
    {
      "epoch": 1.7339038630728625,
      "grad_norm": 1.7621383666992188,
      "learning_rate": 3.5847222222222226e-06,
      "loss": 0.1266,
      "step": 5420
    },
    {
      "epoch": 1.7403023274414142,
      "grad_norm": 1.2135735750198364,
      "learning_rate": 3.5569444444444446e-06,
      "loss": 0.122,
      "step": 5440
    },
    {
      "epoch": 1.7467007918099657,
      "grad_norm": 1.4483864307403564,
      "learning_rate": 3.529166666666667e-06,
      "loss": 0.1291,
      "step": 5460
    },
    {
      "epoch": 1.7530992561785173,
      "grad_norm": 1.4995752573013306,
      "learning_rate": 3.501388888888889e-06,
      "loss": 0.1237,
      "step": 5480
    },
    {
      "epoch": 1.7594977205470688,
      "grad_norm": 1.2310686111450195,
      "learning_rate": 3.4736111111111115e-06,
      "loss": 0.1345,
      "step": 5500
    },
    {
      "epoch": 1.7594977205470688,
      "eval_accuracy": 83.84192096048024,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.57943925233145,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 80.65902578796063,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 86.49468892260501,
      "eval_loss": 0.1162741556763649,
      "eval_macro_f1": 83.91105132096568,
      "eval_runtime": 52.9006,
      "eval_samples_per_second": 37.788,
      "eval_steps_per_second": 1.191,
      "step": 5500
    },
    {
      "epoch": 1.7658961849156203,
      "grad_norm": 1.159619688987732,
      "learning_rate": 3.445833333333334e-06,
      "loss": 0.1214,
      "step": 5520
    },
    {
      "epoch": 1.7722946492841718,
      "grad_norm": 2.341355085372925,
      "learning_rate": 3.4180555555555555e-06,
      "loss": 0.1294,
      "step": 5540
    },
    {
      "epoch": 1.7786931136527233,
      "grad_norm": 1.5722148418426514,
      "learning_rate": 3.390277777777778e-06,
      "loss": 0.1271,
      "step": 5560
    },
    {
      "epoch": 1.7850915780212748,
      "grad_norm": 1.181195616722107,
      "learning_rate": 3.3625000000000004e-06,
      "loss": 0.1213,
      "step": 5580
    },
    {
      "epoch": 1.7914900423898263,
      "grad_norm": 1.347288727760315,
      "learning_rate": 3.3347222222222224e-06,
      "loss": 0.1201,
      "step": 5600
    },
    {
      "epoch": 1.7978885067583779,
      "grad_norm": 1.0114450454711914,
      "learning_rate": 3.306944444444445e-06,
      "loss": 0.1203,
      "step": 5620
    },
    {
      "epoch": 1.8042869711269294,
      "grad_norm": 1.6457182168960571,
      "learning_rate": 3.2791666666666673e-06,
      "loss": 0.1299,
      "step": 5640
    },
    {
      "epoch": 1.810685435495481,
      "grad_norm": 1.2556957006454468,
      "learning_rate": 3.251388888888889e-06,
      "loss": 0.1248,
      "step": 5660
    },
    {
      "epoch": 1.8170838998640326,
      "grad_norm": 1.2920565605163574,
      "learning_rate": 3.2236111111111114e-06,
      "loss": 0.1219,
      "step": 5680
    },
    {
      "epoch": 1.8234823642325841,
      "grad_norm": 0.9371632933616638,
      "learning_rate": 3.1958333333333334e-06,
      "loss": 0.1272,
      "step": 5700
    },
    {
      "epoch": 1.8298808286011359,
      "grad_norm": 1.0685418844223022,
      "learning_rate": 3.168055555555556e-06,
      "loss": 0.1155,
      "step": 5720
    },
    {
      "epoch": 1.8362792929696874,
      "grad_norm": 1.6699379682540894,
      "learning_rate": 3.1402777777777783e-06,
      "loss": 0.1248,
      "step": 5740
    },
    {
      "epoch": 1.842677757338239,
      "grad_norm": 2.888819456100464,
      "learning_rate": 3.1125000000000007e-06,
      "loss": 0.1222,
      "step": 5760
    },
    {
      "epoch": 1.8490762217067904,
      "grad_norm": 1.199257731437683,
      "learning_rate": 3.0847222222222223e-06,
      "loss": 0.1274,
      "step": 5780
    },
    {
      "epoch": 1.855474686075342,
      "grad_norm": 3.07948899269104,
      "learning_rate": 3.0569444444444447e-06,
      "loss": 0.1308,
      "step": 5800
    },
    {
      "epoch": 1.8618731504438935,
      "grad_norm": 1.2047439813613892,
      "learning_rate": 3.0291666666666667e-06,
      "loss": 0.1304,
      "step": 5820
    },
    {
      "epoch": 1.868271614812445,
      "grad_norm": 1.1196928024291992,
      "learning_rate": 3.001388888888889e-06,
      "loss": 0.1171,
      "step": 5840
    },
    {
      "epoch": 1.8746700791809965,
      "grad_norm": 1.7138776779174805,
      "learning_rate": 2.9736111111111116e-06,
      "loss": 0.1285,
      "step": 5860
    },
    {
      "epoch": 1.881068543549548,
      "grad_norm": 1.6239585876464844,
      "learning_rate": 2.9458333333333332e-06,
      "loss": 0.1236,
      "step": 5880
    },
    {
      "epoch": 1.8874670079180995,
      "grad_norm": 1.5552000999450684,
      "learning_rate": 2.9180555555555557e-06,
      "loss": 0.1296,
      "step": 5900
    },
    {
      "epoch": 1.8938654722866513,
      "grad_norm": 0.9768526554107666,
      "learning_rate": 2.890277777777778e-06,
      "loss": 0.1269,
      "step": 5920
    },
    {
      "epoch": 1.9002639366552028,
      "grad_norm": 2.2020459175109863,
      "learning_rate": 2.8625e-06,
      "loss": 0.1208,
      "step": 5940
    },
    {
      "epoch": 1.9066624010237543,
      "grad_norm": 1.3007863759994507,
      "learning_rate": 2.8347222222222226e-06,
      "loss": 0.1289,
      "step": 5960
    },
    {
      "epoch": 1.9130608653923058,
      "grad_norm": 1.0617938041687012,
      "learning_rate": 2.806944444444445e-06,
      "loss": 0.1295,
      "step": 5980
    },
    {
      "epoch": 1.9194593297608575,
      "grad_norm": 2.833794355392456,
      "learning_rate": 2.7791666666666666e-06,
      "loss": 0.1361,
      "step": 6000
    },
    {
      "epoch": 1.9194593297608575,
      "eval_accuracy": 83.84192096048024,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.70948012231916,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 80.17429193899282,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 86.82406702208183,
      "eval_loss": 0.11484286934137344,
      "eval_macro_f1": 83.90261302779794,
      "eval_runtime": 53.0324,
      "eval_samples_per_second": 37.694,
      "eval_steps_per_second": 1.188,
      "step": 6000
    },
    {
      "epoch": 1.925857794129409,
      "grad_norm": 1.348963737487793,
      "learning_rate": 2.751388888888889e-06,
      "loss": 0.1224,
      "step": 6020
    },
    {
      "epoch": 1.9322562584979606,
      "grad_norm": 1.065803050994873,
      "learning_rate": 2.7236111111111115e-06,
      "loss": 0.1259,
      "step": 6040
    },
    {
      "epoch": 1.938654722866512,
      "grad_norm": 0.8703915476799011,
      "learning_rate": 2.6958333333333335e-06,
      "loss": 0.13,
      "step": 6060
    },
    {
      "epoch": 1.9450531872350636,
      "grad_norm": 1.4028170108795166,
      "learning_rate": 2.668055555555556e-06,
      "loss": 0.1231,
      "step": 6080
    },
    {
      "epoch": 1.9514516516036151,
      "grad_norm": 1.1797292232513428,
      "learning_rate": 2.6402777777777775e-06,
      "loss": 0.1211,
      "step": 6100
    },
    {
      "epoch": 1.9578501159721666,
      "grad_norm": 1.4190974235534668,
      "learning_rate": 2.6125e-06,
      "loss": 0.1309,
      "step": 6120
    },
    {
      "epoch": 1.9642485803407181,
      "grad_norm": 1.1344412565231323,
      "learning_rate": 2.5847222222222224e-06,
      "loss": 0.1323,
      "step": 6140
    },
    {
      "epoch": 1.9706470447092697,
      "grad_norm": 5.174822807312012,
      "learning_rate": 2.556944444444445e-06,
      "loss": 0.1215,
      "step": 6160
    },
    {
      "epoch": 1.9770455090778212,
      "grad_norm": 3.4732391834259033,
      "learning_rate": 2.529166666666667e-06,
      "loss": 0.1281,
      "step": 6180
    },
    {
      "epoch": 1.983443973446373,
      "grad_norm": 1.1604571342468262,
      "learning_rate": 2.5013888888888893e-06,
      "loss": 0.1289,
      "step": 6200
    },
    {
      "epoch": 1.9898424378149244,
      "grad_norm": 1.479788064956665,
      "learning_rate": 2.4736111111111113e-06,
      "loss": 0.1252,
      "step": 6220
    },
    {
      "epoch": 1.996240902183476,
      "grad_norm": 1.9352197647094727,
      "learning_rate": 2.4458333333333338e-06,
      "loss": 0.1297,
      "step": 6240
    },
    {
      "epoch": 2.0025593857474204,
      "grad_norm": 1.0697873830795288,
      "learning_rate": 2.418055555555556e-06,
      "loss": 0.1213,
      "step": 6260
    },
    {
      "epoch": 2.0089578501159724,
      "grad_norm": 2.088549852371216,
      "learning_rate": 2.3902777777777782e-06,
      "loss": 0.1236,
      "step": 6280
    },
    {
      "epoch": 2.015356314484524,
      "grad_norm": 0.8885262608528137,
      "learning_rate": 2.3625000000000003e-06,
      "loss": 0.113,
      "step": 6300
    },
    {
      "epoch": 2.0217547788530754,
      "grad_norm": 1.2555360794067383,
      "learning_rate": 2.3347222222222223e-06,
      "loss": 0.1273,
      "step": 6320
    },
    {
      "epoch": 2.028153243221627,
      "grad_norm": 2.8374128341674805,
      "learning_rate": 2.3069444444444447e-06,
      "loss": 0.1235,
      "step": 6340
    },
    {
      "epoch": 2.0345517075901784,
      "grad_norm": 0.9767923951148987,
      "learning_rate": 2.2791666666666667e-06,
      "loss": 0.1254,
      "step": 6360
    },
    {
      "epoch": 2.04095017195873,
      "grad_norm": 1.4072469472885132,
      "learning_rate": 2.251388888888889e-06,
      "loss": 0.1223,
      "step": 6380
    },
    {
      "epoch": 2.0473486363272815,
      "grad_norm": 1.169076919555664,
      "learning_rate": 2.223611111111111e-06,
      "loss": 0.1136,
      "step": 6400
    },
    {
      "epoch": 2.053747100695833,
      "grad_norm": 2.7436537742614746,
      "learning_rate": 2.1958333333333336e-06,
      "loss": 0.12,
      "step": 6420
    },
    {
      "epoch": 2.0601455650643845,
      "grad_norm": 2.218322277069092,
      "learning_rate": 2.1680555555555556e-06,
      "loss": 0.1211,
      "step": 6440
    },
    {
      "epoch": 2.066544029432936,
      "grad_norm": 3.5853965282440186,
      "learning_rate": 2.140277777777778e-06,
      "loss": 0.1226,
      "step": 6460
    },
    {
      "epoch": 2.0729424938014875,
      "grad_norm": 1.0157779455184937,
      "learning_rate": 2.1125e-06,
      "loss": 0.1134,
      "step": 6480
    },
    {
      "epoch": 2.079340958170039,
      "grad_norm": 1.1139583587646484,
      "learning_rate": 2.0847222222222225e-06,
      "loss": 0.1216,
      "step": 6500
    },
    {
      "epoch": 2.079340958170039,
      "eval_accuracy": 84.04202101050525,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.75609756097062,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 80.14814814814315,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 87.27544910179141,
      "eval_loss": 0.11751385033130646,
      "eval_macro_f1": 84.05989827030173,
      "eval_runtime": 53.0943,
      "eval_samples_per_second": 37.65,
      "eval_steps_per_second": 1.187,
      "step": 6500
    },
    {
      "epoch": 2.0857394225385906,
      "grad_norm": 1.4704225063323975,
      "learning_rate": 2.0569444444444446e-06,
      "loss": 0.1151,
      "step": 6520
    },
    {
      "epoch": 2.092137886907142,
      "grad_norm": 1.1121935844421387,
      "learning_rate": 2.0291666666666666e-06,
      "loss": 0.1161,
      "step": 6540
    },
    {
      "epoch": 2.098536351275694,
      "grad_norm": 1.0908315181732178,
      "learning_rate": 2.001388888888889e-06,
      "loss": 0.1148,
      "step": 6560
    },
    {
      "epoch": 2.1049348156442456,
      "grad_norm": 1.4317185878753662,
      "learning_rate": 1.973611111111111e-06,
      "loss": 0.1117,
      "step": 6580
    },
    {
      "epoch": 2.111333280012797,
      "grad_norm": 0.9039095640182495,
      "learning_rate": 1.9458333333333335e-06,
      "loss": 0.1105,
      "step": 6600
    },
    {
      "epoch": 2.1177317443813486,
      "grad_norm": 1.2162851095199585,
      "learning_rate": 1.918055555555556e-06,
      "loss": 0.1189,
      "step": 6620
    },
    {
      "epoch": 2.1241302087499,
      "grad_norm": 0.9786971807479858,
      "learning_rate": 1.8902777777777777e-06,
      "loss": 0.1105,
      "step": 6640
    },
    {
      "epoch": 2.1305286731184516,
      "grad_norm": 1.3649142980575562,
      "learning_rate": 1.8625000000000002e-06,
      "loss": 0.1189,
      "step": 6660
    },
    {
      "epoch": 2.136927137487003,
      "grad_norm": 3.8256187438964844,
      "learning_rate": 1.8347222222222224e-06,
      "loss": 0.1208,
      "step": 6680
    },
    {
      "epoch": 2.1433256018555547,
      "grad_norm": 1.1347216367721558,
      "learning_rate": 1.8069444444444444e-06,
      "loss": 0.1127,
      "step": 6700
    },
    {
      "epoch": 2.149724066224106,
      "grad_norm": 6.7574968338012695,
      "learning_rate": 1.7791666666666669e-06,
      "loss": 0.1173,
      "step": 6720
    },
    {
      "epoch": 2.1561225305926577,
      "grad_norm": 1.3973318338394165,
      "learning_rate": 1.751388888888889e-06,
      "loss": 0.1273,
      "step": 6740
    },
    {
      "epoch": 2.162520994961209,
      "grad_norm": 1.5495274066925049,
      "learning_rate": 1.723611111111111e-06,
      "loss": 0.1253,
      "step": 6760
    },
    {
      "epoch": 2.1689194593297607,
      "grad_norm": 1.055264949798584,
      "learning_rate": 1.6958333333333335e-06,
      "loss": 0.1094,
      "step": 6780
    },
    {
      "epoch": 2.1753179236983122,
      "grad_norm": 1.4301027059555054,
      "learning_rate": 1.6680555555555558e-06,
      "loss": 0.1192,
      "step": 6800
    },
    {
      "epoch": 2.1817163880668637,
      "grad_norm": 1.5022125244140625,
      "learning_rate": 1.6402777777777778e-06,
      "loss": 0.11,
      "step": 6820
    },
    {
      "epoch": 2.1881148524354157,
      "grad_norm": 3.0136477947235107,
      "learning_rate": 1.6125000000000002e-06,
      "loss": 0.117,
      "step": 6840
    },
    {
      "epoch": 2.194513316803967,
      "grad_norm": 1.4433438777923584,
      "learning_rate": 1.5847222222222222e-06,
      "loss": 0.1179,
      "step": 6860
    },
    {
      "epoch": 2.2009117811725187,
      "grad_norm": 1.3565573692321777,
      "learning_rate": 1.5569444444444445e-06,
      "loss": 0.1166,
      "step": 6880
    },
    {
      "epoch": 2.2073102455410702,
      "grad_norm": 1.2450720071792603,
      "learning_rate": 1.529166666666667e-06,
      "loss": 0.1175,
      "step": 6900
    },
    {
      "epoch": 2.2137087099096218,
      "grad_norm": 1.0654921531677246,
      "learning_rate": 1.501388888888889e-06,
      "loss": 0.1201,
      "step": 6920
    },
    {
      "epoch": 2.2201071742781733,
      "grad_norm": 1.8128806352615356,
      "learning_rate": 1.4736111111111112e-06,
      "loss": 0.1157,
      "step": 6940
    },
    {
      "epoch": 2.226505638646725,
      "grad_norm": 1.2664217948913574,
      "learning_rate": 1.4458333333333336e-06,
      "loss": 0.1256,
      "step": 6960
    },
    {
      "epoch": 2.2329041030152763,
      "grad_norm": 1.6262251138687134,
      "learning_rate": 1.4180555555555556e-06,
      "loss": 0.115,
      "step": 6980
    },
    {
      "epoch": 2.239302567383828,
      "grad_norm": 1.5823173522949219,
      "learning_rate": 1.3902777777777779e-06,
      "loss": 0.1113,
      "step": 7000
    },
    {
      "epoch": 2.239302567383828,
      "eval_accuracy": 84.19209604802401,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.7148288973334,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 80.4185351270503,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 87.43494423791321,
      "eval_loss": 0.11846350133419037,
      "eval_macro_f1": 84.1894360874323,
      "eval_runtime": 52.9788,
      "eval_samples_per_second": 37.732,
      "eval_steps_per_second": 1.189,
      "step": 7000
    },
    {
      "epoch": 2.2457010317523793,
      "grad_norm": 1.3400105237960815,
      "learning_rate": 1.3625000000000003e-06,
      "loss": 0.122,
      "step": 7020
    },
    {
      "epoch": 2.252099496120931,
      "grad_norm": 1.531134009361267,
      "learning_rate": 1.3347222222222223e-06,
      "loss": 0.1128,
      "step": 7040
    },
    {
      "epoch": 2.2584979604894824,
      "grad_norm": 1.3947819471359253,
      "learning_rate": 1.3069444444444445e-06,
      "loss": 0.1154,
      "step": 7060
    },
    {
      "epoch": 2.264896424858034,
      "grad_norm": 1.1311324834823608,
      "learning_rate": 1.279166666666667e-06,
      "loss": 0.1193,
      "step": 7080
    },
    {
      "epoch": 2.271294889226586,
      "grad_norm": 1.076934814453125,
      "learning_rate": 1.251388888888889e-06,
      "loss": 0.1151,
      "step": 7100
    },
    {
      "epoch": 2.2776933535951374,
      "grad_norm": 1.5175632238388062,
      "learning_rate": 1.2236111111111112e-06,
      "loss": 0.1204,
      "step": 7120
    },
    {
      "epoch": 2.284091817963689,
      "grad_norm": 1.0436691045761108,
      "learning_rate": 1.1958333333333335e-06,
      "loss": 0.1174,
      "step": 7140
    },
    {
      "epoch": 2.2904902823322404,
      "grad_norm": 1.348122239112854,
      "learning_rate": 1.1680555555555557e-06,
      "loss": 0.1177,
      "step": 7160
    },
    {
      "epoch": 2.296888746700792,
      "grad_norm": 1.5934901237487793,
      "learning_rate": 1.140277777777778e-06,
      "loss": 0.1171,
      "step": 7180
    },
    {
      "epoch": 2.3032872110693434,
      "grad_norm": 13.36949634552002,
      "learning_rate": 1.1125000000000001e-06,
      "loss": 0.1224,
      "step": 7200
    },
    {
      "epoch": 2.309685675437895,
      "grad_norm": 1.271398663520813,
      "learning_rate": 1.0847222222222224e-06,
      "loss": 0.1119,
      "step": 7220
    },
    {
      "epoch": 2.3160841398064465,
      "grad_norm": 1.769083857536316,
      "learning_rate": 1.0569444444444444e-06,
      "loss": 0.1199,
      "step": 7240
    },
    {
      "epoch": 2.322482604174998,
      "grad_norm": 1.0365819931030273,
      "learning_rate": 1.0291666666666668e-06,
      "loss": 0.1133,
      "step": 7260
    },
    {
      "epoch": 2.3288810685435495,
      "grad_norm": 2.523383855819702,
      "learning_rate": 1.001388888888889e-06,
      "loss": 0.1163,
      "step": 7280
    },
    {
      "epoch": 2.335279532912101,
      "grad_norm": 1.004949927330017,
      "learning_rate": 9.73611111111111e-07,
      "loss": 0.1093,
      "step": 7300
    },
    {
      "epoch": 2.3416779972806525,
      "grad_norm": 17.315963745117188,
      "learning_rate": 9.458333333333334e-07,
      "loss": 0.1235,
      "step": 7320
    },
    {
      "epoch": 2.348076461649204,
      "grad_norm": 2.5603187084198,
      "learning_rate": 9.180555555555556e-07,
      "loss": 0.1115,
      "step": 7340
    },
    {
      "epoch": 2.3544749260177555,
      "grad_norm": 1.4754915237426758,
      "learning_rate": 8.902777777777778e-07,
      "loss": 0.1175,
      "step": 7360
    },
    {
      "epoch": 2.360873390386307,
      "grad_norm": 1.335841178894043,
      "learning_rate": 8.625e-07,
      "loss": 0.1174,
      "step": 7380
    },
    {
      "epoch": 2.367271854754859,
      "grad_norm": 1.2333743572235107,
      "learning_rate": 8.347222222222223e-07,
      "loss": 0.1206,
      "step": 7400
    },
    {
      "epoch": 2.3736703191234105,
      "grad_norm": 0.7056669592857361,
      "learning_rate": 8.069444444444445e-07,
      "loss": 0.108,
      "step": 7420
    },
    {
      "epoch": 2.380068783491962,
      "grad_norm": 1.1057924032211304,
      "learning_rate": 7.791666666666667e-07,
      "loss": 0.1144,
      "step": 7440
    },
    {
      "epoch": 2.3864672478605136,
      "grad_norm": 1.1231495141983032,
      "learning_rate": 7.51388888888889e-07,
      "loss": 0.1213,
      "step": 7460
    },
    {
      "epoch": 2.392865712229065,
      "grad_norm": 1.3393051624298096,
      "learning_rate": 7.236111111111111e-07,
      "loss": 0.1214,
      "step": 7480
    },
    {
      "epoch": 2.3992641765976166,
      "grad_norm": 1.5060105323791504,
      "learning_rate": 6.958333333333334e-07,
      "loss": 0.1188,
      "step": 7500
    },
    {
      "epoch": 2.3992641765976166,
      "eval_accuracy": 84.0920460230115,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.88549618320111,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 80.29411764705384,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 87.1987951807179,
      "eval_loss": 0.1171165332198143,
      "eval_macro_f1": 84.12613633699095,
      "eval_runtime": 53.0259,
      "eval_samples_per_second": 37.699,
      "eval_steps_per_second": 1.188,
      "step": 7500
    },
    {
      "epoch": 2.405662640966168,
      "grad_norm": 1.3295153379440308,
      "learning_rate": 6.680555555555557e-07,
      "loss": 0.1123,
      "step": 7520
    },
    {
      "epoch": 2.4120611053347196,
      "grad_norm": 1.3418794870376587,
      "learning_rate": 6.402777777777778e-07,
      "loss": 0.1199,
      "step": 7540
    },
    {
      "epoch": 2.418459569703271,
      "grad_norm": 1.4415582418441772,
      "learning_rate": 6.125000000000001e-07,
      "loss": 0.1138,
      "step": 7560
    },
    {
      "epoch": 2.4248580340718227,
      "grad_norm": 1.423802137374878,
      "learning_rate": 5.847222222222223e-07,
      "loss": 0.1161,
      "step": 7580
    },
    {
      "epoch": 2.431256498440374,
      "grad_norm": 39.126312255859375,
      "learning_rate": 5.569444444444444e-07,
      "loss": 0.1218,
      "step": 7600
    },
    {
      "epoch": 2.4376549628089257,
      "grad_norm": 1.4330430030822754,
      "learning_rate": 5.291666666666668e-07,
      "loss": 0.1201,
      "step": 7620
    },
    {
      "epoch": 2.4440534271774776,
      "grad_norm": 1.4158214330673218,
      "learning_rate": 5.013888888888889e-07,
      "loss": 0.1169,
      "step": 7640
    },
    {
      "epoch": 2.450451891546029,
      "grad_norm": 1.9068396091461182,
      "learning_rate": 4.7361111111111116e-07,
      "loss": 0.1186,
      "step": 7660
    },
    {
      "epoch": 2.4568503559145807,
      "grad_norm": 2.2827749252319336,
      "learning_rate": 4.458333333333334e-07,
      "loss": 0.1158,
      "step": 7680
    },
    {
      "epoch": 2.463248820283132,
      "grad_norm": 1.2616990804672241,
      "learning_rate": 4.1805555555555556e-07,
      "loss": 0.1109,
      "step": 7700
    },
    {
      "epoch": 2.4696472846516837,
      "grad_norm": 1.098456859588623,
      "learning_rate": 3.9027777777777785e-07,
      "loss": 0.1084,
      "step": 7720
    },
    {
      "epoch": 2.476045749020235,
      "grad_norm": 1.2309452295303345,
      "learning_rate": 3.625e-07,
      "loss": 0.1178,
      "step": 7740
    },
    {
      "epoch": 2.4824442133887867,
      "grad_norm": 0.9159917831420898,
      "learning_rate": 3.3472222222222225e-07,
      "loss": 0.1158,
      "step": 7760
    },
    {
      "epoch": 2.4888426777573383,
      "grad_norm": 1.1473095417022705,
      "learning_rate": 3.069444444444445e-07,
      "loss": 0.1128,
      "step": 7780
    },
    {
      "epoch": 2.4952411421258898,
      "grad_norm": 1.2266353368759155,
      "learning_rate": 2.7916666666666666e-07,
      "loss": 0.1179,
      "step": 7800
    },
    {
      "epoch": 2.5016396064944413,
      "grad_norm": 1.52635657787323,
      "learning_rate": 2.513888888888889e-07,
      "loss": 0.1137,
      "step": 7820
    },
    {
      "epoch": 2.508038070862993,
      "grad_norm": 1.1497713327407837,
      "learning_rate": 2.2361111111111112e-07,
      "loss": 0.1172,
      "step": 7840
    },
    {
      "epoch": 2.5144365352315443,
      "grad_norm": 1.6461399793624878,
      "learning_rate": 1.9583333333333337e-07,
      "loss": 0.1219,
      "step": 7860
    },
    {
      "epoch": 2.520834999600096,
      "grad_norm": 1.3640954494476318,
      "learning_rate": 1.6805555555555558e-07,
      "loss": 0.1234,
      "step": 7880
    },
    {
      "epoch": 2.5272334639686473,
      "grad_norm": 1.4033057689666748,
      "learning_rate": 1.4027777777777778e-07,
      "loss": 0.1159,
      "step": 7900
    },
    {
      "epoch": 2.533631928337199,
      "grad_norm": 1.6316980123519897,
      "learning_rate": 1.1250000000000001e-07,
      "loss": 0.116,
      "step": 7920
    },
    {
      "epoch": 2.5400303927057504,
      "grad_norm": 1.220533013343811,
      "learning_rate": 8.472222222222224e-08,
      "loss": 0.1105,
      "step": 7940
    },
    {
      "epoch": 2.5464288570743023,
      "grad_norm": 1.12434720993042,
      "learning_rate": 5.6944444444444454e-08,
      "loss": 0.1135,
      "step": 7960
    },
    {
      "epoch": 2.552827321442854,
      "grad_norm": 0.9669595956802368,
      "learning_rate": 2.916666666666667e-08,
      "loss": 0.1073,
      "step": 7980
    },
    {
      "epoch": 2.5592257858114054,
      "grad_norm": 1.3330892324447632,
      "learning_rate": 1.388888888888889e-09,
      "loss": 0.1155,
      "step": 8000
    },
    {
      "epoch": 2.5592257858114054,
      "eval_accuracy": 84.19209604802401,
      "eval_f1_\u05d4\u05d9\u05e1\u05e7": 84.99234303215427,
      "eval_f1_\u05e0\u05d9\u05d8\u05e8\u05dc\u05d9": 80.46989720998032,
      "eval_f1_\u05e1\u05ea\u05d9\u05e8\u05d4": 87.21804511277696,
      "eval_loss": 0.11710401624441147,
      "eval_macro_f1": 84.22676178497052,
      "eval_runtime": 53.0677,
      "eval_samples_per_second": 37.669,
      "eval_steps_per_second": 1.187,
      "step": 8000
    }
  ],
  "logging_steps": 20,
  "max_steps": 8000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3870792849065492e+18,
  "train_batch_size": 6,
  "trial_name": null,
  "trial_params": null
}
